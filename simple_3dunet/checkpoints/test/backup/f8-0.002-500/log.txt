Building a new model...
24 8 8 ['2.nii', '4.nii', '13.nii', '12.nii', '31.nii', '26.nii', '34.nii', '14.nii', '19.nii', '33.nii', '28.nii', '15.nii', '20.nii', '10.nii', '27.nii', '38.nii', '16.nii', '5.nii', '32.nii', '7.nii', '9.nii', '1.nii', '11.nii', '39.nii'] ['37.nii', '29.nii', '6.nii', '0.nii', '8.nii', '24.nii', '30.nii', '18.nii'] ['35.nii', '36.nii', '17.nii', '25.nii', '21.nii', '22.nii', '3.nii', '23.nii']
Starting training:
            Epochs:1000
            Batch size:1
            Learning rate:0.002
            Training size:24
            Validation size:8
            
1 [0.99890864]
2 [1.99752396]
3 [2.99466854]
4 [3.99086773]
5 [4.98760086]
6 [5.98610812]
7 [6.98447126]
8 [7.98150975]
9 [8.97900283]
10 [9.97636056]
11 [10.97319096]
12 [11.96804333]
13 [12.96641284]
14 [13.96556515]
15 [14.96477687]
16 [15.96245742]
17 [16.95746911]
18 [17.95281303]
19 [18.95023119]
20 [19.9475531]
21 [20.94538945]
22 [21.94298851]
23 [22.93993843]
24 [23.93635899]
train done
Epoch 1/1000 : Loss:0.9973, Valid loss: 0.9962, lr:0.002000 [0.0038] 1683.6951839923859
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
1 [0.998]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
2 [1.9957]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
3 [2.9876]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
4 [3.9847]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
5 [4.9817]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
6 [5.9773]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
7 [6.9769]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
8 [7.9748]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
9 [8.9734]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
10 [9.9676]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
11 [10.9634]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
12 [11.9589]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
13 [12.9569]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
14 [13.9545]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
15 [14.9521]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
16 [15.9493]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
17 [16.9471]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
18 [17.9444]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
19 [18.9408]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
20 [19.9318]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
21 [20.9303]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
22 [21.9301]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
23 [22.9257]
torch.Size([1, 1, 64, 512, 512])
torch.Size([1, 1, 64, 512, 512])
24 [23.9218]
train done
Epoch 2/1000 : Loss:0.9967, Valid loss: 0.9883, lr:0.002000 [0.0117] 1626.223266839981
1 [0.9945]
2 [1.9865]
3 [2.9779]
4 [3.9723]
5 [4.9653]
6 [5.963]
7 [6.9562]
8 [7.9534]
9 [8.9518]
10 [9.9485]
11 [10.9421]
12 [11.9395]
13 [12.9326]
14 [13.9282]
15 [14.9217]
16 [15.9131]
17 [16.9088]
18 [17.9043]
19 [18.9037]
20 [19.9017]
21 [20.893]
22 [21.8837]
23 [22.8788]
24 [23.8684]
train done
Epoch 3/1000 : Loss:0.9945, Valid loss: 0.9815, lr:0.002000 [0.0185] 1619.393944978714
1 [0.9956]
2 [1.9787]
3 [2.975]
4 [3.9708]
5 [4.9633]
6 [5.9624]
7 [6.9514]
8 [7.9371]
9 [8.9268]
10 [9.911]
11 [10.9043]
12 [11.8855]
13 [12.8763]
14 [13.8605]
15 [14.8525]
16 [15.8391]
17 [16.8204]
18 [17.8112]
19 [18.8021]
20 [19.7742]
21 [20.7552]
22 [21.748]
23 [22.7362]
24 [23.7162]
train done
Epoch 4/1000 : Loss:0.9882, Valid loss: 0.9416, lr:0.002000 [0.0584] 1632.611582994461
1 [0.9793]
2 [1.9351]
3 [2.8793]
4 [3.877]
5 [4.8738]
6 [5.8721]
7 [6.8614]
8 [7.8302]
9 [8.7688]
10 [9.7448]
11 [10.708]
12 [11.6834]
13 [12.6133]
14 [13.5971]
15 [14.5495]
16 [15.5097]
17 [16.4927]
18 [17.4196]
19 [18.3818]
20 [19.2736]
21 [20.1418]
22 [21.0793]
23 [22.0465]
24 [22.8875]
train done
Epoch 5/1000 : Loss:0.9536, Valid loss: 0.9433, lr:0.002000 [0.0567] 1635.0041120052338
1 [0.9422]
2 [1.9111]
3 [2.8482]
4 [3.7673]
5 [4.677]
6 [5.6566]
7 [6.5673]
8 [7.5546]
9 [8.5023]
10 [9.4077]
11 [10.2717]
12 [11.2408]
13 [12.2132]
14 [13.2046]
15 [14.197]
16 [15.1697]
17 [16.1568]
18 [17.122]
19 [17.9029]
20 [18.7861]
21 [19.6476]
22 [20.3782]
23 [21.1807]
24 [22.0846]
train done
Epoch 6/1000 : Loss:0.9202, Valid loss: 0.8070, lr:0.002000 [0.193] 1639.4375240802765
1 [0.7517]
2 [1.4906]
3 [2.2371]
4 [2.9975]
5 [3.6235]
6 [4.3556]
7 [5.2841]
8 [6.271]
9 [7.0698]
10 [8.0466]
11 [8.8142]
12 [9.5561]
13 [10.2933]
14 [11.2068]
15 [12.1853]
16 [13.0598]
17 [13.8881]
18 [14.6834]
19 [15.5261]
20 [16.1149]
21 [16.6817]
22 [17.2676]
23 [18.0652]
24 [18.8243]
train done
Epoch 7/1000 : Loss:0.7843, Valid loss: 0.7280, lr:0.002000 [0.272] 1639.6338679790497
1 [0.7479]
2 [1.4805]
3 [2.1367]
4 [2.9154]
5 [3.8358]
6 [4.6927]
7 [5.3519]
8 [6.0514]
9 [6.7609]
10 [7.4975]
11 [8.1393]
12 [9.093]
13 [9.9019]
14 [10.4943]
15 [11.1844]
16 [11.8214]
17 [12.5652]
18 [13.1185]
19 [14.0252]
20 [14.6008]
21 [15.231]
22 [15.9017]
23 [16.8016]
24 [17.4473]
train done
Epoch 8/1000 : Loss:0.7270, Valid loss: 0.6813, lr:0.002000 [0.3187] 1627.8182489871979
1 [0.681]
2 [1.6377]
3 [2.2085]
4 [2.9761]
5 [3.5656]
6 [4.3582]
7 [5.0248]
8 [5.68]
9 [6.5818]
10 [7.194]
11 [8.0152]
12 [8.6136]
13 [9.3695]
14 [10.3051]
15 [11.2941]
16 [12.1656]
17 [13.0896]
18 [14.0122]
19 [14.761]
20 [15.4485]
21 [16.3005]
22 [17.1578]
23 [17.9243]
24 [18.5318]
train done
Epoch 9/1000 : Loss:0.7722, Valid loss: 0.6933, lr:0.002000 [0.3067] 1629.9738171100616
1 [0.9157]
2 [1.5343]
3 [2.3569]
4 [2.9477]
5 [3.5873]
6 [4.4409]
7 [5.4097]
8 [6.1776]
9 [6.6393]
10 [7.1364]
11 [7.8421]
12 [8.2936]
13 [9.0934]
14 [9.977]
15 [10.6257]
16 [11.609]
17 [12.268]
18 [12.7319]
19 [13.3168]
20 [13.8237]
21 [14.6927]
22 [15.4021]
23 [16.0818]
24 [16.8541]
train done
Epoch 10/1000 : Loss:0.7023, Valid loss: 0.6862, lr:0.002000 [0.3138] 1636.3867208957672
Model 10 saved.
1 [0.6039]
2 [1.1611]
3 [1.7595]
4 [2.3591]
5 [3.041]
6 [3.658]
7 [4.4546]
8 [5.0959]
9 [5.8095]
10 [6.5478]
11 [7.2106]
12 [7.8284]
13 [8.3337]
14 [8.9941]
15 [9.6319]
16 [10.391]
17 [11.2376]
18 [11.812]
19 [12.7861]
20 [13.5874]
21 [14.1291]
22 [14.8583]
23 [15.4151]
24 [15.9511]
train done
Epoch 11/1000 : Loss:0.6646, Valid loss: 0.6436, lr:0.002000 [0.3564] 1627.3431000709534
1 [0.5709]
2 [1.0913]
3 [1.76]
4 [2.2837]
5 [3.159]
6 [3.788]
7 [4.592]
8 [5.2093]
9 [5.8688]
10 [6.519]
11 [7.3149]
12 [7.9866]
13 [8.7386]
14 [9.2895]
15 [10.0349]
16 [10.8302]
17 [11.7087]
18 [12.5339]
19 [13.0728]
20 [13.9032]
21 [14.6674]
22 [15.4744]
23 [16.0487]
24 [16.5887]
train done
Epoch 12/1000 : Loss:0.6912, Valid loss: 0.6148, lr:0.002000 [0.3852] 1614.4123630523682
1 [0.6018]
2 [1.1282]
3 [1.5985]
4 [2.29]
5 [2.8713]
6 [3.5037]
7 [4.0405]
8 [4.7588]
9 [5.3895]
10 [6.0304]
11 [6.7705]
12 [7.41]
13 [8.1003]
14 [8.8811]
15 [9.6]
16 [10.3831]
17 [11.011]
18 [11.6937]
19 [12.3835]
20 [13.3835]
21 [14.1082]
22 [14.9122]
23 [15.5081]
24 [16.0235]
train done
Epoch 13/1000 : Loss:0.6676, Valid loss: 0.6056, lr:0.002000 [0.3944] 1642.7460279464722
1 [0.5209]
2 [1.0588]
3 [1.6358]
4 [2.5284]
5 [3.0572]
6 [3.7235]
7 [4.4252]
8 [5.1959]
9 [6.0618]
10 [6.5439]
11 [7.0693]
12 [7.6425]
13 [8.1564]
14 [8.9641]
15 [9.533]
16 [10.1571]
17 [10.8017]
18 [11.523]
19 [12.0412]
20 [12.673]
21 [13.4359]
22 [14.0223]
23 [14.5884]
24 [15.0688]
train done
Epoch 14/1000 : Loss:0.6279, Valid loss: 0.6386, lr:0.002000 [0.3614] 1626.0393702983856
1 [0.5268]
2 [1.0464]
3 [1.7153]
4 [2.3882]
5 [3.0238]
6 [3.5929]
7 [4.2546]
8 [4.9745]
9 [5.5772]
10 [6.2005]
11 [6.7717]
12 [7.5003]
13 [8.2777]
14 [9.0072]
15 [9.6465]
16 [10.2221]
17 [10.6542]
18 [11.0687]
19 [11.4984]
20 [12.0001]
21 [12.5847]
22 [13.1433]
23 [13.8296]
24 [14.5538]
train done
Epoch 15/1000 : Loss:0.6064, Valid loss: 0.7707, lr:0.002000 [0.2293] 1632.4588561058044
1 [0.5925]
2 [1.2148]
3 [1.7902]
4 [2.6861]
5 [3.1571]
6 [3.7041]
7 [4.2733]
8 [4.754]
9 [5.307]
10 [5.9715]
11 [6.5336]
12 [7.1832]
13 [7.6471]
14 [8.4359]
15 [9.0963]
16 [9.9448]
17 [10.5774]
18 [11.0596]
19 [11.7004]
20 [12.3155]
21 [13.1308]
22 [13.7755]
23 [14.4451]
24 [15.0865]
train done
Epoch 16/1000 : Loss:0.6286, Valid loss: 0.6638, lr:0.002000 [0.3362] 1647.1279458999634
1 [0.4793]
2 [1.1993]
3 [1.7233]
4 [2.4675]
5 [3.1205]
6 [4.0046]
7 [4.7011]
8 [5.6503]
9 [6.2193]
10 [6.7804]
11 [7.3475]
12 [8.0301]
13 [8.4543]
14 [9.0011]
15 [9.5572]
16 [10.084]
17 [10.5883]
18 [11.0918]
19 [11.4236]
20 [12.193]
21 [12.6427]
22 [13.1905]
23 [13.6258]
24 [14.0453]
train done
Epoch 17/1000 : Loss:0.5852, Valid loss: 0.5464, lr:0.002000 [0.4536] 1603.0707540512085
1 [0.4907]
2 [1.0318]
3 [1.3535]
4 [1.8279]
5 [2.2746]
6 [2.8859]
7 [3.8859]
8 [4.266]
9 [4.7694]
10 [5.5836]
11 [6.2189]
12 [6.6957]
13 [7.217]
14 [7.5742]
15 [8.0373]
16 [8.3855]
17 [8.8871]
18 [9.4389]
19 [10.0256]
20 [10.5555]
21 [11.1294]
22 [11.5283]
23 [12.3117]
24 [12.8171]
train done
Epoch 18/1000 : Loss:0.5340, Valid loss: 0.5361, lr:0.002000 [0.4639] 1614.7447428703308
1 [0.4944]
2 [1.1226]
3 [1.606]
4 [2.0685]
5 [2.4564]
6 [3.1084]
7 [3.565]
8 [3.9727]
9 [4.4955]
10 [5.0995]
11 [5.6141]
12 [5.9718]
13 [6.6079]
14 [7.4692]
15 [8.0721]
16 [8.3998]
17 [9.1723]
18 [9.6647]
19 [10.2218]
20 [10.7364]
21 [11.4411]
22 [12.1341]
23 [12.5096]
24 [13.0905]
train done
Epoch 19/1000 : Loss:0.5454, Valid loss: 0.5224, lr:0.002000 [0.4776] 1626.6847412586212
1 [0.3609]
2 [0.7926]
3 [1.2009]
4 [2.0934]
5 [2.7849]
6 [3.2122]
7 [3.5073]
8 [4.0548]
9 [4.5058]
10 [4.9482]
11 [5.5546]
12 [5.9813]
13 [6.7636]
14 [7.2798]
15 [7.7716]
16 [8.5412]
17 [8.9924]
18 [9.4628]
19 [9.8597]
20 [10.3643]
21 [11.1365]
22 [11.7355]
23 [12.3734]
24 [12.9819]
train done
Epoch 20/1000 : Loss:0.5409, Valid loss: 0.6127, lr:0.002000 [0.3873] 1629.0009260177612
Model 20 saved.
1 [0.5792]
2 [1.2161]
3 [1.9361]
4 [2.3857]
5 [2.8749]
6 [3.4385]
7 [3.9623]
8 [4.6804]
9 [5.1378]
10 [5.6827]
11 [6.3595]
12 [6.9487]
13 [7.4771]
14 [7.9309]
15 [8.7]
16 [9.1157]
17 [9.7148]
18 [10.1508]
19 [10.7973]
20 [11.323]
21 [11.9132]
22 [12.2967]
23 [12.6603]
24 [13.1989]
train done
Epoch 21/1000 : Loss:0.5500, Valid loss: 0.5477, lr:0.002000 [0.4523] 1624.8616981506348
1 [0.5697]
2 [1.0365]
3 [1.3906]
4 [1.9703]
5 [2.3865]
6 [2.8517]
7 [3.2706]
8 [3.9612]
9 [4.4667]
10 [4.9913]
11 [5.8564]
12 [6.2648]
13 [6.6188]
14 [7.3478]
15 [7.9259]
16 [8.6252]
17 [9.1254]
18 [9.5004]
19 [9.96]
20 [10.7621]
21 [11.3872]
22 [12.0578]
23 [12.5303]
24 [13.0116]
train done
Epoch 22/1000 : Loss:0.5421, Valid loss: 0.5686, lr:0.002000 [0.4314] 1641.622326850891
1 [0.4992]
2 [1.3162]
3 [1.9854]
4 [2.3772]
5 [3.1256]
6 [3.5209]
7 [4.2914]
8 [5.0549]
9 [5.6493]
10 [5.6497]
11 [6.2467]
12 [7.002]
13 [7.5513]
14 [8.1088]
15 [8.6548]
16 [9.454]
17 [9.8885]
18 [10.6636]
19 [11.2631]
20 [11.9548]
21 [12.3509]
22 [12.8721]
23 [13.2315]
24 [13.7568]
train done
Epoch 23/1000 : Loss:0.5732, Valid loss: 0.5411, lr:0.002000 [0.4589] 1635.4653029441833
1 [0.3292]
2 [0.658]
3 [1.18]
4 [1.8093]
5 [2.3621]
6 [2.6744]
7 [3.3192]
8 [3.9432]
9 [4.4534]
10 [5.0787]
11 [5.6566]
12 [6.2708]
13 [6.8389]
14 [7.2703]
15 [7.8968]
16 [8.6228]
17 [9.1972]
18 [9.9206]
19 [10.5897]
20 [11.095]
21 [11.5317]
22 [12.1584]
23 [12.6131]
24 [13.0486]
train done
Epoch 24/1000 : Loss:0.5437, Valid loss: 0.5411, lr:0.002000 [0.4589] 1645.169703245163
1 [0.4114]
2 [1.2613]
3 [1.6313]
4 [2.0244]
5 [2.38]
6 [2.8036]
7 [3.2192]
8 [3.533]
9 [3.8728]
10 [4.1519]
11 [4.6769]
12 [5.6769]
13 [6.1154]
14 [6.6253]
15 [7.0256]
16 [7.4209]
17 [7.8165]
18 [8.3866]
19 [8.7816]
20 [9.4728]
21 [10.0975]
22 [10.6092]
23 [11.3162]
24 [11.8393]
train done
Epoch 25/1000 : Loss:0.4933, Valid loss: 0.5498, lr:0.002000 [0.4502] 1635.8345820903778
1 [0.5149]
2 [1.1558]
3 [1.5209]
4 [2.2227]
5 [2.7245]
6 [3.0901]
7 [3.5063]
8 [3.9219]
9 [4.3989]
10 [4.8703]
11 [5.774]
12 [6.2185]
13 [6.7729]
14 [7.3129]
15 [7.9603]
16 [8.3487]
17 [9.1429]
18 [9.702]
19 [10.077]
20 [10.5108]
21 [10.8757]
22 [11.377]
23 [11.7001]
24 [12.2093]
train done
Epoch 26/1000 : Loss:0.5087, Valid loss: 0.5446, lr:0.002000 [0.4554] 1629.3059587478638
1 [0.5525]
2 [1.0662]
3 [1.5205]
4 [1.9478]
5 [2.3737]
6 [3.181]
7 [3.5611]
8 [3.9353]
9 [4.4805]
10 [4.8053]
11 [5.5708]
12 [5.9674]
13 [6.447]
14 [6.8723]
15 [7.4818]
16 [7.7819]
17 [8.2204]
18 [8.5959]
19 [9.0595]
20 [9.4835]
21 [10.0442]
22 [10.4061]
23 [10.7051]
24 [11.2305]
train done
Epoch 27/1000 : Loss:0.4679, Valid loss: 0.5676, lr:0.002000 [0.4324] 1624.1985743045807
1 [0.8762]
2 [1.5023]
3 [1.9976]
4 [2.5935]
5 [2.9282]
6 [3.4731]
7 [3.7942]
8 [4.2006]
9 [4.6382]
10 [4.9479]
11 [5.4127]
12 [6.2464]
13 [6.9777]
14 [7.4265]
15 [8.0529]
16 [8.3511]
17 [8.8727]
18 [9.2129]
19 [9.7404]
20 [10.0792]
21 [10.4808]
22 [10.874]
23 [11.2305]
24 [11.7269]
train done
Epoch 28/1000 : Loss:0.4886, Valid loss: 0.4973, lr:0.002000 [0.5027] 1654.0076229572296
1 [0.4629]
2 [1.1067]
3 [1.5688]
4 [1.8939]
5 [2.6515]
6 [2.9351]
7 [3.3277]
8 [3.5509]
9 [3.9586]
10 [4.2631]
11 [4.5809]
12 [4.8943]
13 [5.201]
14 [5.7939]
15 [6.2348]
16 [6.6631]
17 [7.0957]
18 [7.4724]
19 [7.7169]
20 [8.446]
21 [8.7704]
22 [9.1032]
23 [9.5529]
24 [10.0524]
train done
Epoch 29/1000 : Loss:0.4189, Valid loss: 0.4592, lr:0.002000 [0.5408] 1568.3066971302032
1 [0.4003]
2 [0.7582]
3 [1.1271]
4 [1.547]
5 [1.8417]
6 [2.3035]
7 [2.6961]
8 [3.1001]
9 [3.4196]
10 [3.8845]
11 [4.3207]
12 [4.6434]
13 [5.3302]
14 [6.1471]
15 [6.8211]
16 [7.2488]
17 [7.5674]
18 [7.8893]
19 [8.575]
20 [8.9635]
21 [9.5836]
22 [10.1264]
23 [10.9903]
24 [11.8675]
train done
Epoch 30/1000 : Loss:0.4945, Valid loss: 0.4907, lr:0.002000 [0.5093] 1690.962100982666
Model 30 saved.
1 [0.6277]
2 [1.0801]
3 [1.5716]
4 [2.259]
5 [2.5521]
6 [3.1037]
7 [3.5377]
8 [3.9422]
9 [4.3134]
10 [4.7869]
11 [5.2557]
12 [5.8007]
13 [6.2878]
14 [7.0249]
15 [7.5945]
16 [8.0418]
17 [8.3846]
18 [8.9906]
19 [9.3522]
20 [9.7938]
21 [10.3049]
22 [10.755]
23 [11.2714]
24 [11.7501]
train done
Epoch 31/1000 : Loss:0.4896, Valid loss: 0.5086, lr:0.002000 [0.4914] 1837.146074771881
1 [0.4403]
2 [0.7527]
3 [1.0429]
4 [1.3095]
5 [1.6568]
6 [1.8457]
7 [2.1631]
8 [2.8348]
9 [3.2672]
10 [3.6049]
11 [3.9838]
12 [4.4602]
13 [4.9668]
14 [5.5719]
15 [6.019]
16 [6.4786]
17 [6.8249]
18 [7.5691]
19 [7.9378]
20 [8.1563]
21 [8.5298]
22 [8.8764]
23 [9.6943]
24 [10.0669]
train done
Epoch 32/1000 : Loss:0.4195, Valid loss: 0.5413, lr:0.002000 [0.4587] 1787.1774060726166
1 [0.5464]
2 [0.9195]
3 [1.3477]
4 [1.7576]
5 [2.2227]
6 [2.5673]
7 [2.9543]
8 [3.3312]
9 [3.7768]
10 [4.4337]
11 [4.805]
12 [5.0817]
13 [5.419]
14 [5.9082]
15 [6.4126]
16 [6.9433]
17 [7.5167]
18 [7.77]
19 [8.1039]
20 [8.3258]
21 [8.8833]
22 [9.4889]
23 [9.8717]
24 [10.485]
train done
Epoch 33/1000 : Loss:0.4369, Valid loss: 0.4715, lr:0.002000 [0.5285] 1691.7502491474152
1 [0.4024]
2 [0.7346]
3 [1.0055]
4 [1.3681]
5 [1.6635]
6 [2.0048]
7 [2.3518]
8 [3.1232]
9 [3.5516]
10 [3.915]
11 [4.4464]
12 [4.794]
13 [5.3648]
14 [5.8094]
15 [6.4822]
16 [6.8664]
17 [7.4844]
18 [7.9701]
19 [8.6247]
20 [9.1907]
21 [9.9956]
22 [10.5683]
23 [10.8671]
24 [11.3511]
train done
Epoch 34/1000 : Loss:0.4730, Valid loss: 0.4769, lr:0.002000 [0.5231] 1623.3401937484741
1 [0.3721]
2 [0.8736]
3 [1.2693]
4 [1.5816]
5 [2.1445]
6 [2.4537]
7 [2.9285]
8 [3.2611]
9 [3.8388]
10 [4.1959]
11 [4.5064]
12 [4.8516]
13 [5.114]
14 [5.5663]
15 [6.0444]
16 [6.7199]
17 [7.0546]
18 [7.5831]
19 [8.0592]
20 [8.5056]
21 [8.7318]
22 [9.2059]
23 [9.6993]
24 [10.0995]
train done
Epoch 35/1000 : Loss:0.4208, Valid loss: 0.4642, lr:0.002000 [0.5358] 1747.5400779247284
1 [0.2808]
2 [0.6472]
3 [0.9704]
4 [1.2398]
5 [1.5087]
6 [1.8091]
7 [2.1588]
8 [2.3989]
9 [2.7631]
10 [3.2249]
11 [3.5607]
12 [3.9499]
13 [4.4532]
14 [4.9381]
15 [5.4312]
16 [5.8043]
17 [6.0902]
18 [6.9774]
19 [7.3513]
20 [7.6572]
21 [7.9565]
22 [8.2921]
23 [8.6164]
24 [9.1329]
train done
Epoch 36/1000 : Loss:0.3805, Valid loss: 0.4264, lr:0.002000 [0.5736] 1987.296455860138
1 [0.3073]
2 [0.6616]
3 [1.0762]
4 [1.2267]
5 [1.7339]
6 [1.9482]
7 [2.5253]
8 [2.677]
9 [3.4545]
10 [3.8549]
11 [4.1384]
12 [4.4233]
13 [4.8623]
14 [5.4459]
15 [5.9563]
16 [6.3453]
17 [6.7293]
18 [7.186]
19 [7.4476]
20 [7.7722]
21 [8.3904]
22 [8.6957]
23 [9.0686]
24 [9.4467]
train done
Epoch 37/1000 : Loss:0.3936, Valid loss: 0.4681, lr:0.002000 [0.5319] 1851.8544690608978
1 [0.4893]
2 [0.8525]
3 [1.16]
4 [1.4306]
5 [2.1427]
6 [2.6238]
7 [2.8271]
8 [3.5179]
9 [4.1824]
10 [4.4931]
11 [4.7875]
12 [5.2737]
13 [5.7024]
14 [6.0625]
15 [6.4308]
16 [6.7535]
17 [7.1395]
18 [7.4961]
19 [7.8537]
20 [8.5902]
21 [8.9605]
22 [9.3513]
23 [10.1013]
24 [10.3764]
train done
Epoch 38/1000 : Loss:0.4323, Valid loss: 0.6071, lr:0.002000 [0.3929] 1711.4613637924194
1 [0.5527]
2 [1.1306]
3 [1.3971]
4 [1.8615]
5 [2.1949]
6 [2.5645]
7 [2.9648]
8 [3.5389]
9 [3.9668]
10 [4.4183]
11 [5.0546]
12 [5.4305]
13 [5.7305]
14 [6.1261]
15 [6.7525]
16 [7.501]
17 [8.0841]
18 [8.2719]
19 [8.6999]
20 [8.9089]
21 [9.4368]
22 [10.1483]
23 [10.5797]
24 [10.9055]
train done
Epoch 39/1000 : Loss:0.4544, Valid loss: 0.5051, lr:0.002000 [0.4949] 1661.369938135147
1 [0.4874]
2 [0.9266]
3 [1.4336]
4 [1.9098]
5 [2.5323]
6 [2.9089]
7 [3.2188]
8 [3.5214]
9 [3.7969]
10 [3.996]
11 [4.3046]
12 [5.2207]
13 [5.5584]
14 [5.9499]
15 [6.2816]
16 [6.4331]
17 [6.795]
18 [7.498]
19 [7.7903]
20 [8.0935]
21 [8.4482]
22 [8.7208]
23 [8.9434]
24 [9.3547]
train done
Epoch 40/1000 : Loss:0.3898, Valid loss: 0.4280, lr:0.002000 [0.572] 1665.1581699848175
Model 40 saved.
1 [0.8267]
2 [1.1495]
3 [1.4717]
4 [1.7778]
5 [2.0324]
6 [2.4307]
7 [2.86]
8 [3.286]
9 [3.8881]
10 [4.1676]
11 [4.6056]
12 [4.978]
13 [5.2948]
14 [5.7529]
15 [6.0812]
16 [6.4433]
17 [6.87]
18 [7.2018]
19 [7.6446]
20 [8.0164]
21 [8.4082]
22 [8.7897]
23 [9.1711]
24 [9.4362]
train done
Epoch 41/1000 : Loss:0.3932, Valid loss: 0.3972, lr:0.002000 [0.6028] 1624.3710451126099
1 [0.6509]
2 [0.9284]
3 [1.4278]
4 [1.9494]
5 [2.4631]
6 [3.2095]
7 [3.5945]
8 [3.9332]
9 [4.3799]
10 [4.7475]
11 [5.5591]
12 [5.9984]
13 [6.2687]
14 [6.7084]
15 [7.0352]
16 [7.372]
17 [7.7181]
18 [7.9728]
19 [8.5916]
20 [9.1499]
21 [9.5227]
22 [9.7739]
23 [10.2619]
24 [10.9019]
train done
Epoch 42/1000 : Loss:0.4542, Valid loss: 0.4720, lr:0.002000 [0.528] 1659.9679498672485
1 [0.2893]
2 [0.8989]
3 [1.4261]
4 [1.7735]
5 [2.3552]
6 [2.7922]
7 [3.5611]
8 [4.2589]
9 [4.7171]
10 [5.016]
11 [5.0167]
12 [5.6254]
13 [6.2183]
14 [6.5889]
15 [7.1828]
16 [7.3834]
17 [8.2877]
18 [8.6292]
19 [8.9943]
20 [9.3875]
21 [9.8278]
22 [10.109]
23 [10.8687]
24 [11.2615]
train done
Epoch 43/1000 : Loss:0.4692, Valid loss: 0.4819, lr:0.002000 [0.5181] 1882.3870887756348
1 [0.3761]
2 [0.7597]
3 [1.2645]
4 [1.4887]
5 [1.9858]
6 [2.3054]
7 [2.948]
8 [3.3113]
9 [3.546]
10 [4.0865]
11 [4.4602]
12 [4.741]
13 [5.6009]
14 [5.9938]
15 [6.3869]
16 [6.6188]
17 [7.1244]
18 [7.565]
19 [7.8823]
20 [8.1218]
21 [8.3485]
22 [8.6813]
23 [9.0103]
24 [9.2595]
train done
Epoch 44/1000 : Loss:0.3858, Valid loss: 0.5291, lr:0.002000 [0.4709] 1944.5651779174805
1 [0.305]
2 [0.6665]
3 [1.0073]
4 [1.545]
5 [1.8963]
6 [2.395]
7 [2.7563]
8 [2.9928]
9 [3.2223]
10 [3.6294]
11 [3.9441]
12 [4.2643]
13 [4.8078]
14 [5.1824]
15 [5.4939]
16 [6.0332]
17 [6.4622]
18 [6.8499]
19 [7.238]
20 [7.6764]
21 [7.9523]
22 [8.2275]
23 [8.4552]
24 [8.9845]
train done
Epoch 45/1000 : Loss:0.3744, Valid loss: 0.5307, lr:0.002000 [0.4693] 1917.5084040164948
1 [0.2721]
2 [0.8376]
3 [1.3742]
4 [1.7824]
5 [2.0311]
6 [2.4792]
7 [2.9595]
8 [3.4318]
9 [3.8364]
10 [4.5142]
11 [4.7332]
12 [5.0514]
13 [5.3899]
14 [5.9693]
15 [6.2728]
16 [6.5044]
17 [6.7878]
18 [7.1318]
19 [7.4355]
20 [7.78]
21 [8.3283]
22 [8.9118]
23 [9.5606]
24 [9.8557]
train done
Epoch 46/1000 : Loss:0.4107, Valid loss: 0.5889, lr:0.002000 [0.4111] 1898.2480540275574
1 [0.5621]
2 [0.8675]
3 [1.1336]
4 [1.4974]
5 [1.7533]
6 [2.017]
7 [2.3016]
8 [2.8648]
9 [3.1824]
10 [3.5016]
11 [3.8826]
12 [4.1285]
13 [4.4298]
14 [4.6375]
15 [5.058]
16 [5.5088]
17 [6.142]
18 [6.5264]
19 [7.1337]
20 [7.5108]
21 [7.8389]
22 [8.3087]
23 [8.7338]
24 [9.2432]
train done
Epoch 47/1000 : Loss:0.3851, Valid loss: 0.4956, lr:0.002000 [0.5044] 1988.0231082439423
1 [0.3225]
2 [0.6654]
3 [0.9059]
4 [1.3713]
5 [1.7042]
6 [1.9876]
7 [2.2533]
8 [2.5194]
9 [2.796]
10 [3.133]
11 [3.5517]
12 [3.8865]
13 [4.1763]
14 [4.4762]
15 [4.858]
16 [5.1101]
17 [5.5677]
18 [5.9933]
19 [6.1786]
20 [6.5949]
21 [7.269]
22 [7.7961]
23 [8.0434]
24 [8.4239]
train done
Epoch 48/1000 : Loss:0.3510, Valid loss: 0.3791, lr:0.002000 [0.6209] 1936.4621770381927
1 [0.3588]
2 [0.8333]
3 [1.1816]
4 [1.477]
5 [1.8421]
6 [2.1714]
7 [2.5658]
8 [2.8951]
9 [3.2874]
10 [3.6102]
11 [4.0688]
12 [4.4498]
13 [4.7498]
14 [5.2494]
15 [5.7971]
16 [6.2262]
17 [6.9817]
18 [7.4801]
19 [7.7631]
20 [7.9265]
21 [8.2412]
22 [8.525]
23 [8.8016]
24 [9.1141]
train done
Epoch 49/1000 : Loss:0.3798, Valid loss: 0.4458, lr:0.002000 [0.5542] 1886.3749840259552
1 [0.3344]
2 [0.8303]
3 [1.4172]
4 [1.8289]
5 [2.3038]
6 [2.6571]
7 [2.9695]
8 [3.2505]
9 [3.7182]
10 [4.1443]
11 [4.4781]
12 [4.7174]
13 [4.9971]
14 [5.1816]
15 [5.641]
16 [6.068]
17 [6.4483]
18 [6.7355]
19 [6.9321]
20 [7.2673]
21 [7.6062]
22 [7.9419]
23 [8.2074]
24 [8.4353]
train done
Epoch 50/1000 : Loss:0.3515, Valid loss: 0.4454, lr:0.002000 [0.5546] 1856.9036710262299
Model 50 saved.
1 [0.333]
2 [0.5556]
3 [0.8999]
4 [1.1657]
5 [1.739]
6 [1.9568]
7 [2.4186]
8 [2.9289]
9 [3.2615]
10 [3.9183]
11 [4.2349]
12 [4.555]
13 [4.9367]
14 [5.5127]
15 [5.832]
16 [6.168]
17 [6.635]
18 [7.0935]
19 [7.8168]
20 [8.2056]
21 [8.4097]
22 [8.7306]
23 [9.0299]
24 [9.2722]
train done
Epoch 51/1000 : Loss:0.3863, Valid loss: 0.4556, lr:0.001400 [0.5444] 1840.7576079368591
1 [0.4602]
2 [0.8133]
3 [1.1622]
4 [1.4146]
5 [1.6868]
6 [2.0596]
7 [2.3062]
8 [2.6594]
9 [2.9933]
10 [3.2606]
11 [3.8626]
12 [4.1831]
13 [4.3905]
14 [4.64]
15 [5.1512]
16 [5.4322]
17 [5.7081]
18 [6.0319]
19 [6.285]
20 [6.5653]
21 [7.1139]
22 [7.3289]
23 [7.5899]
24 [7.8827]
train done
Epoch 52/1000 : Loss:0.3284, Valid loss: 0.4146, lr:0.001400 [0.5854] 1901.4372279644012
1 [0.2999]
2 [0.9046]
3 [1.5854]
4 [2.3272]
5 [2.9071]
6 [3.2447]
7 [3.5216]
8 [3.8017]
9 [4.121]
10 [4.8287]
11 [5.3568]
12 [5.5924]
13 [5.9428]
14 [6.236]
15 [6.6672]
16 [7.1057]
17 [7.353]
18 [7.803]
19 [8.1717]
20 [8.5635]
21 [8.9202]
22 [9.0929]
23 [9.5025]
24 [10.1896]
train done
Epoch 53/1000 : Loss:0.4246, Valid loss: 0.5127, lr:0.001400 [0.4873] 1793.6812539100647
1 [0.3796]
2 [1.0099]
3 [1.2889]
4 [1.6576]
5 [1.8281]
6 [1.9637]
7 [2.371]
8 [2.6751]
9 [2.8829]
10 [3.1643]
11 [3.5308]
12 [4.1322]
13 [4.4288]
14 [4.7265]
15 [5.0284]
16 [5.3386]
17 [5.6865]
18 [6.2446]
19 [6.6542]
20 [7.1017]
21 [7.4236]
22 [7.7613]
23 [8.0814]
24 [8.3139]
train done
Epoch 54/1000 : Loss:0.3464, Valid loss: 0.4002, lr:0.001400 [0.5998] 1615.1134910583496
1 [0.6342]
2 [1.0715]
3 [1.7298]
4 [2.3928]
5 [2.8622]
6 [3.2777]
7 [3.7854]
8 [4.0933]
9 [4.678]
10 [5.0066]
11 [5.2334]
12 [5.4719]
13 [5.8829]
14 [6.4572]
15 [6.7824]
16 [7.0707]
17 [7.4455]
18 [7.7154]
19 [8.2212]
20 [8.6215]
21 [9.0353]
22 [9.362]
23 [9.8452]
24 [10.1257]
train done
Epoch 55/1000 : Loss:0.4219, Valid loss: 0.4480, lr:0.001400 [0.552] 1614.316615819931
1 [0.34]
2 [0.5925]
3 [1.207]
4 [1.4424]
5 [1.756]
6 [2.1575]
7 [2.3356]
8 [2.6771]
9 [2.9182]
10 [3.1277]
11 [3.3894]
12 [3.6041]
13 [4.0917]
14 [4.3734]
15 [4.774]
16 [4.9883]
17 [5.1652]
18 [5.4412]
19 [5.6596]
20 [5.9535]
21 [6.295]
22 [6.5725]
23 [6.978]
24 [7.3581]
train done
Epoch 56/1000 : Loss:0.3066, Valid loss: 0.3851, lr:0.001400 [0.6149] 1618.5482139587402
1 [0.2919]
2 [0.4613]
3 [1.1205]
4 [1.3358]
5 [1.5918]
6 [2.0389]
7 [2.2757]
8 [2.6874]
9 [2.8595]
10 [3.4727]
11 [3.9076]
12 [4.1087]
13 [4.5165]
14 [5.0873]
15 [5.7004]
16 [6.0314]
17 [6.3652]
18 [6.8964]
19 [7.2505]
20 [7.4947]
21 [7.8073]
22 [8.1341]
23 [8.5665]
24 [8.8093]
train done
Epoch 57/1000 : Loss:0.3671, Valid loss: 0.4558, lr:0.001400 [0.5442] 1597.9384109973907
1 [0.2574]
2 [0.5728]
3 [0.8407]
4 [1.1731]
5 [1.4799]
6 [1.7217]
7 [2.1322]
8 [2.3382]
9 [2.6163]
10 [2.9244]
11 [3.1437]
12 [3.4302]
13 [3.6964]
14 [4.0933]
15 [4.3376]
16 [4.5725]
17 [4.8205]
18 [5.5262]
19 [5.8109]
20 [6.2533]
21 [6.6104]
22 [6.9034]
23 [7.15]
24 [7.4549]
train done
Epoch 58/1000 : Loss:0.3106, Valid loss: 0.4037, lr:0.001400 [0.5963] 1636.489429950714
1 [0.1599]
2 [0.6549]
3 [1.0283]
4 [1.768]
5 [2.0694]
6 [2.4333]
7 [2.6094]
8 [3.1381]
9 [3.5039]
10 [3.7755]
11 [4.0898]
12 [4.3341]
13 [4.4927]
14 [4.7398]
15 [5.0137]
16 [5.2615]
17 [5.6926]
18 [5.9739]
19 [6.4992]
20 [7.0184]
21 [7.7648]
22 [8.145]
23 [8.6091]
24 [8.9988]
train done
Epoch 59/1000 : Loss:0.3750, Valid loss: 0.4431, lr:0.001400 [0.5569] 1617.2223188877106
1 [0.3941]
2 [0.6885]
3 [1.0745]
4 [1.4508]
5 [1.8043]
6 [2.0165]
7 [2.3449]
8 [3.0714]
9 [3.2549]
10 [3.4813]
11 [4.0144]
12 [4.2555]
13 [4.6511]
14 [4.8798]
15 [5.3838]
16 [5.693]
17 [6.1323]
18 [6.6418]
19 [6.8705]
20 [7.7556]
21 [8.166]
22 [8.5415]
23 [8.808]
24 [9.0411]
train done
Epoch 60/1000 : Loss:0.3767, Valid loss: 0.3834, lr:0.001400 [0.6166] 1610.6759049892426
Model 60 saved.
1 [0.2386]
2 [0.6124]
3 [0.9554]
4 [1.2933]
5 [1.734]
6 [1.973]
7 [2.2485]
8 [2.5711]
9 [2.7506]
10 [3.2826]
11 [3.5917]
12 [3.8966]
13 [4.068]
14 [4.2623]
15 [4.5784]
16 [4.8487]
17 [5.5113]
18 [5.7863]
19 [6.0152]
20 [6.2705]
21 [6.5187]
22 [6.7898]
23 [7.0463]
24 [7.2978]
train done
Epoch 61/1000 : Loss:0.3041, Valid loss: 0.3938, lr:0.001400 [0.6062] 1616.9739398956299
1 [0.2358]
2 [0.5425]
3 [0.7734]
4 [0.965]
5 [1.1719]
6 [1.4911]
7 [1.7352]
8 [1.9392]
9 [2.2575]
10 [2.4647]
11 [3.0838]
12 [3.4206]
13 [3.6714]
14 [4.0192]
15 [4.4005]
16 [4.8854]
17 [5.0464]
18 [5.7881]
19 [6.0547]
20 [6.2844]
21 [6.5966]
22 [6.9311]
23 [7.1664]
24 [7.425]
train done
Epoch 62/1000 : Loss:0.3094, Valid loss: 0.3943, lr:0.001400 [0.6057] 1616.3292081356049
1 [0.1844]
2 [0.4693]
3 [0.6171]
4 [1.1382]
5 [1.724]
6 [2.1857]
7 [2.499]
8 [2.7385]
9 [2.9458]
10 [3.1569]
11 [3.3946]
12 [3.6795]
13 [3.917]
14 [4.2121]
15 [4.5185]
16 [4.7362]
17 [4.915]
18 [5.1175]
19 [5.4663]
20 [6.2951]
21 [6.5503]
22 [6.891]
23 [7.1384]
24 [7.4446]
train done
Epoch 63/1000 : Loss:0.3102, Valid loss: 0.3935, lr:0.001400 [0.6065] 1638.500935792923
1 [0.1682]
2 [0.5347]
3 [0.8108]
4 [1.1977]
5 [1.7403]
6 [1.9466]
7 [2.2306]
8 [2.452]
9 [2.9178]
10 [3.107]
11 [3.3697]
12 [3.8245]
13 [3.9865]
14 [4.3637]
15 [4.6145]
16 [4.7695]
17 [5.1737]
18 [5.3812]
19 [5.5716]
20 [5.9368]
21 [6.1846]
22 [6.4655]
23 [6.6855]
24 [6.9505]
train done
Epoch 64/1000 : Loss:0.2896, Valid loss: 0.4065, lr:0.001400 [0.5935] 1630.8104948997498
1 [0.6252]
2 [0.8881]
3 [1.2416]
4 [1.9561]
5 [2.3363]
6 [2.5695]
7 [2.7588]
8 [3.0545]
9 [3.4737]
10 [3.7467]
11 [3.9896]
12 [4.2538]
13 [4.6246]
14 [4.879]
15 [5.2851]
16 [5.4665]
17 [5.6818]
18 [5.8978]
19 [6.0903]
20 [6.6687]
21 [7.0311]
22 [7.2792]
23 [7.4907]
24 [7.7113]
train done
Epoch 65/1000 : Loss:0.3213, Valid loss: 0.3733, lr:0.001400 [0.6267] 1622.3070888519287
1 [0.3004]
2 [0.7101]
3 [0.9944]
4 [1.5052]
5 [1.8637]
6 [2.0579]
7 [2.4604]
8 [2.6455]
9 [2.9146]
10 [3.1546]
11 [3.4293]
12 [3.7088]
13 [3.8858]
14 [4.3659]
15 [4.7504]
16 [5.0367]
17 [5.3812]
18 [5.7057]
19 [5.863]
20 [6.0399]
21 [6.4736]
22 [6.6998]
23 [6.9713]
24 [7.1696]
train done
Epoch 66/1000 : Loss:0.2987, Valid loss: 0.3873, lr:0.001400 [0.6127] 1613.5149192810059
1 [0.3081]
2 [0.6508]
3 [0.8951]
4 [1.2666]
5 [2.0573]
6 [2.7935]
7 [3.136]
8 [3.6537]
9 [4.0379]
10 [4.4091]
11 [4.7658]
12 [5.1635]
13 [5.334]
14 [5.6237]
15 [5.9357]
16 [6.2894]
17 [6.8176]
18 [7.2591]
19 [7.5961]
20 [8.0047]
21 [8.3596]
22 [8.5548]
23 [8.8708]
24 [9.3236]
train done
Epoch 67/1000 : Loss:0.3885, Valid loss: 0.5417, lr:0.001400 [0.4583] 1637.746638059616
1 [0.483]
2 [0.8059]
3 [1.0473]
4 [1.3195]
5 [1.6565]
6 [2.0157]
7 [2.2211]
8 [2.5183]
9 [3.3926]
10 [3.6464]
11 [3.8694]
12 [4.0865]
13 [4.4272]
14 [4.6854]
15 [5.1257]
16 [5.6181]
17 [5.9499]
18 [6.2548]
19 [7.1714]
20 [7.6913]
21 [8.1362]
22 [8.5224]
23 [8.8247]
24 [9.2737]
train done
Epoch 68/1000 : Loss:0.3864, Valid loss: 0.5038, lr:0.001400 [0.4962] 1647.5990178585052
1 [0.4043]
2 [0.8917]
3 [1.4454]
4 [1.8739]
5 [2.4645]
6 [2.8966]
7 [3.125]
8 [3.4817]
9 [3.842]
10 [4.1124]
11 [4.4768]
12 [5.1654]
13 [5.5824]
14 [5.885]
15 [6.3882]
16 [6.6046]
17 [6.8348]
18 [7.0466]
19 [7.389]
20 [7.8527]
21 [8.0945]
22 [8.4531]
23 [9.0495]
24 [9.51]
train done
Epoch 69/1000 : Loss:0.3963, Valid loss: 0.3625, lr:0.001400 [0.6375] 1629.9585781097412
1 [0.2523]
2 [0.4839]
3 [0.7751]
4 [1.094]
5 [1.3566]
6 [1.79]
7 [2.051]
8 [2.2938]
9 [2.5496]
10 [2.7736]
11 [3.2066]
12 [3.5336]
13 [3.8515]
14 [4.1276]
15 [4.4293]
16 [4.7609]
17 [4.9674]
18 [5.365]
19 [5.9552]
20 [6.1776]
21 [6.8899]
22 [7.3847]
23 [7.7621]
24 [8.1961]
train done
Epoch 70/1000 : Loss:0.3415, Valid loss: 0.4017, lr:0.001400 [0.5983] 1652.6184408664703
Model 70 saved.
1 [0.2827]
2 [0.7272]
3 [1.2466]
4 [1.5742]
5 [1.9147]
6 [2.4936]
7 [2.8411]
8 [3.244]
9 [3.4953]
10 [3.7654]
11 [4.0453]
12 [4.3361]
13 [4.6066]
14 [4.9399]
15 [5.3158]
16 [5.511]
17 [5.9812]
18 [6.2379]
19 [6.7138]
20 [7.1159]
21 [7.3726]
22 [7.6454]
23 [7.9513]
24 [8.3467]
train done
Epoch 71/1000 : Loss:0.3478, Valid loss: 0.5062, lr:0.001400 [0.4938] 1613.9544749259949
1 [0.2567]
2 [0.641]
3 [1.0006]
4 [1.3381]
5 [1.6908]
6 [1.9792]
7 [2.3485]
8 [2.731]
9 [2.976]
10 [3.2769]
11 [3.5553]
12 [4.1384]
13 [4.2778]
14 [4.5336]
15 [4.7613]
16 [5.1152]
17 [5.3578]
18 [5.5167]
19 [5.8044]
20 [6.604]
21 [6.9724]
22 [7.2978]
23 [7.5627]
24 [8.0512]
train done
Epoch 72/1000 : Loss:0.3355, Valid loss: 0.3716, lr:0.001400 [0.6284] 1643.318689107895
1 [0.3025]
2 [0.6512]
3 [0.8374]
4 [1.1871]
5 [1.4462]
6 [1.9787]
7 [2.2442]
8 [2.588]
9 [2.9866]
10 [3.2193]
11 [3.5732]
12 [3.8801]
13 [4.3411]
14 [4.6832]
15 [4.8555]
16 [5.0443]
17 [5.2225]
18 [5.5736]
19 [5.7498]
20 [6.4305]
21 [6.8936]
22 [7.1344]
23 [7.3806]
24 [7.7728]
train done
Epoch 73/1000 : Loss:0.3239, Valid loss: 0.3804, lr:0.001400 [0.6196] 1700.3835368156433
1 [0.2919]
2 [0.512]
3 [0.8249]
4 [0.9948]
5 [1.3509]
6 [1.5577]
7 [1.7525]
8 [2.0518]
9 [2.7]
10 [3.2355]
11 [3.6778]
12 [4.1027]
13 [4.5257]
14 [4.9456]
15 [5.3647]
16 [5.8873]
17 [6.1649]
18 [6.4568]
19 [6.8086]
20 [7.1743]
21 [7.5999]
22 [7.8361]
23 [8.025]
24 [8.3712]
train done
Epoch 74/1000 : Loss:0.3488, Valid loss: 0.3931, lr:0.001400 [0.6069] 1685.258024930954
1 [0.5147]
2 [0.6923]
3 [0.9629]
4 [1.2519]
5 [1.6462]
6 [1.8789]
7 [2.0732]
8 [2.2742]
9 [2.4715]
10 [2.7525]
11 [3.3522]
12 [3.5662]
13 [3.8364]
14 [4.1308]
15 [4.3944]
16 [4.6004]
17 [4.7589]
18 [5.0744]
19 [5.4685]
20 [5.9429]
21 [6.1164]
22 [6.5308]
23 [7.108]
24 [7.3387]
train done
Epoch 75/1000 : Loss:0.3058, Valid loss: 0.3737, lr:0.001400 [0.6263] 1784.4518389701843
1 [0.2505]
2 [0.532]
3 [0.8207]
4 [1.5396]
5 [1.74]
6 [2.1234]
7 [2.3972]
8 [2.752]
9 [3.0781]
10 [3.3317]
11 [3.656]
12 [3.9897]
13 [4.2886]
14 [4.5767]
15 [4.8917]
16 [5.2474]
17 [5.4549]
18 [5.7143]
19 [6.0428]
20 [6.2852]
21 [6.5806]
22 [7.0135]
23 [7.592]
24 [8.0271]
train done
Epoch 76/1000 : Loss:0.3345, Valid loss: 0.3599, lr:0.001400 [0.6401] 1864.939889907837
1 [0.3512]
2 [0.7483]
3 [0.9209]
4 [1.2091]
5 [1.4739]
6 [1.7402]
7 [1.9652]
8 [2.5652]
9 [2.848]
10 [3.0544]
11 [3.3311]
12 [3.5136]
13 [3.7768]
14 [4.0465]
15 [4.2139]
16 [4.374]
17 [4.6243]
18 [4.9358]
19 [5.2116]
20 [5.9373]
21 [6.2804]
22 [6.4231]
23 [6.6105]
24 [7.0755]
train done
Epoch 77/1000 : Loss:0.2948, Valid loss: 0.3631, lr:0.001400 [0.6369] 1834.236879825592
1 [0.2614]
2 [0.5627]
3 [0.7233]
4 [1.1345]
5 [1.4277]
6 [2.0316]
7 [2.2524]
8 [2.6919]
9 [2.8961]
10 [3.0763]
11 [3.3151]
12 [3.5288]
13 [3.718]
14 [3.9678]
15 [4.3581]
16 [4.5517]
17 [5.1118]
18 [5.3703]
19 [5.5042]
20 [5.6838]
21 [5.9477]
22 [6.3546]
23 [6.5423]
24 [7.2112]
train done
Epoch 78/1000 : Loss:0.3005, Valid loss: 0.3664, lr:0.001400 [0.6336] 1615.7470750808716
1 [0.4521]
2 [0.614]
3 [0.9323]
4 [1.1767]
5 [1.4927]
6 [1.7895]
7 [2.3991]
8 [2.5965]
9 [2.9522]
10 [3.1502]
11 [3.3324]
12 [3.6806]
13 [3.8007]
14 [4.2904]
15 [4.668]
16 [4.8808]
17 [5.1369]
18 [5.4196]
19 [5.5994]
20 [5.8377]
21 [6.6692]
22 [6.9579]
23 [7.4584]
24 [7.8148]
train done
Epoch 79/1000 : Loss:0.3256, Valid loss: 0.3683, lr:0.001400 [0.6317] 1637.8556380271912
1 [0.3012]
2 [0.6236]
3 [0.9441]
4 [1.371]
5 [1.5578]
6 [1.7907]
7 [2.0484]
8 [2.2418]
9 [2.765]
10 [2.8754]
11 [3.1363]
12 [3.4891]
13 [3.7761]
14 [4.1209]
15 [4.4921]
16 [4.7517]
17 [5.1666]
18 [5.424]
19 [5.9077]
20 [6.3491]
21 [6.6333]
22 [6.8581]
23 [7.1248]
24 [7.7608]
train done
Epoch 80/1000 : Loss:0.3234, Valid loss: 0.4418, lr:0.001400 [0.5582] 1617.8687679767609
Model 80 saved.
1 [0.2517]
2 [0.4914]
3 [0.7303]
4 [1.3724]
5 [1.6249]
6 [2.0677]
7 [2.4462]
8 [2.7463]
9 [2.9816]
10 [3.5175]
11 [4.4574]
12 [4.7957]
13 [5.0817]
14 [5.4901]
15 [5.9555]
16 [6.1734]
17 [6.5054]
18 [6.86]
19 [7.3047]
20 [7.5918]
21 [7.8114]
22 [8.0143]
23 [8.709]
24 [9.0957]
train done
Epoch 81/1000 : Loss:0.3790, Valid loss: 0.3896, lr:0.001400 [0.6104] 1648.0271949768066
1 [0.2366]
2 [0.4378]
3 [0.842]
4 [1.1472]
5 [1.3239]
6 [1.5892]
7 [1.8004]
8 [2.0441]
9 [2.2113]
10 [2.7901]
11 [3.0578]
12 [3.2301]
13 [3.7807]
14 [4.3832]
15 [4.7818]
16 [5.068]
17 [5.4174]
18 [5.7215]
19 [6.004]
20 [6.2618]
21 [6.5564]
22 [6.7996]
23 [7.1035]
24 [7.6994]
train done
Epoch 82/1000 : Loss:0.3208, Valid loss: 0.3513, lr:0.001400 [0.6487] 1602.355536699295
1 [0.2445]
2 [0.7213]
3 [1.1321]
4 [1.3329]
5 [1.545]
6 [1.8638]
7 [2.0417]
8 [2.2974]
9 [2.492]
10 [2.7511]
11 [3.0606]
12 [3.3138]
13 [3.6811]
14 [3.9164]
15 [4.2027]
16 [4.4432]
17 [4.7289]
18 [4.9013]
19 [5.2273]
20 [5.5091]
21 [5.7018]
22 [5.9948]
23 [6.3341]
24 [6.4917]
train done
Epoch 83/1000 : Loss:0.2705, Valid loss: 0.3346, lr:0.001400 [0.6654] 1631.9393150806427
1 [0.1441]
2 [0.6038]
3 [0.8397]
4 [1.4125]
5 [1.6613]
6 [1.9418]
7 [2.6035]
8 [2.9194]
9 [3.1948]
10 [3.8232]
11 [4.0762]
12 [4.265]
13 [4.5054]
14 [4.9419]
15 [5.2305]
16 [5.8993]
17 [6.4078]
18 [6.6561]
19 [6.9452]
20 [7.1666]
21 [7.4405]
22 [7.7485]
23 [8.3353]
24 [8.7022]
train done
Epoch 84/1000 : Loss:0.3626, Valid loss: 0.3731, lr:0.001400 [0.6269] 1643.4534001350403
1 [0.2383]
2 [0.4657]
3 [0.8039]
4 [1.0012]
5 [1.1416]
6 [1.5351]
7 [2.3143]
8 [2.5142]
9 [2.6984]
10 [2.8577]
11 [3.1768]
12 [3.3659]
13 [3.627]
14 [3.8113]
15 [4.0478]
16 [4.2919]
17 [4.6193]
18 [4.8132]
19 [4.977]
20 [5.225]
21 [5.6425]
22 [6.0248]
23 [6.6539]
24 [6.9791]
train done
Epoch 85/1000 : Loss:0.2908, Valid loss: 0.3566, lr:0.001400 [0.6434] 1664.4255380630493
1 [0.1889]
2 [0.4713]
3 [0.7567]
4 [1.1355]
5 [1.4918]
6 [1.9854]
7 [2.2154]
8 [2.6523]
9 [2.8625]
10 [3.1881]
11 [3.7421]
12 [3.98]
13 [4.3221]
14 [4.5253]
15 [4.7681]
16 [5.0293]
17 [5.3974]
18 [5.6704]
19 [5.9256]
20 [6.1509]
21 [6.3583]
22 [6.6266]
23 [7.0622]
24 [7.3089]
train done
Epoch 86/1000 : Loss:0.3045, Valid loss: 0.3288, lr:0.001400 [0.6712] 1833.6906530857086
1 [0.2656]
2 [0.4223]
3 [0.7337]
4 [0.9381]
5 [1.2685]
6 [1.5124]
7 [1.7134]
8 [2.2405]
9 [2.6118]
10 [2.8408]
11 [3.1048]
12 [3.5735]
13 [4.0218]
14 [4.1995]
15 [4.3868]
16 [4.791]
17 [5.0701]
18 [5.2913]
19 [5.5443]
20 [5.894]
21 [6.3298]
22 [6.9239]
23 [7.0978]
24 [7.2879]
train done
Epoch 87/1000 : Loss:0.3037, Valid loss: 0.3436, lr:0.001400 [0.6564] 1976.853686094284
1 [0.4676]
2 [0.6892]
3 [1.0653]
4 [1.0655]
5 [1.3128]
6 [1.5169]
7 [1.7531]
8 [2.1807]
9 [2.3804]
10 [2.6638]
11 [3.4247]
12 [3.8965]
13 [4.2711]
14 [4.4087]
15 [4.7483]
16 [5.0141]
17 [5.859]
18 [6.2693]
19 [6.4316]
20 [6.8352]
21 [7.032]
22 [7.4384]
23 [7.6706]
24 [7.9067]
train done
Epoch 88/1000 : Loss:0.3294, Valid loss: 0.3497, lr:0.001400 [0.6503] 1746.9935188293457
1 [0.2899]
2 [0.599]
3 [0.8345]
4 [1.1452]
5 [1.4622]
6 [1.7015]
7 [2.029]
8 [2.3116]
9 [2.5733]
10 [2.7626]
11 [3.0071]
12 [3.3301]
13 [3.6577]
14 [3.9193]
15 [4.0742]
16 [4.272]
17 [4.6738]
18 [5.1476]
19 [5.7333]
20 [6.013]
21 [6.3695]
22 [6.6921]
23 [6.9121]
24 [7.0503]
train done
Epoch 89/1000 : Loss:0.2938, Valid loss: 0.3551, lr:0.001400 [0.6449] 1681.9820988178253
1 [0.5202]
2 [0.7723]
3 [1.0476]
4 [1.3661]
5 [1.4706]
6 [1.6813]
7 [2.6811]
8 [3.1063]
9 [3.3708]
10 [3.5893]
11 [4.0334]
12 [4.2545]
13 [4.4509]
14 [4.6404]
15 [4.8292]
16 [5.1959]
17 [5.3327]
18 [5.6219]
19 [5.9601]
20 [6.6387]
21 [6.8661]
22 [7.0254]
23 [7.2139]
24 [7.4729]
train done
Epoch 90/1000 : Loss:0.3114, Valid loss: 0.3632, lr:0.001400 [0.6368] 1625.4797778129578
Model 90 saved.
1 [0.4366]
2 [0.6241]
3 [0.9284]
4 [1.1887]
5 [1.4098]
6 [1.6102]
7 [2.1047]
8 [2.4209]
9 [2.705]
10 [2.9389]
11 [3.1911]
12 [3.3574]
13 [3.484]
14 [3.7573]
15 [4.0287]
16 [4.2223]
17 [4.4809]
18 [4.6571]
19 [4.9177]
20 [5.2453]
21 [5.5637]
22 [5.7266]
23 [5.8946]
24 [6.1188]
train done
Epoch 91/1000 : Loss:0.2549, Valid loss: 0.3521, lr:0.001400 [0.6479] 1618.2581770420074
1 [0.286]
2 [0.4792]
3 [0.7475]
4 [1.6215]
5 [2.2001]
6 [2.4075]
7 [2.5925]
8 [2.7846]
9 [3.0433]
10 [3.3971]
11 [3.677]
12 [4.0657]
13 [4.3038]
14 [4.4261]
15 [5.242]
16 [5.6303]
17 [5.8103]
18 [6.5493]
19 [6.7363]
20 [7.2254]
21 [7.3803]
22 [7.827]
23 [8.1548]
24 [8.7648]
train done
Epoch 92/1000 : Loss:0.3652, Valid loss: 0.4491, lr:0.001400 [0.5509] 1618.0599689483643
1 [0.3578]
2 [0.8107]
3 [1.0214]
4 [1.4227]
5 [1.6531]
6 [1.8369]
7 [2.0654]
8 [2.2539]
9 [2.4694]
10 [3.0322]
11 [3.548]
12 [3.6833]
13 [3.8786]
14 [4.1242]
15 [4.4106]
16 [4.8588]
17 [5.1296]
18 [5.5307]
19 [5.8675]
20 [6.1668]
21 [6.3671]
22 [6.7345]
23 [7.0717]
24 [7.3338]
train done
Epoch 93/1000 : Loss:0.3056, Valid loss: 0.3395, lr:0.001400 [0.6605] 1667.2161836624146
1 [0.1787]
2 [0.394]
3 [0.649]
4 [0.8355]
5 [1.0436]
6 [1.399]
7 [1.5922]
8 [1.8015]
9 [2.0286]
10 [2.3866]
11 [2.9288]
12 [3.2978]
13 [3.6205]
14 [3.9831]
15 [4.3363]
16 [4.9526]
17 [5.2453]
18 [5.8219]
19 [6.0829]
20 [6.3092]
21 [7.0005]
22 [7.3279]
23 [7.8824]
24 [8.386]
train done
Epoch 94/1000 : Loss:0.3494, Valid loss: 0.4051, lr:0.001400 [0.5949] 1765.738710641861
1 [0.243]
2 [0.5131]
3 [0.7625]
4 [1.0276]
5 [1.3193]
6 [1.5889]
7 [1.863]
8 [2.267]
9 [2.5609]
10 [3.0084]
11 [3.1853]
12 [3.3759]
13 [3.6391]
14 [3.7903]
15 [4.2333]
16 [4.4815]
17 [4.7229]
18 [5.352]
19 [5.6278]
20 [6.0291]
21 [6.3146]
22 [6.5316]
23 [6.5317]
24 [6.7821]
train done
Epoch 95/1000 : Loss:0.2826, Valid loss: 0.4135, lr:0.001400 [0.5865] 1828.2364132404327
1 [0.4065]
2 [0.5701]
3 [0.7093]
4 [1.3019]
5 [1.6019]
6 [1.905]
7 [2.4907]
8 [2.7364]
9 [2.9657]
10 [3.1698]
11 [3.6126]
12 [4.038]
13 [4.2469]
14 [4.476]
15 [4.6702]
16 [4.8643]
17 [5.1635]
18 [5.4441]
19 [5.6308]
20 [5.8364]
21 [6.0437]
22 [6.5338]
23 [6.6786]
24 [7.0966]
train done
Epoch 96/1000 : Loss:0.2957, Valid loss: 0.3358, lr:0.001400 [0.6642] 1820.8021969795227
1 [0.5829]
2 [0.7859]
3 [0.9771]
4 [1.1015]
5 [1.3537]
6 [1.7459]
7 [2.0859]
8 [2.5036]
9 [2.6972]
10 [3.1046]
11 [3.3241]
12 [3.5488]
13 [3.7843]
14 [4.0213]
15 [4.8243]
16 [5.0563]
17 [5.3991]
18 [5.5628]
19 [5.8106]
20 [6.1513]
21 [6.5728]
22 [6.9637]
23 [7.2818]
24 [7.6845]
train done
Epoch 97/1000 : Loss:0.3202, Valid loss: 0.3847, lr:0.001400 [0.6153] 1945.283066034317
1 [0.3816]
2 [0.8802]
3 [1.3382]
4 [1.5213]
5 [1.7482]
6 [2.0046]
7 [2.2069]
8 [2.3596]
9 [2.6942]
10 [3.2587]
11 [3.5137]
12 [3.9328]
13 [4.2269]
14 [4.3999]
15 [4.5765]
16 [4.7921]
17 [4.9775]
18 [5.3064]
19 [5.6597]
20 [5.8817]
21 [6.438]
22 [6.8255]
23 [7.1695]
24 [7.4037]
train done
Epoch 98/1000 : Loss:0.3085, Valid loss: 0.3886, lr:0.001400 [0.6114] 1953.3662838935852
1 [0.6705]
2 [1.0959]
3 [1.3753]
4 [1.5879]
5 [1.8918]
6 [2.0595]
7 [2.341]
8 [2.6728]
9 [2.8451]
10 [3.0215]
11 [3.2868]
12 [3.4725]
13 [3.9055]
14 [4.331]
15 [4.6187]
16 [4.8456]
17 [5.1638]
18 [5.7091]
19 [6.1617]
20 [6.4292]
21 [6.6724]
22 [6.8197]
23 [7.0607]
24 [7.2995]
train done
Epoch 99/1000 : Loss:0.3041, Valid loss: 0.3582, lr:0.001400 [0.6418] 1920.556824207306
1 [0.5049]
2 [0.8311]
3 [1.0365]
4 [1.3578]
5 [1.5268]
6 [1.8812]
7 [2.1663]
8 [2.3166]
9 [2.4692]
10 [2.7463]
11 [2.8875]
12 [3.2659]
13 [3.6408]
14 [3.8316]
15 [4.1704]
16 [4.4603]
17 [4.712]
18 [4.9357]
19 [5.2221]
20 [5.424]
21 [5.8799]
22 [6.0833]
23 [6.2976]
24 [6.4845]
train done
Epoch 100/1000 : Loss:0.2702, Valid loss: 0.3419, lr:0.001400 [0.6581] 1877.8241498470306
Model 100 saved.
1 [0.3176]
2 [0.6262]
3 [0.9397]
4 [1.6236]
5 [1.8902]
6 [2.3498]
7 [2.6122]
8 [2.9377]
9 [3.2211]
10 [3.6492]
11 [3.9282]
12 [4.1828]
13 [4.3772]
14 [4.6626]
15 [5.3298]
16 [5.4949]
17 [5.7087]
18 [6.1091]
19 [6.2819]
20 [6.4134]
21 [6.6085]
22 [6.7764]
23 [7.0577]
24 [7.2947]
train done
Epoch 101/1000 : Loss:0.3039, Valid loss: 0.3566, lr:0.000980 [0.6434] 1919.4993209838867
1 [0.3939]
2 [0.6205]
3 [0.863]
4 [1.2854]
5 [1.4357]
6 [1.6115]
7 [1.8162]
8 [2.397]
9 [2.6765]
10 [2.8499]
11 [3.0159]
12 [3.2472]
13 [3.7544]
14 [3.9991]
15 [4.2032]
16 [4.3735]
17 [4.7183]
18 [4.913]
19 [5.0831]
20 [5.3073]
21 [5.6275]
22 [5.6277]
23 [5.8445]
24 [6.1837]
train done
Epoch 102/1000 : Loss:0.2577, Valid loss: 0.3353, lr:0.000980 [0.6647] 1988.6979372501373
1 [0.2855]
2 [0.5825]
3 [1.0207]
4 [1.1812]
5 [1.3244]
6 [1.5342]
7 [1.6913]
8 [1.9464]
9 [2.1201]
10 [2.4231]
11 [3.1113]
12 [3.3521]
13 [3.5404]
14 [3.6524]
15 [3.8842]
16 [4.1954]
17 [4.3644]
18 [4.5079]
19 [4.7521]
20 [4.9329]
21 [5.2337]
22 [5.613]
23 [5.8504]
24 [6.5309]
train done
Epoch 103/1000 : Loss:0.2721, Valid loss: 0.3648, lr:0.000980 [0.6352] 1868.6133460998535
1 [0.2372]
2 [0.3757]
3 [0.6154]
4 [0.9382]
5 [1.1009]
6 [1.3558]
7 [1.628]
8 [1.95]
9 [2.3622]
10 [2.5435]
11 [2.9947]
12 [3.3787]
13 [3.4907]
14 [3.5971]
15 [4.2185]
16 [4.4188]
17 [4.5911]
18 [4.9877]
19 [5.1918]
20 [5.4745]
21 [5.685]
22 [5.8833]
23 [6.0439]
24 [6.2468]
train done
Epoch 104/1000 : Loss:0.2603, Valid loss: 0.3377, lr:0.000980 [0.6623] 1640.654510974884
1 [0.1127]
2 [0.3489]
3 [0.5313]
4 [0.6886]
5 [1.3302]
6 [1.7808]
7 [2.0028]
8 [2.3833]
9 [2.6646]
10 [2.8518]
11 [3.1904]
12 [3.3439]
13 [3.5503]
14 [4.0631]
15 [4.3412]
16 [4.5568]
17 [4.6823]
18 [4.8236]
19 [4.97]
20 [5.1018]
21 [5.7784]
22 [5.9801]
23 [6.1984]
24 [6.5798]
train done
Epoch 105/1000 : Loss:0.2742, Valid loss: 0.3557, lr:0.000980 [0.6443] 1633.8386900424957
1 [0.2445]
2 [0.5313]
3 [0.7259]
4 [1.1363]
5 [1.6543]
6 [1.8716]
7 [2.1821]
8 [2.4218]
9 [2.7812]
10 [3.1025]
11 [3.4932]
12 [3.7141]
13 [3.9359]
14 [4.2593]
15 [4.5616]
16 [4.8503]
17 [5.1097]
18 [5.5024]
19 [5.7869]
20 [6.0726]
21 [6.292]
22 [6.4295]
23 [6.6884]
24 [6.8]
train done
Epoch 106/1000 : Loss:0.2833, Valid loss: 0.3157, lr:0.000980 [0.6843] 1619.4344599246979
1 [0.211]
2 [0.4353]
3 [0.7881]
4 [1.2501]
5 [1.6074]
6 [1.7956]
7 [1.9106]
8 [2.0762]
9 [2.3766]
10 [3.036]
11 [3.3795]
12 [3.793]
13 [4.124]
14 [4.3973]
15 [4.7907]
16 [4.9914]
17 [5.1912]
18 [5.5065]
19 [5.7781]
20 [5.9443]
21 [6.1161]
22 [6.5428]
23 [6.729]
24 [6.9269]
train done
Epoch 107/1000 : Loss:0.2886, Valid loss: 0.3243, lr:0.000980 [0.6757] 1612.521579027176
1 [0.2312]
2 [0.4096]
3 [1.1073]
4 [1.2439]
5 [1.5703]
6 [1.7188]
7 [1.8691]
8 [2.1661]
9 [2.5072]
10 [2.8439]
11 [3.019]
12 [3.1544]
13 [3.7303]
14 [4.1129]
15 [4.5042]
16 [4.8471]
17 [5.1271]
18 [5.3176]
19 [5.4288]
20 [5.9673]
21 [6.2184]
22 [6.4487]
23 [6.7161]
24 [6.9602]
train done
Epoch 108/1000 : Loss:0.2900, Valid loss: 0.3480, lr:0.000980 [0.652] 1689.5787358283997
1 [0.2598]
2 [0.4491]
3 [0.6606]
4 [0.9374]
5 [1.1429]
6 [1.5503]
7 [1.7791]
8 [2.0145]
9 [2.2119]
10 [2.5021]
11 [2.6687]
12 [3.1408]
13 [3.2734]
14 [3.7821]
15 [4.1293]
16 [4.2912]
17 [4.6147]
18 [4.8122]
19 [5.0374]
20 [5.336]
21 [5.6822]
22 [5.9103]
23 [6.3463]
24 [6.5609]
train done
Epoch 109/1000 : Loss:0.2734, Valid loss: 0.3320, lr:0.000980 [0.668] 1616.2033169269562
1 [0.2165]
2 [0.4709]
3 [0.7632]
4 [1.0851]
5 [1.428]
6 [1.7278]
7 [2.0958]
8 [2.2835]
9 [2.7307]
10 [2.8988]
11 [3.2916]
12 [3.6184]
13 [3.7759]
14 [3.9859]
15 [4.1877]
16 [4.5365]
17 [4.7974]
18 [4.9449]
19 [5.1613]
20 [5.4705]
21 [5.6622]
22 [5.7988]
23 [6.0466]
24 [6.2589]
train done
Epoch 110/1000 : Loss:0.2608, Valid loss: 0.3300, lr:0.000980 [0.67] 1618.5575993061066
Model 110 saved.
1 [0.2094]
2 [0.5174]
3 [0.681]
4 [1.0125]
5 [1.1695]
6 [1.4027]
7 [1.917]
8 [2.2514]
9 [2.426]
10 [2.6307]
11 [3.3568]
12 [3.5879]
13 [3.7539]
14 [4.0211]
15 [4.2715]
16 [4.4797]
17 [4.7564]
18 [4.8988]
19 [5.1876]
20 [5.3695]
21 [5.5795]
22 [5.8883]
23 [6.0181]
24 [6.2131]
train done
Epoch 111/1000 : Loss:0.2589, Valid loss: 0.3286, lr:0.000980 [0.6714] 1626.1735742092133
1 [0.1667]
2 [0.6471]
3 [0.8302]
4 [1.2683]
5 [1.5397]
6 [1.7091]
7 [1.8896]
8 [2.2187]
9 [2.5451]
10 [2.6984]
11 [3.2223]
12 [3.4298]
13 [3.7346]
14 [4.112]
15 [4.2929]
16 [4.5768]
17 [4.8186]
18 [4.9522]
19 [5.1738]
20 [5.425]
21 [5.8124]
22 [6.004]
23 [6.3064]
24 [6.4897]
train done
Epoch 112/1000 : Loss:0.2704, Valid loss: 0.3179, lr:0.000980 [0.6821] 1637.3677208423615
1 [0.1876]
2 [0.3949]
3 [0.6313]
4 [0.7918]
5 [1.3894]
6 [1.5707]
7 [1.8366]
8 [2.1359]
9 [2.2657]
10 [2.6723]
11 [2.8473]
12 [3.0144]
13 [3.1635]
14 [3.3982]
15 [3.5288]
16 [3.8599]
17 [4.0628]
18 [4.4842]
19 [4.6247]
20 [5.064]
21 [5.4016]
22 [5.5756]
23 [5.7182]
24 [5.93]
train done
Epoch 113/1000 : Loss:0.2471, Valid loss: 0.3347, lr:0.000980 [0.6653] 1613.0411257743835
1 [0.3976]
2 [1.0684]
3 [1.3166]
4 [1.603]
5 [1.9786]
6 [2.1492]
7 [3.0225]
8 [3.2032]
9 [3.4604]
10 [3.5816]
11 [3.8424]
12 [4.0604]
13 [4.3499]
14 [4.5948]
15 [4.8132]
16 [5.0272]
17 [5.334]
18 [5.5661]
19 [5.7866]
20 [5.967]
21 [6.6106]
22 [6.8457]
23 [7.1479]
24 [7.4281]
train done
Epoch 114/1000 : Loss:0.3095, Valid loss: 0.3885, lr:0.000980 [0.6115] 1616.5342290401459
1 [0.1942]
2 [0.6454]
3 [1.0718]
4 [1.334]
5 [1.9483]
6 [2.2146]
7 [2.6098]
8 [2.892]
9 [3.3515]
10 [3.5317]
11 [3.7186]
12 [4.0184]
13 [4.2408]
14 [4.4742]
15 [4.6492]
16 [5.0932]
17 [5.228]
18 [5.5882]
19 [5.8353]
20 [6.144]
21 [6.4571]
22 [6.7069]
23 [6.9183]
24 [7.1886]
train done
Epoch 115/1000 : Loss:0.2995, Valid loss: 0.3483, lr:0.000980 [0.6517] 1611.7367222309113
1 [0.2325]
2 [0.7157]
3 [1.0531]
4 [1.2642]
5 [1.5234]
6 [1.7009]
7 [1.9662]
8 [2.1893]
9 [2.4218]
10 [2.8129]
11 [3.0606]
12 [3.4865]
13 [3.6441]
14 [3.8217]
15 [4.0089]
16 [4.3003]
17 [4.4729]
18 [4.6255]
19 [4.7964]
20 [5.0468]
21 [5.2058]
22 [5.4166]
23 [5.6872]
24 [5.8699]
train done
Epoch 116/1000 : Loss:0.2446, Valid loss: 0.3609, lr:0.000980 [0.6391] 1610.667296886444
1 [0.3477]
2 [0.5108]
3 [0.7949]
4 [1.3018]
5 [1.3019]
6 [1.5796]
7 [1.5797]
8 [1.8371]
9 [2.2665]
10 [2.4752]
11 [3.138]
12 [3.293]
13 [3.5346]
14 [3.816]
15 [3.9837]
16 [4.2555]
17 [4.4804]
18 [4.8131]
19 [5.1151]
20 [5.3266]
21 [5.4272]
22 [5.7641]
23 [6.0861]
24 [6.4436]
train done
Epoch 117/1000 : Loss:0.2685, Valid loss: 0.3452, lr:0.000980 [0.6548] 1615.230319738388
1 [0.2495]
2 [0.4042]
3 [0.8178]
4 [1.0265]
5 [1.5769]
6 [1.9171]
7 [2.18]
8 [2.381]
9 [2.7417]
10 [2.9718]
11 [3.4709]
12 [3.6139]
13 [3.8564]
14 [4.0808]
15 [4.4899]
16 [4.8995]
17 [5.1819]
18 [5.4837]
19 [5.7724]
20 [6.0156]
21 [6.4114]
22 [7.0374]
23 [7.2017]
24 [7.3414]
train done
Epoch 118/1000 : Loss:0.3059, Valid loss: 0.3286, lr:0.000980 [0.6714] 1614.4906780719757
1 [0.4134]
2 [0.5364]
3 [1.0496]
4 [1.2113]
5 [1.4304]
6 [1.589]
7 [2.2215]
8 [3.2124]
9 [3.4358]
10 [3.7766]
11 [4.0609]
12 [4.2619]
13 [4.8915]
14 [5.1143]
15 [5.443]
16 [5.5845]
17 [5.914]
18 [6.1092]
19 [6.3933]
20 [6.649]
21 [6.7939]
22 [7.0451]
23 [7.1438]
24 [7.3687]
train done
Epoch 119/1000 : Loss:0.3070, Valid loss: 0.3269, lr:0.000980 [0.6731] 1616.4843442440033
1 [0.2524]
2 [0.4475]
3 [0.6759]
4 [0.7799]
5 [1.0119]
6 [1.3611]
7 [1.47]
8 [1.669]
9 [2.121]
10 [2.433]
11 [3.0733]
12 [3.322]
13 [3.5771]
14 [3.8154]
15 [4.0726]
16 [4.3363]
17 [4.5691]
18 [4.9371]
19 [5.2635]
20 [5.4282]
21 [5.6345]
22 [5.8685]
23 [6.2681]
24 [6.5382]
train done
Epoch 120/1000 : Loss:0.2724, Valid loss: 0.3438, lr:0.000980 [0.6562] 1607.553721666336
Model 120 saved.
1 [0.4114]
2 [0.5234]
3 [0.7071]
4 [0.8961]
5 [1.1926]
6 [1.3717]
7 [1.4864]
8 [1.6641]
9 [1.899]
10 [2.2094]
11 [2.5312]
12 [2.9476]
13 [3.2169]
14 [3.3693]
15 [3.667]
16 [3.9352]
17 [4.2841]
18 [4.5703]
19 [4.7417]
20 [4.9078]
21 [5.1023]
22 [5.3541]
23 [5.5369]
24 [5.7884]
train done
Epoch 121/1000 : Loss:0.2412, Valid loss: 0.3641, lr:0.000980 [0.6359] 1624.0390689373016
1 [0.3331]
2 [0.5586]
3 [0.739]
4 [0.9516]
5 [1.2211]
6 [1.3752]
7 [1.6471]
8 [1.8855]
9 [2.1308]
10 [2.3175]
11 [2.4523]
12 [2.6685]
13 [2.7898]
14 [2.9397]
15 [3.2129]
16 [3.3334]
17 [4.1268]
18 [4.4197]
19 [4.6026]
20 [4.8722]
21 [5.0073]
22 [5.2574]
23 [5.3938]
24 [5.6396]
train done
Epoch 122/1000 : Loss:0.2350, Valid loss: 0.3200, lr:0.000980 [0.68] 1724.7822749614716
1 [0.1279]
2 [0.3821]
3 [0.6482]
4 [0.8399]
5 [1.0146]
6 [1.2011]
7 [1.4126]
8 [1.6224]
9 [1.9442]
10 [2.0695]
11 [2.3417]
12 [2.6123]
13 [2.8094]
14 [2.9321]
15 [3.1785]
16 [3.4672]
17 [3.7891]
18 [4.0085]
19 [4.1664]
20 [4.3391]
21 [4.5755]
22 [4.759]
23 [5.0122]
24 [5.3521]
train done
Epoch 123/1000 : Loss:0.2230, Valid loss: 0.3732, lr:0.000980 [0.6268] 3669.103709936142
1 [0.3626]
2 [0.5728]
3 [0.8111]
4 [1.0645]
5 [1.3868]
6 [1.5826]
7 [1.9193]
8 [2.2047]
9 [2.3338]
10 [2.507]
11 [2.9687]
12 [3.2138]
13 [3.5097]
14 [4.0512]
15 [4.2224]
16 [4.4667]
17 [4.8541]
18 [4.9729]
19 [5.143]
20 [5.5125]
21 [5.8625]
22 [6.2463]
23 [6.4038]
24 [6.5894]
train done
Epoch 124/1000 : Loss:0.2746, Valid loss: 0.3314, lr:0.000980 [0.6686] 1897.6330897808075
1 [0.3292]
2 [0.4534]
3 [0.6557]
4 [0.869]
5 [1.1724]
6 [1.3917]
7 [1.9566]
8 [2.2542]
9 [2.7358]
10 [3.2966]
11 [3.7048]
12 [3.8882]
13 [4.2407]
14 [4.4876]
15 [4.7295]
16 [5.0672]
17 [5.4276]
18 [5.7123]
19 [5.9028]
20 [6.2013]
21 [6.4038]
22 [6.7416]
23 [7.3274]
24 [7.5131]
train done
Epoch 125/1000 : Loss:0.3130, Valid loss: 0.4282, lr:0.000980 [0.5718] 1608.28111577034
1 [0.2901]
2 [0.4825]
3 [0.6974]
4 [0.9296]
5 [1.1998]
6 [1.4242]
7 [1.5653]
8 [2.0242]
9 [2.5796]
10 [2.984]
11 [3.3775]
12 [3.9106]
13 [4.209]
14 [4.4722]
15 [4.8862]
16 [5.1781]
17 [5.3238]
18 [5.5956]
19 [5.8559]
20 [6.5925]
21 [6.905]
22 [7.0637]
23 [7.3097]
24 [7.5026]
train done
Epoch 126/1000 : Loss:0.3126, Valid loss: 0.3677, lr:0.000980 [0.6323] 1617.654932975769
1 [0.2817]
2 [0.6442]
3 [0.9615]
4 [1.48]
5 [1.7186]
6 [1.9302]
7 [2.2699]
8 [2.5344]
9 [2.7435]
10 [2.9089]
11 [3.3195]
12 [3.6288]
13 [4.2533]
14 [4.5647]
15 [5.0219]
16 [5.694]
17 [5.9054]
18 [6.1813]
19 [6.3862]
20 [6.6562]
21 [6.9809]
22 [7.1886]
23 [7.4714]
24 [7.6155]
train done
Epoch 127/1000 : Loss:0.3173, Valid loss: 0.3471, lr:0.000980 [0.6529] 1630.8121888637543
1 [0.4203]
2 [0.6672]
3 [0.9251]
4 [1.0802]
5 [1.2781]
6 [1.5359]
7 [1.7727]
8 [2.0523]
9 [2.2168]
10 [2.5272]
11 [2.7306]
12 [2.8736]
13 [3.1381]
14 [3.3626]
15 [3.5624]
16 [3.7993]
17 [3.9842]
18 [4.1762]
19 [4.3926]
20 [4.9458]
21 [5.1211]
22 [5.5492]
23 [5.7601]
24 [6.138]
train done
Epoch 128/1000 : Loss:0.2557, Valid loss: 0.3658, lr:0.000980 [0.6342] 1622.5098249912262
1 [0.1934]
2 [0.3798]
3 [0.5275]
4 [0.6745]
5 [0.8323]
6 [1.0327]
7 [1.2095]
8 [1.3003]
9 [1.7527]
10 [1.9095]
11 [2.1124]
12 [2.4333]
13 [2.7677]
14 [2.9464]
15 [3.2162]
16 [3.5606]
17 [3.8154]
18 [4.0169]
19 [4.288]
20 [4.4421]
21 [4.9409]
22 [5.2162]
23 [5.5194]
24 [5.8625]
train done
Epoch 129/1000 : Loss:0.2443, Valid loss: 0.3223, lr:0.000980 [0.6777] 1618.7939929962158
1 [0.2252]
2 [0.4393]
3 [0.6119]
4 [1.0169]
5 [1.4897]
6 [1.9285]
7 [2.1919]
8 [2.3696]
9 [2.6358]
10 [2.9106]
11 [3.2888]
12 [3.7365]
13 [4.3108]
14 [4.6746]
15 [5.0303]
16 [5.2999]
17 [5.9259]
18 [6.1824]
19 [6.3348]
20 [6.5238]
21 [6.68]
22 [6.9921]
23 [7.2232]
24 [7.3972]
train done
Epoch 130/1000 : Loss:0.3082, Valid loss: 0.3434, lr:0.000980 [0.6566] 1626.8650541305542
Model 130 saved.
1 [0.2028]
2 [0.5745]
3 [0.966]
4 [1.2296]
5 [1.4085]
6 [1.546]
7 [1.6428]
8 [1.8996]
9 [2.0762]
10 [2.4131]
11 [2.8929]
12 [3.0889]
13 [3.3658]
14 [3.5548]
15 [3.9382]
16 [4.5125]
17 [4.8085]
18 [5.141]
19 [5.338]
20 [5.4739]
21 [5.7104]
22 [5.9086]
23 [6.4242]
24 [6.5591]
train done
Epoch 131/1000 : Loss:0.2733, Valid loss: 0.3386, lr:0.000980 [0.6614] 1617.3043749332428
1 [0.308]
2 [0.5864]
3 [0.8378]
4 [1.0261]
5 [1.3558]
6 [1.8089]
7 [2.0257]
8 [2.2486]
9 [2.4905]
10 [2.7373]
11 [3.1587]
12 [3.3122]
13 [3.843]
14 [3.9799]
15 [4.3033]
16 [4.5023]
17 [4.6273]
18 [4.8406]
19 [5.3566]
20 [5.6379]
21 [5.8355]
22 [6.0545]
23 [6.342]
24 [6.558]
train done
Epoch 132/1000 : Loss:0.2733, Valid loss: 0.3414, lr:0.000980 [0.6586] 1633.0316619873047
1 [0.1768]
2 [0.4314]
3 [0.723]
4 [0.9086]
5 [1.1628]
6 [1.4314]
7 [1.7478]
8 [2.1618]
9 [2.4265]
10 [2.5923]
11 [2.8008]
12 [3.1505]
13 [3.407]
14 [3.9908]
15 [4.134]
16 [4.7574]
17 [4.9246]
18 [5.154]
19 [5.2685]
20 [5.4571]
21 [5.8139]
22 [6.1207]
23 [6.3135]
24 [6.6301]
train done
Epoch 133/1000 : Loss:0.2763, Valid loss: 0.3650, lr:0.000980 [0.635] 1786.722524881363
1 [0.2071]
2 [0.8284]
3 [0.995]
4 [1.477]
5 [1.6283]
6 [1.8724]
7 [2.2025]
8 [2.3975]
9 [2.6771]
10 [2.8728]
11 [3.1232]
12 [3.4848]
13 [3.6392]
14 [3.8587]
15 [4.072]
16 [4.3123]
17 [4.8525]
18 [5.]
19 [5.5784]
20 [6.0852]
21 [6.3095]
22 [6.645]
23 [6.8422]
24 [6.9723]
train done
Epoch 134/1000 : Loss:0.2905, Valid loss: 0.3634, lr:0.000980 [0.6366] 1782.3122079372406
1 [0.4532]
2 [0.7578]
3 [0.927]
4 [1.3384]
5 [1.4948]
6 [1.7613]
7 [2.0225]
8 [2.8375]
9 [3.1225]
10 [3.4222]
11 [3.6744]
12 [3.8811]
13 [4.1362]
14 [4.3123]
15 [4.6131]
16 [4.8735]
17 [5.1581]
18 [5.4298]
19 [5.6346]
20 [5.8303]
21 [6.2369]
22 [6.444]
23 [6.6823]
24 [6.8582]
train done
Epoch 135/1000 : Loss:0.2858, Valid loss: 0.3265, lr:0.000980 [0.6735] 1707.7388770580292
1 [0.1101]
2 [0.543]
3 [0.7406]
4 [1.083]
5 [1.286]
6 [1.5935]
7 [1.7475]
8 [2.0756]
9 [2.6179]
10 [2.8735]
11 [3.2617]
12 [3.5237]
13 [3.7124]
14 [4.0562]
15 [4.2616]
16 [4.5099]
17 [4.6446]
18 [4.8633]
19 [5.1212]
20 [5.365]
21 [5.5583]
22 [5.8612]
23 [5.999]
24 [6.3552]
train done
Epoch 136/1000 : Loss:0.2648, Valid loss: 0.3492, lr:0.000980 [0.6508] 1681.416212797165
1 [0.4031]
2 [0.6011]
3 [0.7848]
4 [0.9562]
5 [1.1068]
6 [1.3566]
7 [1.6543]
8 [1.9412]
9 [2.0831]
10 [2.2648]
11 [2.4721]
12 [2.6471]
13 [2.9975]
14 [3.4344]
15 [3.8221]
16 [3.9938]
17 [4.2074]
18 [4.694]
19 [5.0724]
20 [5.303]
21 [5.486]
22 [5.6416]
23 [6.0068]
24 [6.222]
train done
Epoch 137/1000 : Loss:0.2593, Valid loss: 0.3401, lr:0.000980 [0.6599] 1777.6959981918335
1 [0.2329]
2 [0.4196]
3 [0.5627]
4 [0.7604]
5 [0.9151]
6 [1.3081]
7 [1.5015]
8 [1.7262]
9 [1.8761]
10 [2.1497]
11 [2.3017]
12 [2.7144]
13 [3.2222]
14 [3.5219]
15 [3.6477]
16 [3.8718]
17 [4.4118]
18 [4.5588]
19 [4.8264]
20 [5.1744]
21 [5.3414]
22 [5.7564]
23 [6.066]
24 [6.2948]
train done
Epoch 138/1000 : Loss:0.2623, Valid loss: 0.3345, lr:0.000980 [0.6655] 1718.2915980815887
1 [0.187]
2 [0.346]
3 [0.8899]
4 [1.0871]
5 [1.4936]
6 [1.635]
7 [1.888]
8 [2.1457]
9 [2.2852]
10 [2.4446]
11 [2.7477]
12 [2.9825]
13 [3.3446]
14 [3.478]
15 [3.7368]
16 [4.0328]
17 [4.2909]
18 [4.5]
19 [5.0479]
20 [5.2259]
21 [5.6235]
22 [5.756]
23 [5.9019]
24 [6.142]
train done
Epoch 139/1000 : Loss:0.2559, Valid loss: 0.2957, lr:0.000980 [0.7043] 1713.6500549316406
1 [0.2152]
2 [0.4013]
3 [0.5842]
4 [0.7941]
5 [0.8984]
6 [1.1557]
7 [1.4209]
8 [1.5832]
9 [1.7498]
10 [1.8698]
11 [2.0276]
12 [2.4934]
13 [3.0159]
14 [3.434]
15 [3.8046]
16 [4.0477]
17 [4.3967]
18 [4.8254]
19 [5.1045]
20 [5.3068]
21 [5.5079]
22 [5.6689]
23 [5.8615]
24 [6.036]
train done
Epoch 140/1000 : Loss:0.2515, Valid loss: 0.3278, lr:0.000980 [0.6722] 1713.6595010757446
Model 140 saved.
1 [0.277]
2 [0.507]
3 [0.7659]
4 [1.0176]
5 [1.1593]
6 [1.3429]
7 [1.495]
8 [1.71]
9 [2.0595]
10 [2.3632]
11 [2.6666]
12 [3.1142]
13 [3.3849]
14 [3.7567]
15 [3.8722]
16 [4.5621]
17 [4.7751]
18 [4.9657]
19 [5.315]
20 [5.6099]
21 [5.7196]
22 [5.945]
23 [6.228]
24 [6.3934]
train done
Epoch 141/1000 : Loss:0.2664, Valid loss: 0.3428, lr:0.000980 [0.6572] 1704.0946371555328
1 [0.284]
2 [0.6933]
3 [0.919]
4 [1.2956]
5 [1.4112]
6 [1.7291]
7 [1.8546]
8 [2.278]
9 [2.4776]
10 [2.8821]
11 [3.4275]
12 [3.5959]
13 [3.8032]
14 [4.2793]
15 [4.5602]
16 [4.8084]
17 [5.0253]
18 [5.4226]
19 [5.609]
20 [6.2058]
21 [6.4489]
22 [6.6787]
23 [7.0284]
24 [7.3109]
train done
Epoch 142/1000 : Loss:0.3046, Valid loss: 0.3008, lr:0.000980 [0.6992] 1643.1714749336243
1 [0.2835]
2 [0.9276]
3 [1.1539]
4 [1.3812]
5 [1.6824]
6 [1.8543]
7 [2.0385]
8 [2.2666]
9 [2.5047]
10 [2.7909]
11 [2.9998]
12 [3.4041]
13 [3.5692]
14 [3.7626]
15 [4.0385]
16 [4.2959]
17 [4.5127]
18 [4.7329]
19 [4.927]
20 [5.2092]
21 [5.5371]
22 [5.777]
23 [5.9954]
24 [6.1855]
train done
Epoch 143/1000 : Loss:0.2577, Valid loss: 0.3333, lr:0.000980 [0.6667] 1681.508219718933
1 [0.1732]
2 [0.2945]
3 [0.4724]
4 [0.6857]
5 [0.8587]
6 [1.6631]
7 [1.878]
8 [2.4832]
9 [2.6939]
10 [2.9]
11 [3.0261]
12 [3.1603]
13 [3.2822]
14 [3.5426]
15 [3.7452]
16 [4.2429]
17 [4.5058]
18 [4.8183]
19 [5.0127]
20 [5.3067]
21 [5.6693]
22 [5.87]
23 [6.0521]
24 [6.6476]
train done
Epoch 144/1000 : Loss:0.2770, Valid loss: 0.3296, lr:0.000980 [0.6704] 1881.070858001709
1 [0.2439]
2 [0.4597]
3 [0.6587]
4 [0.9855]
5 [1.127]
6 [1.2447]
7 [1.3607]
8 [1.5476]
9 [1.677]
10 [1.8784]
11 [2.1677]
12 [2.583]
13 [2.8692]
14 [3.3099]
15 [3.5647]
16 [3.8608]
17 [4.1079]
18 [4.7254]
19 [5.074]
20 [5.2862]
21 [5.5825]
22 [5.8143]
23 [6.0405]
24 [6.2018]
train done
Epoch 145/1000 : Loss:0.2584, Valid loss: 0.3471, lr:0.000980 [0.6529] 1716.858242034912
1 [0.9998]
2 [1.4303]
3 [1.5816]
4 [1.9776]
5 [2.3263]
6 [2.4669]
7 [2.7164]
8 [3.1155]
9 [3.3396]
10 [3.5046]
11 [3.7632]
12 [3.9795]
13 [4.3811]
14 [4.723]
15 [5.0144]
16 [5.3372]
17 [5.5882]
18 [5.7472]
19 [5.9732]
20 [6.1187]
21 [6.2524]
22 [6.4482]
23 [6.6116]
24 [6.7578]
train done
Epoch 146/1000 : Loss:0.2816, Valid loss: 0.3283, lr:0.000980 [0.6717] 1684.4613680839539
1 [0.1812]
2 [0.4845]
3 [0.5887]
4 [0.8188]
5 [1.0531]
6 [1.2712]
7 [1.5984]
8 [2.2119]
9 [2.3435]
10 [2.4503]
11 [2.676]
12 [2.8827]
13 [3.3404]
14 [3.5026]
15 [3.6629]
16 [3.8411]
17 [4.1475]
18 [4.5955]
19 [4.9122]
20 [5.283]
21 [5.9372]
22 [6.2015]
23 [6.4795]
24 [6.7263]
train done
Epoch 147/1000 : Loss:0.2803, Valid loss: 0.3053, lr:0.000980 [0.6947] 1711.0741970539093
1 [0.2669]
2 [0.6532]
3 [0.9348]
4 [1.203]
5 [1.4596]
6 [1.6491]
7 [2.1454]
8 [2.3116]
9 [2.5439]
10 [2.7555]
11 [3.3082]
12 [3.4574]
13 [3.7516]
14 [3.9323]
15 [4.3866]
16 [4.6542]
17 [4.8111]
18 [5.0234]
19 [5.1917]
20 [5.3716]
21 [5.6481]
22 [5.8038]
23 [5.9903]
24 [6.2438]
train done
Epoch 148/1000 : Loss:0.2602, Valid loss: 0.3369, lr:0.000980 [0.6631] 1706.8223428726196
1 [0.2345]
2 [0.4659]
3 [0.8213]
4 [1.0517]
5 [1.3057]
6 [1.6497]
7 [1.8871]
8 [2.0461]
9 [2.395]
10 [2.5456]
11 [2.7989]
12 [2.9599]
13 [3.3194]
14 [3.6222]
15 [3.8775]
16 [4.1859]
17 [4.3957]
18 [4.5691]
19 [4.9116]
20 [5.1502]
21 [5.3494]
22 [5.5612]
23 [5.6502]
24 [5.7469]
train done
Epoch 149/1000 : Loss:0.2395, Valid loss: 0.3264, lr:0.000980 [0.6736] 1713.738492012024
1 [0.2076]
2 [0.7104]
3 [1.0534]
4 [1.2926]
5 [1.5132]
6 [1.7319]
7 [1.9491]
8 [2.1475]
9 [2.4666]
10 [2.6827]
11 [2.9272]
12 [3.0978]
13 [3.4026]
14 [3.6854]
15 [3.8389]
16 [3.9544]
17 [4.2956]
18 [4.4176]
19 [4.7164]
20 [4.9626]
21 [5.1962]
22 [5.5312]
23 [5.9803]
24 [6.1943]
train done
Epoch 150/1000 : Loss:0.2581, Valid loss: 0.3033, lr:0.000980 [0.6967] 1677.4098176956177
Model 150 saved.
1 [0.1721]
2 [0.419]
3 [0.6797]
4 [0.9316]
5 [1.187]
6 [1.5685]
7 [1.8275]
8 [1.9772]
9 [2.5253]
10 [2.7023]
11 [3.0563]
12 [3.3726]
13 [3.5663]
14 [3.7117]
15 [3.9841]
16 [4.1522]
17 [4.434]
18 [4.8031]
19 [5.0301]
20 [5.3558]
21 [5.5582]
22 [5.7836]
23 [5.9528]
24 [6.1962]
train done
Epoch 151/1000 : Loss:0.2582, Valid loss: 0.3352, lr:0.000686 [0.6648] 1812.4832820892334
1 [0.2132]
2 [0.4141]
3 [0.6952]
4 [1.0213]
5 [1.1907]
6 [1.297]
7 [1.4049]
8 [1.6298]
9 [1.8729]
10 [2.0726]
11 [2.4572]
12 [2.6518]
13 [2.8973]
14 [2.994]
15 [3.2039]
16 [3.4205]
17 [3.5798]
18 [3.7976]
19 [4.1697]
20 [4.346]
21 [4.6214]
22 [4.8664]
23 [5.1247]
24 [5.9348]
train done
Epoch 152/1000 : Loss:0.2473, Valid loss: 0.3052, lr:0.000686 [0.6948] 1782.261080980301
1 [0.1525]
2 [0.3799]
3 [0.5574]
4 [0.7717]
5 [1.0662]
6 [1.2214]
7 [1.4159]
8 [1.5985]
9 [1.8459]
10 [2.0592]
11 [2.3291]
12 [2.5131]
13 [3.0754]
14 [3.2138]
15 [3.5995]
16 [3.8033]
17 [3.9132]
18 [4.0285]
19 [4.217]
20 [4.4727]
21 [4.9243]
22 [5.0745]
23 [5.4677]
24 [5.6198]
train done
Epoch 153/1000 : Loss:0.2342, Valid loss: 0.3057, lr:0.000686 [0.6943] 1878.8177490234375
1 [0.3556]
2 [0.6441]
3 [0.8255]
4 [0.9909]
5 [1.2523]
6 [1.4661]
7 [1.6639]
8 [1.8293]
9 [1.982]
10 [2.1648]
11 [2.4251]
12 [2.5959]
13 [2.9286]
14 [3.5964]
15 [3.8432]
16 [4.1003]
17 [4.3477]
18 [4.6552]
19 [4.6552]
20 [4.8554]
21 [5.0619]
22 [5.3473]
23 [5.5319]
24 [5.7179]
train done
Epoch 154/1000 : Loss:0.2382, Valid loss: 0.3271, lr:0.000686 [0.6729] 1891.3302071094513
1 [0.1761]
2 [0.336]
3 [0.4266]
4 [0.8094]
5 [0.9969]
6 [1.1988]
7 [1.4157]
8 [1.6486]
9 [1.8688]
10 [2.1533]
11 [2.4287]
12 [2.6807]
13 [2.8141]
14 [3.0048]
15 [3.2055]
16 [3.3512]
17 [3.5248]
18 [3.6535]
19 [3.8164]
20 [4.4533]
21 [4.5956]
22 [4.7451]
23 [4.9762]
24 [5.4382]
train done
Epoch 155/1000 : Loss:0.2266, Valid loss: 0.3036, lr:0.000686 [0.6964] 1654.7216041088104
1 [0.3597]
2 [0.5996]
3 [0.849]
4 [1.0043]
5 [1.1396]
6 [1.489]
7 [1.739]
8 [1.9405]
9 [2.2052]
10 [2.3438]
11 [2.6615]
12 [2.9746]
13 [3.7796]
14 [4.1578]
15 [4.2704]
16 [4.4086]
17 [4.6751]
18 [4.9312]
19 [5.3161]
20 [5.4921]
21 [5.6282]
22 [5.8475]
23 [5.9932]
24 [6.5744]
train done
Epoch 156/1000 : Loss:0.2739, Valid loss: 0.3219, lr:0.000686 [0.6781] 1637.2460510730743
1 [0.2207]
2 [0.4405]
3 [0.7308]
4 [1.0797]
5 [1.2374]
6 [1.3889]
7 [1.5725]
8 [1.7078]
9 [1.8356]
10 [2.0378]
11 [2.3924]
12 [2.5367]
13 [2.8043]
14 [2.9953]
15 [3.1721]
16 [3.4996]
17 [3.6889]
18 [4.2333]
19 [4.4395]
20 [4.5548]
21 [4.7442]
22 [5.1186]
23 [5.3695]
24 [5.6656]
train done
Epoch 157/1000 : Loss:0.2361, Valid loss: 0.3060, lr:0.000686 [0.694] 1624.7845721244812
1 [0.1958]
2 [0.415]
3 [0.7058]
4 [0.8551]
5 [1.0376]
6 [1.2073]
7 [1.4143]
8 [1.5133]
9 [1.9797]
10 [2.2704]
11 [2.5712]
12 [2.7314]
13 [2.8798]
14 [3.1586]
15 [3.3114]
16 [3.5742]
17 [3.9886]
18 [4.1237]
19 [4.4595]
20 [4.6143]
21 [4.7455]
22 [5.0476]
23 [5.4147]
24 [5.7913]
train done
Epoch 158/1000 : Loss:0.2413, Valid loss: 0.3381, lr:0.000686 [0.6619] 1650.8560662269592
1 [0.6147]
2 [0.8622]
3 [1.1314]
4 [1.2971]
5 [1.4849]
6 [2.0991]
7 [2.3801]
8 [2.5702]
9 [2.6587]
10 [2.9116]
11 [3.389]
12 [3.6415]
13 [3.9398]
14 [4.1267]
15 [4.3698]
16 [4.5423]
17 [4.8202]
18 [5.1084]
19 [5.3494]
20 [5.5163]
21 [5.7884]
22 [5.9453]
23 [6.1478]
24 [6.3352]
train done
Epoch 159/1000 : Loss:0.2640, Valid loss: 0.3096, lr:0.000686 [0.6904] 1640.4330999851227
1 [0.1469]
2 [0.3908]
3 [0.6305]
4 [0.8196]
5 [1.0779]
6 [1.3236]
7 [1.531]
8 [1.925]
9 [2.2455]
10 [2.6413]
11 [2.8974]
12 [2.9982]
13 [3.4631]
14 [3.664]
15 [3.8295]
16 [4.1873]
17 [4.3363]
18 [4.4908]
19 [4.6655]
20 [4.8836]
21 [5.1795]
22 [5.3063]
23 [5.5278]
24 [5.7945]
train done
Epoch 160/1000 : Loss:0.2414, Valid loss: 0.3001, lr:0.000686 [0.6999] 1601.2768518924713
Model 160 saved.
1 [0.1878]
2 [0.5304]
3 [0.7254]
4 [0.9995]
5 [1.0895]
6 [1.2104]
7 [1.5018]
8 [1.832]
9 [1.9855]
10 [2.2292]
11 [2.4595]
12 [2.7187]
13 [2.909]
14 [3.0791]
15 [3.3329]
16 [3.9293]
17 [4.1099]
18 [4.3331]
19 [4.7327]
20 [4.8406]
21 [5.0881]
22 [5.2964]
23 [5.4351]
24 [5.5953]
train done
Epoch 161/1000 : Loss:0.2331, Valid loss: 0.2897, lr:0.000686 [0.7103] 1634.3768990039825
1 [0.2293]
2 [0.4561]
3 [0.7165]
4 [0.9277]
5 [1.0737]
6 [1.4153]
7 [1.5538]
8 [1.7006]
9 [1.8771]
10 [2.0186]
11 [2.4601]
12 [2.658]
13 [2.786]
14 [3.0291]
15 [3.2668]
16 [3.5585]
17 [4.0076]
18 [4.1348]
19 [4.7474]
20 [4.9733]
21 [5.2874]
22 [5.6389]
23 [6.0178]
24 [6.1928]
train done
Epoch 162/1000 : Loss:0.2580, Valid loss: 0.3149, lr:0.000686 [0.6851] 1624.3537793159485
1 [0.178]
2 [0.4317]
3 [0.9314]
4 [1.3561]
5 [1.5248]
6 [1.7398]
7 [1.9736]
8 [2.1651]
9 [2.5221]
10 [2.8134]
11 [3.0419]
12 [3.2017]
13 [3.429]
14 [3.6673]
15 [3.9282]
16 [4.4302]
17 [4.6306]
18 [4.9018]
19 [5.1518]
20 [5.3243]
21 [5.4491]
22 [5.8007]
23 [5.9782]
24 [6.3334]
train done
Epoch 163/1000 : Loss:0.2639, Valid loss: 0.3397, lr:0.000686 [0.6603] 1618.2434711456299
1 [0.1847]
2 [0.4389]
3 [0.7062]
4 [0.9492]
5 [1.3696]
6 [1.5305]
7 [2.1249]
8 [2.3502]
9 [2.5712]
10 [2.7644]
11 [2.8834]
12 [3.2753]
13 [3.5251]
14 [3.7254]
15 [3.9345]
16 [4.0847]
17 [4.2585]
18 [4.5519]
19 [4.7321]
20 [5.0341]
21 [5.3125]
22 [5.6938]
23 [6.059]
24 [6.2646]
train done
Epoch 164/1000 : Loss:0.2610, Valid loss: 0.3571, lr:0.000686 [0.6429] 1644.0668003559113
1 [0.2003]
2 [0.4014]
3 [0.6833]
4 [1.1345]
5 [1.3181]
6 [1.5049]
7 [1.9417]
8 [2.8064]
9 [2.9457]
10 [3.1622]
11 [3.6762]
12 [3.9867]
13 [4.2292]
14 [5.1548]
15 [5.43]
16 [5.5773]
17 [5.9758]
18 [6.1465]
19 [6.2717]
20 [6.6404]
21 [6.8036]
22 [7.2042]
23 [7.5041]
24 [7.6196]
train done
Epoch 165/1000 : Loss:0.3175, Valid loss: 0.3337, lr:0.000686 [0.6663] 1636.5938041210175
1 [0.3854]
2 [0.7969]
3 [1.3589]
4 [1.6358]
5 [1.8399]
6 [2.0671]
7 [2.1835]
8 [2.3316]
9 [2.5807]
10 [2.7971]
11 [3.0453]
12 [3.1682]
13 [3.3923]
14 [4.2373]
15 [4.4147]
16 [4.5085]
17 [4.6719]
18 [4.8284]
19 [5.2549]
20 [5.5878]
21 [5.7485]
22 [5.9258]
23 [6.2096]
24 [6.3891]
train done
Epoch 166/1000 : Loss:0.2662, Valid loss: 0.3238, lr:0.000686 [0.6762] 1632.2145438194275
1 [0.1682]
2 [0.4202]
3 [0.5422]
4 [0.7549]
5 [1.3773]
6 [1.6477]
7 [1.8607]
8 [2.1478]
9 [2.3677]
10 [2.6105]
11 [2.7796]
12 [2.9751]
13 [3.3942]
14 [3.561]
15 [3.7827]
16 [3.917]
17 [4.1767]
18 [4.353]
19 [4.8886]
20 [5.0297]
21 [5.4886]
22 [5.6993]
23 [5.9575]
24 [6.1671]
train done
Epoch 167/1000 : Loss:0.2570, Valid loss: 0.2967, lr:0.000686 [0.7033] 1628.052521944046
1 [0.1482]
2 [0.459]
3 [0.7115]
4 [0.9353]
5 [1.2034]
6 [1.3496]
7 [1.6926]
8 [2.0648]
9 [2.2247]
10 [2.4095]
11 [2.5716]
12 [2.8611]
13 [3.344]
14 [3.5178]
15 [3.6656]
16 [3.7815]
17 [3.9792]
18 [4.2469]
19 [4.4333]
20 [4.7129]
21 [4.9808]
22 [5.341]
23 [5.519]
24 [5.6585]
train done
Epoch 168/1000 : Loss:0.2358, Valid loss: 0.3057, lr:0.000686 [0.6943] 1624.148138999939
1 [0.1555]
2 [0.3436]
3 [0.667]
4 [0.8551]
5 [0.9966]
6 [1.1151]
7 [1.4683]
8 [1.6025]
9 [1.8609]
10 [2.0488]
11 [2.3267]
12 [2.5532]
13 [2.7054]
14 [2.9517]
15 [3.184]
16 [3.5628]
17 [4.3396]
18 [4.4407]
19 [4.6041]
20 [4.7705]
21 [5.0132]
22 [5.137]
23 [5.5576]
24 [5.8272]
train done
Epoch 169/1000 : Loss:0.2428, Valid loss: 0.3104, lr:0.000686 [0.6896] 1634.4454131126404
1 [0.3338]
2 [0.5127]
3 [0.6692]
4 [0.8619]
5 [1.1936]
6 [1.3528]
7 [1.4412]
8 [1.5644]
9 [2.1607]
10 [2.3038]
11 [2.4562]
12 [2.6766]
13 [2.8595]
14 [2.9698]
15 [3.2743]
16 [3.467]
17 [3.8522]
18 [4.1833]
19 [4.3204]
20 [4.5562]
21 [4.7021]
22 [4.8904]
23 [5.2559]
24 [5.3804]
train done
Epoch 170/1000 : Loss:0.2242, Valid loss: 0.2850, lr:0.000686 [0.715] 1636.947348833084
Model 170 saved.
1 [0.1589]
2 [0.3001]
3 [0.4364]
4 [0.6113]
5 [0.7679]
6 [0.9744]
7 [1.3241]
8 [1.5597]
9 [1.728]
10 [2.2922]
11 [2.494]
12 [2.6608]
13 [2.9143]
14 [3.1171]
15 [3.5095]
16 [3.8017]
17 [4.3444]
18 [4.7058]
19 [4.8568]
20 [5.0867]
21 [5.3163]
22 [5.5735]
23 [5.7117]
24 [5.9132]
train done
Epoch 171/1000 : Loss:0.2464, Valid loss: 0.2845, lr:0.000686 [0.7155] 1640.0666251182556
1 [0.3882]
2 [0.6405]
3 [1.139]
4 [1.2867]
5 [1.4491]
6 [1.6954]
7 [1.9764]
8 [2.1404]
9 [2.4025]
10 [2.7566]
11 [2.9582]
12 [3.1547]
13 [3.4555]
14 [3.5961]
15 [3.8709]
16 [4.1715]
17 [4.2883]
18 [4.6224]
19 [4.8615]
20 [5.1196]
21 [5.3954]
22 [5.6748]
23 [5.9294]
24 [6.0787]
train done
Epoch 172/1000 : Loss:0.2533, Valid loss: 0.2970, lr:0.000686 [0.703] 1643.8295738697052
1 [0.2731]
2 [0.5049]
3 [0.6775]
4 [0.8241]
5 [0.9424]
6 [1.0875]
7 [1.3248]
8 [1.6815]
9 [2.0287]
10 [2.1302]
11 [2.2799]
12 [2.6121]
13 [2.7764]
14 [2.9745]
15 [3.1711]
16 [3.3406]
17 [3.4952]
18 [3.6544]
19 [3.9067]
20 [4.1752]
21 [4.4234]
22 [4.6986]
23 [5.1004]
24 [5.3102]
train done
Epoch 173/1000 : Loss:0.2213, Valid loss: 0.3290, lr:0.000686 [0.671] 1651.400143146515
1 [0.2504]
2 [0.4678]
3 [0.6078]
4 [0.7401]
5 [1.1349]
6 [1.3064]
7 [1.5004]
8 [1.676]
9 [1.8194]
10 [2.1011]
11 [2.4227]
12 [2.8493]
13 [3.0597]
14 [3.4195]
15 [3.6792]
16 [3.8966]
17 [4.2046]
18 [4.6566]
19 [4.8559]
20 [5.0693]
21 [5.2678]
22 [5.575]
23 [5.734]
24 [6.0154]
train done
Epoch 174/1000 : Loss:0.2506, Valid loss: 0.4112, lr:0.000686 [0.5888] 1840.5122182369232
1 [0.5286]
2 [0.775]
3 [1.0218]
4 [1.1578]
5 [1.2856]
6 [1.5004]
7 [1.7322]
8 [1.9247]
9 [2.0317]
10 [2.5062]
11 [2.6882]
12 [2.8525]
13 [3.7672]
14 [4.0448]
15 [4.3418]
16 [4.5559]
17 [4.7236]
18 [5.0106]
19 [5.3025]
20 [5.4885]
21 [5.7675]
22 [6.016]
23 [6.3541]
24 [6.5163]
train done
Epoch 175/1000 : Loss:0.2715, Valid loss: 0.2950, lr:0.000686 [0.705] 1849.4618210792542
1 [0.256]
2 [0.4857]
3 [1.0066]
4 [1.1715]
5 [1.3645]
6 [1.5504]
7 [1.6925]
8 [1.806]
9 [2.0236]
10 [2.2211]
11 [2.5298]
12 [2.7419]
13 [3.0985]
14 [3.2719]
15 [3.5006]
16 [3.9083]
17 [4.0834]
18 [4.3136]
19 [4.5336]
20 [4.7502]
21 [4.9635]
22 [5.2146]
23 [5.4309]
24 [5.5678]
train done
Epoch 176/1000 : Loss:0.2320, Valid loss: 0.2967, lr:0.000686 [0.7033] 1964.5514776706696
1 [0.2013]
2 [0.4466]
3 [0.6813]
4 [1.0036]
5 [1.2268]
6 [1.4387]
7 [1.571]
8 [1.7321]
9 [1.9671]
10 [2.1197]
11 [2.2859]
12 [2.5289]
13 [2.8975]
14 [3.1568]
15 [3.2961]
16 [3.4567]
17 [3.6386]
18 [3.7708]
19 [4.0532]
20 [4.1624]
21 [4.35]
22 [4.5421]
23 [4.8664]
24 [5.1734]
train done
Epoch 177/1000 : Loss:0.2156, Valid loss: 0.3625, lr:0.000686 [0.6375] 1810.6915600299835
1 [0.306]
2 [0.6285]
3 [0.8895]
4 [1.0423]
5 [1.2797]
6 [1.5215]
7 [1.6966]
8 [1.8709]
9 [2.0414]
10 [2.1963]
11 [2.6131]
12 [2.8325]
13 [3.006]
14 [3.4552]
15 [3.5987]
16 [3.8496]
17 [4.0364]
18 [4.2283]
19 [4.8641]
20 [5.035]
21 [5.1822]
22 [5.4585]
23 [5.6353]
24 [5.9383]
train done
Epoch 178/1000 : Loss:0.2474, Valid loss: 0.3104, lr:0.000686 [0.6896] 1678.8027820587158
1 [0.2191]
2 [0.4054]
3 [0.6887]
4 [0.9684]
5 [1.1395]
6 [1.5377]
7 [1.6979]
8 [1.9394]
9 [2.0855]
10 [2.3329]
11 [2.4945]
12 [2.897]
13 [3.2106]
14 [3.4608]
15 [3.612]
16 [3.7581]
17 [3.9354]
18 [4.5022]
19 [4.6705]
20 [5.2924]
21 [5.4601]
22 [5.6764]
23 [5.8764]
24 [6.041]
train done
Epoch 179/1000 : Loss:0.2517, Valid loss: 0.3046, lr:0.000686 [0.6954] 1655.8229928016663
1 [0.4339]
2 [0.5501]
3 [0.6723]
4 [0.7777]
5 [0.9126]
6 [1.103]
7 [1.4515]
8 [1.7316]
9 [2.0604]
10 [2.4621]
11 [2.6832]
12 [2.8592]
13 [2.9555]
14 [3.4363]
15 [3.7913]
16 [3.9633]
17 [4.521]
18 [4.7593]
19 [4.9458]
20 [5.1335]
21 [5.3437]
22 [5.538]
23 [5.7185]
24 [5.8695]
train done
Epoch 180/1000 : Loss:0.2446, Valid loss: 0.3118, lr:0.000686 [0.6882] 1654.0506517887115
Model 180 saved.
1 [0.4709]
2 [0.6488]
3 [0.8108]
4 [1.0747]
5 [1.4429]
6 [1.7116]
7 [1.9033]
8 [2.1364]
9 [2.3729]
10 [2.6724]
11 [2.7514]
12 [2.911]
13 [3.1175]
14 [3.3401]
15 [3.4967]
16 [3.727]
17 [3.9639]
18 [4.1947]
19 [4.3327]
20 [4.5118]
21 [4.6274]
22 [4.8078]
23 [5.1127]
24 [5.33]
train done
Epoch 181/1000 : Loss:0.2221, Valid loss: 0.3411, lr:0.000686 [0.6589] 1649.058044910431
1 [3.1412e-05]
2 [0.3807]
3 [0.689]
4 [1.1684]
5 [1.4867]
6 [1.7617]
7 [2.2053]
8 [2.3027]
9 [2.4589]
10 [2.689]
11 [2.9178]
12 [3.184]
13 [3.2946]
14 [3.458]
15 [3.625]
16 [3.8383]
17 [3.9602]
18 [4.2262]
19 [4.3825]
20 [4.5677]
21 [4.6659]
22 [4.7882]
23 [5.548]
24 [5.953]
train done
Epoch 182/1000 : Loss:0.2480, Valid loss: 0.3581, lr:0.000686 [0.6419] 1655.160790681839
1 [0.4582]
2 [0.7121]
3 [0.8905]
4 [1.0308]
5 [1.5373]
6 [1.7505]
7 [1.8559]
8 [2.0554]
9 [2.1638]
10 [2.7701]
11 [2.898]
12 [3.127]
13 [3.3488]
14 [3.5075]
15 [3.6626]
16 [3.8804]
17 [4.3332]
18 [4.4799]
19 [4.7928]
20 [4.9687]
21 [5.227]
22 [5.545]
23 [5.6828]
24 [5.9594]
train done
Epoch 183/1000 : Loss:0.2483, Valid loss: 0.3336, lr:0.000686 [0.6664] 1761.612312078476
1 [0.1259]
2 [0.253]
3 [0.4817]
4 [0.7108]
5 [0.8539]
6 [1.1732]
7 [1.5829]
8 [1.8482]
9 [2.2417]
10 [2.484]
11 [2.6827]
12 [2.9686]
13 [3.0752]
14 [3.2603]
15 [3.3957]
16 [3.5407]
17 [3.8166]
18 [4.1008]
19 [4.2256]
20 [4.721]
21 [4.9747]
22 [5.2883]
23 [5.3795]
24 [5.5963]
train done
Epoch 184/1000 : Loss:0.2332, Valid loss: 0.3201, lr:0.000686 [0.6799] 1986.0096337795258
1 [0.1573]
2 [0.3213]
3 [0.6854]
4 [1.1119]
5 [1.5371]
6 [1.7237]
7 [1.9379]
8 [2.0885]
9 [2.4562]
10 [2.6269]
11 [2.9702]
12 [3.1559]
13 [3.4494]
14 [3.9785]
15 [4.2177]
16 [4.4553]
17 [4.6011]
18 [4.8625]
19 [5.0602]
20 [5.6734]
21 [5.777]
22 [5.9917]
23 [6.2623]
24 [6.5718]
train done
Epoch 185/1000 : Loss:0.2738, Valid loss: 0.3449, lr:0.000686 [0.6551] 2016.5189011096954
1 [0.3163]
2 [0.6132]
3 [0.8883]
4 [1.0117]
5 [1.1832]
6 [1.3235]
7 [1.7367]
8 [1.9434]
9 [2.2533]
10 [2.4578]
11 [2.587]
12 [2.9246]
13 [3.124]
14 [3.3056]
15 [3.6017]
16 [3.785]
17 [3.9708]
18 [4.0724]
19 [4.3906]
20 [4.4903]
21 [4.668]
22 [4.8504]
23 [5.1127]
24 [5.2532]
train done
Epoch 186/1000 : Loss:0.2189, Valid loss: 0.3355, lr:0.000686 [0.6645] 2014.1837980747223
1 [0.2681]
2 [0.8907]
3 [1.2158]
4 [1.5435]
5 [1.697]
6 [1.8647]
7 [1.9984]
8 [2.221]
9 [2.597]
10 [2.7197]
11 [2.842]
12 [3.0447]
13 [3.1865]
14 [3.4229]
15 [3.9798]
16 [4.1612]
17 [4.3667]
18 [4.5675]
19 [4.6854]
20 [4.8758]
21 [5.0487]
22 [5.2977]
23 [5.494]
24 [5.855]
train done
Epoch 187/1000 : Loss:0.2440, Valid loss: 0.3213, lr:0.000686 [0.6787] 2016.5742001533508
1 [0.3269]
2 [0.6368]
3 [0.8974]
4 [1.1522]
5 [1.2606]
6 [1.3861]
7 [1.5326]
8 [1.7399]
9 [2.0124]
10 [2.279]
11 [2.4599]
12 [2.7051]
13 [3.0547]
14 [3.3247]
15 [3.5442]
16 [3.6744]
17 [3.7987]
18 [3.9778]
19 [4.2741]
20 [4.657]
21 [4.855]
22 [5.1229]
23 [5.2407]
24 [5.5681]
train done
Epoch 188/1000 : Loss:0.2320, Valid loss: 0.3111, lr:0.000686 [0.6889] 2041.086706161499
1 [0.2083]
2 [0.3668]
3 [0.4641]
4 [0.7603]
5 [0.9351]
6 [1.1144]
7 [1.4611]
8 [1.7987]
9 [1.9514]
10 [2.2858]
11 [2.4971]
12 [2.8657]
13 [3.1136]
14 [3.2939]
15 [3.4899]
16 [3.6677]
17 [3.9117]
18 [4.0331]
19 [4.1764]
20 [4.5386]
21 [4.8382]
22 [4.9693]
23 [5.0771]
24 [5.2169]
train done
Epoch 189/1000 : Loss:0.2174, Valid loss: 0.3065, lr:0.000686 [0.6935] 2086.0973138809204
1 [0.2014]
2 [0.4375]
3 [0.5674]
4 [0.7792]
5 [1.0029]
6 [1.1849]
7 [1.5417]
8 [1.7561]
9 [2.0264]
10 [2.1984]
11 [2.4999]
12 [3.0137]
13 [3.3228]
14 [3.4698]
15 [3.6061]
16 [3.8337]
17 [4.1029]
18 [4.3961]
19 [4.7702]
20 [4.9542]
21 [5.379]
22 [5.7425]
23 [5.9335]
24 [6.2178]
train done
Epoch 190/1000 : Loss:0.2591, Valid loss: 0.3338, lr:0.000686 [0.6662] 1992.8440310955048
Model 190 saved.
1 [0.2687]
2 [0.4168]
3 [0.8765]
4 [1.1512]
5 [1.4025]
6 [1.5846]
7 [1.7772]
8 [1.9643]
9 [2.1322]
10 [2.6297]
11 [2.9342]
12 [3.2431]
13 [3.3844]
14 [3.5081]
15 [3.6585]
16 [3.7886]
17 [4.0407]
18 [4.2096]
19 [4.3564]
20 [4.5493]
21 [4.6752]
22 [4.8412]
23 [5.3617]
24 [5.6922]
train done
Epoch 191/1000 : Loss:0.2372, Valid loss: 0.3403, lr:0.000686 [0.6597] 1885.3075160980225
1 [0.1915]
2 [0.524]
3 [0.8199]
4 [1.2463]
5 [1.3913]
6 [1.6349]
7 [1.8484]
8 [2.0083]
9 [2.2266]
10 [2.5213]
11 [3.0275]
12 [3.1976]
13 [3.3569]
14 [3.5079]
15 [3.6531]
16 [3.7724]
17 [3.9251]
18 [4.4853]
19 [4.7192]
20 [4.9024]
21 [5.0018]
22 [5.1724]
23 [5.4071]
24 [5.6138]
train done
Epoch 192/1000 : Loss:0.2339, Valid loss: 0.2943, lr:0.000686 [0.7057] 2006.6968522071838
1 [0.243]
2 [0.7964]
3 [0.9446]
4 [1.1226]
5 [1.3369]
6 [1.4744]
7 [1.6427]
8 [1.9613]
9 [2.0859]
10 [2.3232]
11 [2.548]
12 [2.7786]
13 [2.9961]
14 [3.2186]
15 [3.4255]
16 [3.7121]
17 [3.934]
18 [4.0713]
19 [4.3162]
20 [4.4651]
21 [4.5467]
22 [4.8872]
23 [5.089]
24 [5.3216]
train done
Epoch 193/1000 : Loss:0.2217, Valid loss: 0.2904, lr:0.000686 [0.7096] 2030.8940382003784
1 [0.1718]
2 [0.4576]
3 [0.6054]
4 [1.178]
5 [1.3934]
6 [1.8412]
7 [1.9648]
8 [2.1365]
9 [2.3131]
10 [2.5921]
11 [2.8341]
12 [2.9933]
13 [3.0979]
14 [3.2475]
15 [3.4507]
16 [3.8094]
17 [3.9433]
18 [4.3355]
19 [4.5533]
20 [4.8142]
21 [5.0011]
22 [5.134]
23 [5.3408]
24 [5.5599]
train done
Epoch 194/1000 : Loss:0.2317, Valid loss: 0.3088, lr:0.000686 [0.6912] 2016.6270999908447
1 [0.2282]
2 [0.4421]
3 [0.6322]
4 [0.7629]
5 [0.8775]
6 [1.0028]
7 [1.1849]
8 [1.3955]
9 [1.7988]
10 [2.2619]
11 [2.5043]
12 [2.7422]
13 [2.9313]
14 [3.3374]
15 [3.5988]
16 [3.8604]
17 [3.9961]
18 [4.1099]
19 [4.2651]
20 [4.701]
21 [5.1805]
22 [5.4139]
23 [5.783]
24 [6.0113]
train done
Epoch 195/1000 : Loss:0.2505, Valid loss: 0.3496, lr:0.000686 [0.6504] 2001.7136859893799
1 [0.1618]
2 [0.282]
3 [0.4331]
4 [0.6264]
5 [0.8056]
6 [1.2321]
7 [1.4027]
8 [1.6657]
9 [2.2861]
10 [2.3965]
11 [2.9009]
12 [3.2266]
13 [3.4811]
14 [3.6686]
15 [3.9005]
16 [4.0577]
17 [4.4045]
18 [4.518]
19 [4.8428]
20 [5.0178]
21 [5.2757]
22 [5.4203]
23 [5.6096]
24 [5.9173]
train done
Epoch 196/1000 : Loss:0.2466, Valid loss: 0.3293, lr:0.000686 [0.6707] 1899.2703838348389
1 [0.3615]
2 [0.5367]
3 [0.8013]
4 [1.2005]
5 [1.4736]
6 [1.6008]
7 [1.7531]
8 [1.9822]
9 [2.2452]
10 [2.3398]
11 [2.4644]
12 [2.6616]
13 [2.8324]
14 [3.3471]
15 [3.4544]
16 [3.714]
17 [3.9747]
18 [4.1329]
19 [4.2412]
20 [4.8799]
21 [5.0381]
22 [5.2872]
23 [5.4698]
24 [5.634]
train done
Epoch 197/1000 : Loss:0.2348, Valid loss: 0.3532, lr:0.000686 [0.6468] 1997.873420715332
1 [0.2582]
2 [0.6453]
3 [0.9191]
4 [1.0867]
5 [1.2249]
6 [1.3918]
7 [1.6207]
8 [1.9038]
9 [2.4506]
10 [2.5893]
11 [3.0107]
12 [3.2447]
13 [3.5917]
14 [3.8508]
15 [4.0655]
16 [4.8066]
17 [5.0318]
18 [5.2428]
19 [5.454]
20 [5.6483]
21 [5.8857]
22 [6.0697]
23 [6.2782]
24 [6.6017]
train done
Epoch 198/1000 : Loss:0.2751, Valid loss: 0.3214, lr:0.000686 [0.6786] 1932.1074512004852
1 [0.2062]
2 [0.3982]
3 [0.5936]
4 [0.8372]
5 [1.1005]
6 [1.279]
7 [1.5593]
8 [1.759]
9 [2.0492]
10 [2.3113]
11 [2.4815]
12 [2.6776]
13 [2.9591]
14 [3.1756]
15 [3.3545]
16 [3.46]
17 [3.8726]
18 [4.0314]
19 [4.2196]
20 [4.5818]
21 [4.772]
22 [4.9724]
23 [5.2879]
24 [5.5401]
train done
Epoch 199/1000 : Loss:0.2308, Valid loss: 0.3066, lr:0.000686 [0.6934] 1956.484530210495
1 [0.2022]
2 [0.3617]
3 [0.6914]
4 [0.8738]
5 [1.0823]
6 [1.2714]
7 [1.402]
8 [1.4954]
9 [1.8561]
10 [2.1307]
11 [2.3549]
12 [2.5214]
13 [2.7082]
14 [2.8705]
15 [3.1529]
16 [3.3737]
17 [3.5486]
18 [3.7267]
19 [3.9106]
20 [4.1224]
21 [4.4541]
22 [4.6237]
23 [4.8693]
24 [5.1252]
train done
Epoch 200/1000 : Loss:0.2135, Valid loss: 0.3315, lr:0.000686 [0.6685] 2046.3922271728516
Model 200 saved.
1 [0.1274]
2 [0.2931]
3 [0.4755]
4 [0.6948]
5 [0.8583]
6 [1.0649]
7 [1.2201]
8 [1.4055]
9 [1.6077]
10 [2.1983]
11 [2.4035]
12 [2.6523]
13 [2.8145]
14 [2.9304]
15 [3.1154]
16 [3.2915]
17 [3.6442]
18 [3.8841]
19 [4.0528]
20 [4.2246]
21 [4.417]
22 [4.6476]
23 [4.8393]
24 [5.2394]
train done
Epoch 201/1000 : Loss:0.2183, Valid loss: 0.3289, lr:0.000480 [0.6711] 1994.862713098526
1 [0.1747]
2 [0.3864]
3 [0.5755]
4 [0.8239]
5 [1.0318]
6 [1.217]
7 [1.3659]
8 [1.4913]
9 [2.1124]
10 [2.3294]
11 [2.4622]
12 [2.6427]
13 [2.8929]
14 [3.0989]
15 [3.2962]
16 [3.5025]
17 [3.8504]
18 [4.0366]
19 [4.3157]
20 [4.618]
21 [5.0867]
22 [5.2573]
23 [5.5659]
24 [5.8356]
train done
Epoch 202/1000 : Loss:0.2431, Valid loss: 0.3243, lr:0.000480 [0.6757] 1909.8076701164246
1 [0.1964]
2 [0.2958]
3 [0.537]
4 [0.948]
5 [1.2749]
6 [1.407]
7 [1.5613]
8 [1.944]
9 [2.0999]
10 [2.2855]
11 [2.5013]
12 [2.7824]
13 [2.9802]
14 [3.1377]
15 [3.5096]
16 [3.7612]
17 [3.9287]
18 [3.9288]
19 [4.1192]
20 [4.6552]
21 [4.8512]
22 [4.9793]
23 [5.1524]
24 [5.3019]
train done
Epoch 203/1000 : Loss:0.2209, Valid loss: 0.3040, lr:0.000480 [0.696] 1705.9977221488953
1 [0.0819]
2 [0.182]
3 [0.2755]
4 [0.5854]
5 [0.7714]
6 [0.9783]
7 [1.1852]
8 [1.3754]
9 [1.6979]
10 [1.988]
11 [2.1618]
12 [2.3241]
13 [2.6114]
14 [2.8286]
15 [2.9984]
16 [3.2554]
17 [3.4565]
18 [3.6141]
19 [3.8994]
20 [4.564]
21 [4.8856]
22 [5.1526]
23 [5.306]
24 [5.4994]
train done
Epoch 204/1000 : Loss:0.2291, Valid loss: 0.3269, lr:0.000480 [0.6731] 1690.4597871303558
1 [0.1772]
2 [0.336]
3 [0.6176]
4 [0.9712]
5 [1.2199]
6 [1.4688]
7 [1.576]
8 [1.7766]
9 [2.1389]
10 [2.5532]
11 [2.7114]
12 [2.8406]
13 [3.0067]
14 [3.2423]
15 [3.3274]
16 [3.4842]
17 [3.6537]
18 [3.872]
19 [4.1085]
20 [4.3544]
21 [4.5301]
22 [4.74]
23 [4.9568]
24 [5.2136]
train done
Epoch 205/1000 : Loss:0.2172, Valid loss: 0.2802, lr:0.000480 [0.7198] 1701.5821568965912
1 [0.2357]
2 [0.3661]
3 [0.6396]
4 [0.7398]
5 [1.0541]
6 [1.168]
7 [1.5089]
8 [1.8932]
9 [2.0761]
10 [2.2968]
11 [2.4153]
12 [2.5618]
13 [2.7379]
14 [2.9438]
15 [3.1571]
16 [3.3524]
17 [3.5454]
18 [3.7124]
19 [3.9747]
20 [4.1847]
21 [4.6274]
22 [4.8747]
23 [5.0351]
24 [5.2261]
train done
Epoch 206/1000 : Loss:0.2178, Valid loss: 0.2963, lr:0.000480 [0.7037] 1676.0691180229187
1 [0.296]
2 [0.763]
3 [1.0756]
4 [1.3291]
5 [1.4809]
6 [1.7017]
7 [1.8693]
8 [1.9981]
9 [2.1293]
10 [2.3514]
11 [2.5522]
12 [2.8244]
13 [3.0505]
14 [3.3606]
15 [3.6081]
16 [3.8852]
17 [4.2416]
18 [4.354]
19 [4.577]
20 [4.7629]
21 [4.9322]
22 [5.1879]
23 [5.5301]
24 [5.7511]
train done
Epoch 207/1000 : Loss:0.2396, Valid loss: 0.3006, lr:0.000480 [0.6994] 1669.415776014328
1 [0.169]
2 [0.3585]
3 [0.6263]
4 [0.8179]
5 [1.1219]
6 [1.4768]
7 [1.7412]
8 [1.9586]
9 [2.1821]
10 [2.4347]
11 [2.4347]
12 [2.7554]
13 [2.949]
14 [3.2489]
15 [3.5212]
16 [3.6634]
17 [3.9163]
18 [4.0911]
19 [4.3675]
20 [4.5376]
21 [4.8373]
22 [4.9683]
23 [5.1512]
24 [5.6167]
train done
Epoch 208/1000 : Loss:0.2340, Valid loss: 0.2859, lr:0.000480 [0.7141] 1677.947437763214
1 [0.2824]
2 [0.434]
3 [0.777]
4 [1.036]
5 [1.2407]
6 [1.4217]
7 [1.5913]
8 [2.0681]
9 [2.303]
10 [2.4434]
11 [2.5626]
12 [2.7728]
13 [2.9684]
14 [3.1733]
15 [3.3424]
16 [3.4621]
17 [3.6626]
18 [3.9066]
19 [4.0997]
20 [4.3937]
21 [4.5628]
22 [4.6957]
23 [4.9776]
24 [5.3243]
train done
Epoch 209/1000 : Loss:0.2218, Valid loss: 0.2956, lr:0.000480 [0.7044] 1676.9062278270721
1 [0.1521]
2 [0.376]
3 [0.5016]
4 [0.6324]
5 [0.8459]
6 [1.1264]
7 [1.3877]
8 [1.5353]
9 [1.7266]
10 [1.8555]
11 [2.0537]
12 [2.4155]
13 [2.6432]
14 [2.855]
15 [3.0006]
16 [3.3178]
17 [3.5334]
18 [3.9186]
19 [4.0858]
20 [4.3363]
21 [4.4741]
22 [4.7184]
23 [4.9243]
24 [5.1067]
train done
Epoch 210/1000 : Loss:0.2128, Valid loss: 0.3067, lr:0.000480 [0.6933] 1708.6095530986786
Model 210 saved.
1 [0.1188]
2 [0.2969]
3 [0.9622]
4 [1.0742]
5 [1.2258]
6 [1.3856]
7 [1.5837]
8 [1.7091]
9 [1.8259]
10 [2.1392]
11 [2.3541]
12 [2.4959]
13 [2.657]
14 [2.8745]
15 [3.0292]
16 [3.251]
17 [3.5599]
18 [3.8725]
19 [4.1248]
20 [4.2513]
21 [4.6003]
22 [4.7844]
23 [5.0271]
24 [5.1871]
train done
Epoch 211/1000 : Loss:0.2161, Valid loss: 0.3011, lr:0.000480 [0.6989] 1718.08225107193
1 [0.2333]
2 [0.4801]
3 [0.6682]
4 [0.8946]
5 [1.253]
6 [1.4965]
7 [1.644]
8 [1.876]
9 [2.0661]
10 [2.4904]
11 [2.6993]
12 [2.8533]
13 [3.033]
14 [3.1567]
15 [3.2762]
16 [3.4283]
17 [3.732]
18 [3.8409]
19 [4.0062]
20 [4.1708]
21 [4.4222]
22 [4.6088]
23 [4.833]
24 [5.0469]
train done
Epoch 212/1000 : Loss:0.2103, Valid loss: 0.2735, lr:0.000480 [0.7265] 1682.9702680110931
1 [0.3617]
2 [0.5929]
3 [0.7291]
4 [0.9274]
5 [1.1154]
6 [1.3154]
7 [1.8965]
8 [2.0026]
9 [2.1855]
10 [2.4758]
11 [2.7066]
12 [2.9493]
13 [3.1775]
14 [3.4369]
15 [3.686]
16 [3.8123]
17 [4.2083]
18 [4.3547]
19 [4.5248]
20 [4.7823]
21 [5.113]
22 [5.227]
23 [5.3947]
24 [5.5086]
train done
Epoch 213/1000 : Loss:0.2295, Valid loss: 0.2924, lr:0.000480 [0.7076] 1692.4223098754883
1 [0.2922]
2 [0.3636]
3 [0.5308]
4 [0.9522]
5 [1.0604]
6 [1.2041]
7 [1.3839]
8 [1.5551]
9 [1.7428]
10 [1.9087]
11 [2.0731]
12 [2.324]
13 [2.5778]
14 [2.7897]
15 [3.0604]
16 [3.3957]
17 [3.6269]
18 [3.9936]
19 [4.1047]
20 [4.3799]
21 [4.6077]
22 [4.7411]
23 [5.2262]
24 [5.4917]
train done
Epoch 214/1000 : Loss:0.2288, Valid loss: 0.3265, lr:0.000480 [0.6735] 1689.2714040279388
1 [0.3009]
2 [0.4742]
3 [0.7108]
4 [0.8889]
5 [1.0942]
6 [1.3641]
7 [1.6102]
8 [1.9772]
9 [2.1058]
10 [2.3667]
11 [2.8431]
12 [2.9429]
13 [3.0696]
14 [3.2678]
15 [3.4755]
16 [3.644]
17 [3.835]
18 [4.1089]
19 [4.6142]
20 [5.0586]
21 [5.4206]
22 [5.5231]
23 [5.8337]
24 [6.1267]
train done
Epoch 215/1000 : Loss:0.2553, Valid loss: 0.2697, lr:0.000480 [0.7303] 1693.373095035553
1 [0.6035]
2 [0.8506]
3 [1.0386]
4 [1.3421]
5 [1.6183]
6 [1.8731]
7 [2.1066]
8 [2.4779]
9 [2.6684]
10 [2.9844]
11 [3.1801]
12 [3.3529]
13 [3.494]
14 [3.6486]
15 [3.907]
16 [4.218]
17 [4.5014]
18 [4.7498]
19 [4.9314]
20 [5.1059]
21 [5.3277]
22 [5.5234]
23 [5.7598]
24 [5.9472]
train done
Epoch 216/1000 : Loss:0.2478, Valid loss: 0.2908, lr:0.000480 [0.7092] 1679.675615787506
1 [0.1051]
2 [0.261]
3 [0.4078]
4 [0.6205]
5 [0.8277]
6 [0.9617]
7 [1.0921]
8 [1.3194]
9 [1.5423]
10 [1.7936]
11 [1.9479]
12 [2.042]
13 [2.3485]
14 [2.5312]
15 [2.916]
16 [3.1986]
17 [3.3101]
18 [3.4814]
19 [3.8196]
20 [4.1481]
21 [4.3893]
22 [4.5526]
23 [4.7448]
24 [4.9281]
train done
Epoch 217/1000 : Loss:0.2053, Valid loss: 0.3082, lr:0.000480 [0.6918] 1665.2603697776794
1 [0.1714]
2 [0.4239]
3 [0.5679]
4 [1.0006]
5 [1.1308]
6 [1.3238]
7 [1.7206]
8 [1.9137]
9 [2.1724]
10 [2.335]
11 [2.5547]
12 [2.7962]
13 [2.9691]
14 [3.1198]
15 [3.4839]
16 [3.6547]
17 [3.7642]
18 [4.2083]
19 [4.48]
20 [4.646]
21 [4.9457]
22 [5.1211]
23 [5.3237]
24 [5.4719]
train done
Epoch 218/1000 : Loss:0.2280, Valid loss: 0.3087, lr:0.000480 [0.6913] 1675.0293231010437
1 [0.1328]
2 [0.3978]
3 [0.5721]
4 [0.8232]
5 [0.9861]
6 [1.2198]
7 [1.3862]
8 [1.6918]
9 [1.8609]
10 [2.0785]
11 [2.3539]
12 [2.6063]
13 [2.7653]
14 [3.0374]
15 [3.4036]
16 [3.5509]
17 [3.6959]
18 [3.696]
19 [3.9522]
20 [4.0702]
21 [4.2593]
22 [4.4279]
23 [4.5692]
24 [4.6804]
train done
Epoch 219/1000 : Loss:0.1950, Valid loss: 0.3033, lr:0.000480 [0.6967] 1765.5153143405914
1 [2.9087e-05]
2 [0.1311]
3 [0.3874]
4 [0.5032]
5 [0.7389]
6 [0.8811]
7 [1.0472]
8 [1.2547]
9 [1.5031]
10 [1.695]
11 [1.9027]
12 [2.1461]
13 [2.3057]
14 [2.5738]
15 [2.8227]
16 [2.9737]
17 [3.0835]
18 [3.3481]
19 [3.5908]
20 [3.7452]
21 [4.1517]
22 [4.363]
23 [4.6018]
24 [4.7721]
train done
Epoch 220/1000 : Loss:0.1988, Valid loss: 0.3104, lr:0.000480 [0.6896] 1818.1162712574005
Model 220 saved.
1 [0.3449]
2 [0.5008]
3 [0.7186]
4 [0.9191]
5 [1.1406]
6 [1.2354]
7 [1.5721]
8 [1.7443]
9 [1.945]
10 [2.0891]
11 [2.4573]
12 [2.9137]
13 [3.236]
14 [3.3496]
15 [3.5089]
16 [3.7582]
17 [4.001]
18 [4.1739]
19 [4.4111]
20 [4.6645]
21 [4.9277]
22 [5.0468]
23 [5.2161]
24 [5.4523]
train done
Epoch 221/1000 : Loss:0.2272, Valid loss: 0.2700, lr:0.000480 [0.73] 1702.278396844864
1 [0.2029]
2 [0.5651]
3 [1.2302]
4 [1.3389]
5 [1.4753]
6 [1.6269]
7 [1.7933]
8 [2.0181]
9 [2.2412]
10 [2.4858]
11 [2.6106]
12 [2.7679]
13 [3.0349]
14 [3.1671]
15 [3.2753]
16 [3.5639]
17 [3.9101]
18 [4.0986]
19 [4.3192]
20 [4.5235]
21 [4.7567]
22 [4.9916]
23 [5.2501]
24 [5.5577]
train done
Epoch 222/1000 : Loss:0.2316, Valid loss: 0.3132, lr:0.000480 [0.6868] 1634.159790277481
1 [0.2083]
2 [0.4305]
3 [0.5566]
4 [0.7751]
5 [0.9547]
6 [1.1155]
7 [1.511]
8 [1.7106]
9 [2.1]
10 [2.3584]
11 [2.5863]
12 [2.741]
13 [2.949]
14 [3.2138]
15 [3.4088]
16 [3.583]
17 [3.7465]
18 [4.0035]
19 [4.1709]
20 [4.3443]
21 [4.6771]
22 [5.0421]
23 [5.2339]
24 [5.4812]
train done
Epoch 223/1000 : Loss:0.2284, Valid loss: 0.3173, lr:0.000480 [0.6827] 1854.7978460788727
1 [0.281]
2 [0.4529]
3 [0.7311]
4 [1.0287]
5 [1.189]
6 [1.3339]
7 [1.5153]
8 [1.7571]
9 [2.0198]
10 [2.1691]
11 [2.3757]
12 [2.6638]
13 [2.816]
14 [3.2104]
15 [3.3358]
16 [3.554]
17 [3.7604]
18 [3.9471]
19 [4.2]
20 [4.3293]
21 [4.4657]
22 [4.7259]
23 [4.8035]
24 [5.1456]
train done
Epoch 224/1000 : Loss:0.2144, Valid loss: 0.3120, lr:0.000480 [0.688] 1986.2358930110931
1 [0.304]
2 [0.8155]
3 [1.0831]
4 [1.2625]
5 [1.409]
6 [1.6064]
7 [1.7423]
8 [1.9481]
9 [2.031]
10 [2.2685]
11 [2.4433]
12 [2.6564]
13 [2.8423]
14 [3.0909]
15 [3.2842]
16 [3.7701]
17 [4.1228]
18 [4.1229]
19 [4.2917]
20 [4.6658]
21 [4.9011]
22 [5.099]
23 [5.3365]
24 [5.4667]
train done
Epoch 225/1000 : Loss:0.2278, Valid loss: 0.3011, lr:0.000480 [0.6989] 1665.2324109077454
1 [0.3321]
2 [0.4548]
3 [0.6743]
4 [0.7966]
5 [0.8865]
6 [1.2085]
7 [1.4088]
8 [1.7088]
9 [1.9098]
10 [2.1457]
11 [2.2756]
12 [2.3804]
13 [2.7239]
14 [3.0633]
15 [3.2524]
16 [3.3509]
17 [3.5909]
18 [3.7884]
19 [4.2272]
20 [4.4035]
21 [4.6261]
22 [4.8048]
23 [5.0231]
24 [5.1957]
train done
Epoch 226/1000 : Loss:0.2165, Valid loss: 0.3002, lr:0.000480 [0.6998] 1655.0140671730042
1 [0.2159]
2 [0.3977]
3 [0.5577]
4 [0.7584]
5 [0.9065]
6 [1.1808]
7 [1.3125]
8 [1.4832]
9 [1.6619]
10 [1.8054]
11 [2.0008]
12 [2.2427]
13 [2.4688]
14 [2.6537]
15 [2.8]
16 [3.1999]
17 [3.4412]
18 [3.6123]
19 [3.7837]
20 [4.0975]
21 [4.2402]
22 [4.5698]
23 [4.7064]
24 [4.8634]
train done
Epoch 227/1000 : Loss:0.2026, Valid loss: 0.2982, lr:0.000480 [0.7018] 1659.6863276958466
1 [0.142]
2 [0.5236]
3 [0.7491]
4 [0.8647]
5 [1.1093]
6 [1.273]
7 [1.4675]
8 [1.6501]
9 [1.8397]
10 [2.0525]
11 [2.1751]
12 [2.3035]
13 [2.4249]
14 [2.6291]
15 [2.7938]
16 [2.9813]
17 [3.1645]
18 [3.4408]
19 [3.6097]
20 [3.9763]
21 [4.3106]
22 [4.4882]
23 [4.9156]
24 [5.0944]
train done
Epoch 228/1000 : Loss:0.2123, Valid loss: 0.3152, lr:0.000480 [0.6848] 1670.4859199523926
1 [0.1903]
2 [0.3538]
3 [0.478]
4 [0.756]
5 [1.0597]
6 [1.3132]
7 [1.5477]
8 [1.7788]
9 [1.9364]
10 [2.2381]
11 [2.6305]
12 [2.811]
13 [2.9916]
14 [3.3642]
15 [3.4979]
16 [3.7998]
17 [4.0001]
18 [4.406]
19 [4.5636]
20 [4.754]
21 [4.9253]
22 [5.1089]
23 [5.2846]
24 [5.428]
train done
Epoch 229/1000 : Loss:0.2262, Valid loss: 0.3517, lr:0.000480 [0.6483] 1654.639654159546
1 [0.1742]
2 [0.3375]
3 [0.8195]
4 [0.9379]
5 [1.2151]
6 [1.5282]
7 [1.6273]
8 [1.7807]
9 [2.1437]
10 [2.273]
11 [2.5133]
12 [2.7504]
13 [2.9502]
14 [3.0641]
15 [3.2989]
16 [3.4222]
17 [3.5817]
18 [3.7318]
19 [3.9059]
20 [4.027]
21 [4.4424]
22 [4.6992]
23 [4.8843]
24 [5.0524]
train done
Epoch 230/1000 : Loss:0.2105, Valid loss: 0.3009, lr:0.000480 [0.6991] 1657.6693618297577
Model 230 saved.
1 [0.4077]
2 [0.6261]
3 [0.7376]
4 [1.1595]
5 [1.3605]
6 [1.5409]
7 [1.6819]
8 [1.8282]
9 [1.993]
10 [2.2225]
11 [2.3423]
12 [2.5193]
13 [2.6387]
14 [2.8252]
15 [2.9537]
16 [3.0697]
17 [3.3779]
18 [3.6065]
19 [3.703]
20 [4.0223]
21 [4.2987]
22 [4.4702]
23 [4.5803]
24 [4.8342]
train done
Epoch 231/1000 : Loss:0.2014, Valid loss: 0.2930, lr:0.000480 [0.707] 1638.5415260791779
1 [0.1242]
2 [0.4675]
3 [0.6725]
4 [0.875]
5 [1.103]
6 [1.2591]
7 [1.6221]
8 [1.7223]
9 [2.0047]
10 [2.1178]
11 [2.3158]
12 [2.6817]
13 [2.7775]
14 [2.9491]
15 [3.1291]
16 [3.2962]
17 [3.4891]
18 [3.5941]
19 [3.7422]
20 [3.888]
21 [4.1125]
22 [4.3935]
23 [4.6362]
24 [4.738]
train done
Epoch 232/1000 : Loss:0.1974, Valid loss: 0.2891, lr:0.000480 [0.7109] 1697.2439198493958
1 [0.3022]
2 [0.4004]
3 [0.626]
4 [0.7166]
5 [0.8756]
6 [1.0807]
7 [1.2299]
8 [1.4743]
9 [1.6227]
10 [1.8779]
11 [2.0205]
12 [2.1943]
13 [2.4085]
14 [2.587]
15 [2.7749]
16 [2.928]
17 [3.136]
18 [3.4583]
19 [3.577]
20 [3.8139]
21 [4.0377]
22 [4.2332]
23 [4.3807]
24 [4.4695]
train done
Epoch 233/1000 : Loss:0.1862, Valid loss: 0.3144, lr:0.000480 [0.6856] 1752.2381649017334
1 [0.1918]
2 [0.4693]
3 [0.671]
4 [0.7893]
5 [0.9538]
6 [1.2336]
7 [1.4095]
8 [1.5098]
9 [1.7524]
10 [1.9642]
11 [2.183]
12 [2.4066]
13 [2.6394]
14 [2.8109]
15 [3.0668]
16 [3.2337]
17 [3.3977]
18 [3.5544]
19 [3.9253]
20 [4.1119]
21 [4.2535]
22 [4.4589]
23 [4.9617]
24 [5.1633]
train done
Epoch 234/1000 : Loss:0.2151, Valid loss: 0.3174, lr:0.000480 [0.6826] 2039.7968158721924
1 [0.3715]
2 [0.5104]
3 [0.8135]
4 [1.2335]
5 [1.3799]
6 [1.5556]
7 [1.7787]
8 [1.9696]
9 [2.5683]
10 [2.7911]
11 [3.1089]
12 [3.2544]
13 [3.3892]
14 [3.5954]
15 [3.729]
16 [3.8817]
17 [3.9853]
18 [4.24]
19 [4.8676]
20 [5.0622]
21 [5.275]
22 [5.4728]
23 [5.647]
24 [5.8089]
train done
Epoch 235/1000 : Loss:0.2420, Valid loss: 0.3131, lr:0.000480 [0.6869] 2074.707183122635
1 [0.2247]
2 [0.3891]
3 [0.5112]
4 [0.6847]
5 [1.3551]
6 [1.5816]
7 [1.8064]
8 [2.023]
9 [2.3547]
10 [2.6006]
11 [2.8385]
12 [3.0237]
13 [3.2507]
14 [3.49]
15 [3.6523]
16 [3.894]
17 [4.2479]
18 [4.43]
19 [4.6419]
20 [4.8407]
21 [4.9737]
22 [5.0908]
23 [5.5374]
24 [5.7108]
train done
Epoch 236/1000 : Loss:0.2379, Valid loss: 0.3113, lr:0.000480 [0.6887] 2196.117212295532
1 [0.2603]
2 [0.5982]
3 [0.8331]
4 [0.9393]
5 [1.0888]
6 [1.261]
7 [1.6308]
8 [1.8242]
9 [1.9606]
10 [2.1349]
11 [2.2311]
12 [2.3583]
13 [2.5711]
14 [2.906]
15 [3.1392]
16 [3.3831]
17 [3.5563]
18 [3.7299]
19 [3.9675]
20 [4.0984]
21 [4.2589]
22 [4.4133]
23 [4.617]
24 [4.7674]
train done
Epoch 237/1000 : Loss:0.1986, Valid loss: 0.3204, lr:0.000480 [0.6796] 2123.3834459781647
1 [0.1572]
2 [0.38]
3 [0.4799]
4 [0.7297]
5 [0.9549]
6 [1.0817]
7 [1.2187]
8 [1.3579]
9 [2.0732]
10 [2.187]
11 [2.5387]
12 [2.7886]
13 [3.0781]
14 [3.2592]
15 [3.3623]
16 [3.5482]
17 [3.8742]
18 [4.0575]
19 [4.1568]
20 [4.2846]
21 [4.5832]
22 [4.737]
23 [4.9644]
24 [5.1784]
train done
Epoch 238/1000 : Loss:0.2158, Valid loss: 0.2891, lr:0.000480 [0.7109] 1929.5891480445862
1 [0.2983]
2 [0.4185]
3 [0.5585]
4 [0.7796]
5 [1.0262]
6 [1.2038]
7 [1.4254]
8 [1.5474]
9 [1.8138]
10 [2.0014]
11 [2.1284]
12 [2.4608]
13 [2.6333]
14 [2.8828]
15 [3.2521]
16 [3.4017]
17 [3.6659]
18 [3.8416]
19 [3.927]
20 [4.1015]
21 [4.4728]
22 [4.6885]
23 [4.854]
24 [4.9574]
train done
Epoch 239/1000 : Loss:0.2066, Valid loss: 0.2783, lr:0.000480 [0.7217] 1815.9055380821228
1 [0.2421]
2 [0.4938]
3 [0.6785]
4 [0.8296]
5 [1.0157]
6 [1.1575]
7 [1.3525]
8 [1.7994]
9 [1.9187]
10 [2.0859]
11 [2.3132]
12 [2.5618]
13 [2.7669]
14 [2.9653]
15 [3.0656]
16 [3.1645]
17 [3.3802]
18 [3.5879]
19 [3.748]
20 [3.8246]
21 [4.1099]
22 [4.4857]
23 [4.7524]
24 [4.9252]
train done
Epoch 240/1000 : Loss:0.2052, Valid loss: 0.2752, lr:0.000480 [0.7248] 1819.6510338783264
Model 240 saved.
1 [0.375]
2 [0.7099]
3 [0.8805]
4 [0.9783]
5 [1.0513]
6 [1.6919]
7 [1.9348]
8 [2.1356]
9 [2.2736]
10 [2.3686]
11 [2.5702]
12 [2.6982]
13 [2.842]
14 [3.0477]
15 [3.1495]
16 [3.7061]
17 [3.9454]
18 [4.1606]
19 [4.3609]
20 [4.5357]
21 [4.6882]
22 [4.8971]
23 [5.1987]
24 [5.501]
train done
Epoch 241/1000 : Loss:0.2292, Valid loss: 0.3167, lr:0.000480 [0.6833] 1805.6461608409882
1 [0.1665]
2 [0.335]
3 [0.5636]
4 [0.7725]
5 [0.9927]
6 [1.2564]
7 [1.6183]
8 [1.7469]
9 [1.8729]
10 [2.2575]
11 [2.3843]
12 [2.4962]
13 [2.6546]
14 [2.874]
15 [3.058]
16 [3.3348]
17 [3.6634]
18 [3.8483]
19 [4.0673]
20 [4.4481]
21 [4.5983]
22 [4.8619]
23 [5.1697]
24 [5.3171]
train done
Epoch 242/1000 : Loss:0.2215, Valid loss: 0.3255, lr:0.000480 [0.6745] 1804.1438641548157
1 [0.1118]
2 [0.2513]
3 [0.6436]
4 [0.8004]
5 [0.948]
6 [1.088]
7 [1.2978]
8 [1.5687]
9 [1.9956]
10 [2.2395]
11 [2.3532]
12 [2.6391]
13 [2.8299]
14 [2.9667]
15 [3.4167]
16 [3.8683]
17 [4.1193]
18 [4.3449]
19 [4.5315]
20 [4.7636]
21 [4.9155]
22 [5.0505]
23 [5.2049]
24 [5.3832]
train done
Epoch 243/1000 : Loss:0.2243, Valid loss: 0.3391, lr:0.000480 [0.6609] 1958.4387710094452
1 [0.5499]
2 [0.6923]
3 [0.8263]
4 [1.0351]
5 [1.1303]
6 [1.2472]
7 [1.4717]
8 [1.6341]
9 [1.9396]
10 [2.0263]
11 [2.1692]
12 [2.4299]
13 [2.6668]
14 [2.851]
15 [3.1857]
16 [3.5023]
17 [3.6801]
18 [3.9502]
19 [4.1297]
20 [4.3155]
21 [4.6269]
22 [4.8549]
23 [5.0595]
24 [5.4128]
train done
Epoch 244/1000 : Loss:0.2255, Valid loss: 0.2840, lr:0.000480 [0.716] 2249.2544679641724
1 [0.2078]
2 [0.3335]
3 [0.4808]
4 [0.775]
5 [0.9125]
6 [1.1527]
7 [1.3179]
8 [1.4906]
9 [1.7156]
10 [1.925]
11 [2.0147]
12 [2.5501]
13 [2.9033]
14 [3.1157]
15 [3.3326]
16 [3.6228]
17 [3.8726]
18 [4.247]
19 [4.5707]
20 [4.6903]
21 [4.904]
22 [5.1017]
23 [5.595]
24 [5.7732]
train done
Epoch 245/1000 : Loss:0.2406, Valid loss: 0.3004, lr:0.000480 [0.6996] 2309.7397680282593
1 [0.1104]
2 [0.3185]
3 [0.5009]
4 [0.589]
5 [0.6982]
6 [0.9774]
7 [1.1253]
8 [1.3585]
9 [1.5178]
10 [1.7818]
11 [2.0726]
12 [2.3777]
13 [2.6584]
14 [3.0906]
15 [3.2624]
16 [3.4104]
17 [3.547]
18 [3.7307]
19 [4.0113]
20 [4.0933]
21 [4.4434]
22 [4.6954]
23 [5.0591]
24 [5.3215]
train done
Epoch 246/1000 : Loss:0.2217, Valid loss: 0.2924, lr:0.000480 [0.7076] 2368.091624736786
1 [0.241]
2 [0.5699]
3 [0.8622]
4 [1.1105]
5 [1.5058]
6 [1.6477]
7 [1.7868]
8 [2.1568]
9 [2.5882]
10 [2.943]
11 [3.403]
12 [3.9789]
13 [4.2845]
14 [4.5554]
15 [4.7388]
16 [4.8984]
17 [5.0902]
18 [5.34]
19 [5.5012]
20 [5.6901]
21 [5.7961]
22 [5.9599]
23 [6.2114]
24 [6.3225]
train done
Epoch 247/1000 : Loss:0.2634, Valid loss: 0.3081, lr:0.000480 [0.6919] 2171.194000005722
1 [0.3102]
2 [0.571]
3 [0.8488]
4 [1.007]
5 [1.3974]
6 [1.5674]
7 [1.6744]
8 [1.8864]
9 [2.3679]
10 [2.5713]
11 [2.6789]
12 [2.8995]
13 [3.1819]
14 [3.452]
15 [3.6229]
16 [3.8836]
17 [4.1388]
18 [4.2632]
19 [4.5134]
20 [4.6617]
21 [5.0285]
22 [5.3367]
23 [5.5214]
24 [5.7718]
train done
Epoch 248/1000 : Loss:0.2405, Valid loss: 0.2995, lr:0.000480 [0.7005] 1727.2014210224152
1 [0.2686]
2 [0.4916]
3 [0.7227]
4 [0.8597]
5 [1.0506]
6 [1.2511]
7 [1.4159]
8 [1.6246]
9 [1.8405]
10 [1.999]
11 [2.1657]
12 [2.485]
13 [3.0284]
14 [3.3414]
15 [3.5468]
16 [3.6586]
17 [3.8204]
18 [3.9357]
19 [4.0989]
20 [4.3283]
21 [4.4569]
22 [4.7657]
23 [4.957]
24 [5.1387]
train done
Epoch 249/1000 : Loss:0.2141, Valid loss: 0.2907, lr:0.000480 [0.7093] 1724.1352860927582
1 [0.4024]
2 [0.516]
3 [0.7992]
4 [1.09]
5 [1.6888]
6 [1.904]
7 [2.0974]
8 [2.2574]
9 [2.606]
10 [2.8353]
11 [3.0488]
12 [3.1924]
13 [3.3207]
14 [3.6048]
15 [3.7797]
16 [4.107]
17 [4.3341]
18 [4.6057]
19 [4.7282]
20 [5.1586]
21 [5.3831]
22 [5.4802]
23 [5.5696]
24 [5.7946]
train done
Epoch 250/1000 : Loss:0.2414, Valid loss: 0.2838, lr:0.000480 [0.7162] 1702.5875828266144
Model 250 saved.
1 [0.1331]
2 [0.3122]
3 [0.6531]
4 [0.7639]
5 [1.1039]
6 [1.3321]
7 [1.8573]
8 [2.0155]
9 [2.1061]
10 [2.268]
11 [2.4309]
12 [2.5761]
13 [2.8376]
14 [2.997]
15 [3.2425]
16 [3.4056]
17 [3.5401]
18 [3.7579]
19 [3.9357]
20 [4.1115]
21 [4.3737]
22 [4.6433]
23 [4.8378]
24 [4.9652]
train done
Epoch 251/1000 : Loss:0.2069, Valid loss: 0.2806, lr:0.000336 [0.7194] 1698.1108839511871
1 [0.2092]
2 [0.4058]
3 [0.6262]
4 [0.7437]
5 [0.9247]
6 [1.0595]
7 [1.2321]
8 [1.3966]
9 [1.6409]
10 [1.902]
11 [2.2621]
12 [2.515]
13 [2.7469]
14 [2.9809]
15 [3.0607]
16 [3.4478]
17 [3.6302]
18 [3.8544]
19 [4.0181]
20 [4.1532]
21 [4.3175]
22 [4.4589]
23 [4.6677]
24 [4.8905]
train done
Epoch 252/1000 : Loss:0.2038, Valid loss: 0.2941, lr:0.000336 [0.7059] 1737.4847781658173
1 [0.1915]
2 [0.3436]
3 [0.7125]
4 [0.9068]
5 [1.0992]
6 [1.2436]
7 [1.4333]
8 [1.6753]
9 [1.8877]
10 [2.1621]
11 [2.5554]
12 [2.7783]
13 [2.935]
14 [3.5374]
15 [3.6888]
16 [3.941]
17 [4.0839]
18 [4.1655]
19 [4.5458]
20 [4.7557]
21 [4.8901]
22 [5.0162]
23 [5.2279]
24 [5.4439]
train done
Epoch 253/1000 : Loss:0.2268, Valid loss: 0.2652, lr:0.000336 [0.7348] 1712.395486831665
1 [0.2166]
2 [0.3841]
3 [0.5401]
4 [0.6741]
5 [0.7674]
6 [0.9436]
7 [1.2196]
8 [1.4663]
9 [1.7261]
10 [1.9764]
11 [2.1481]
12 [2.2991]
13 [2.5296]
14 [2.665]
15 [2.7745]
16 [2.9854]
17 [3.2092]
18 [3.4321]
19 [3.64]
20 [3.8507]
21 [4.0373]
22 [4.2592]
23 [4.6118]
24 [4.6977]
train done
Epoch 254/1000 : Loss:0.1957, Valid loss: 0.2678, lr:0.000336 [0.7322] 1713.79931306839
1 [0.1972]
2 [0.5546]
3 [0.7393]
4 [1.0703]
5 [1.2368]
6 [1.3643]
7 [1.5853]
8 [1.9253]
9 [2.1201]
10 [2.2811]
11 [2.3627]
12 [2.5312]
13 [2.7147]
14 [2.9047]
15 [3.1927]
16 [3.2718]
17 [3.6552]
18 [3.7526]
19 [3.9395]
20 [4.1178]
21 [4.3636]
22 [4.5429]
23 [4.699]
24 [5.0061]
train done
Epoch 255/1000 : Loss:0.2086, Valid loss: 0.2761, lr:0.000336 [0.7239] 1727.8056991100311
1 [0.3109]
2 [0.4672]
3 [0.625]
4 [0.7171]
5 [0.9398]
6 [1.0848]
7 [1.2263]
8 [1.3386]
9 [1.4838]
10 [1.5747]
11 [1.8805]
12 [2.1529]
13 [2.3457]
14 [2.445]
15 [2.857]
16 [3.0402]
17 [3.1548]
18 [3.3819]
19 [3.5425]
20 [3.7345]
21 [4.2368]
22 [4.3973]
23 [4.6764]
24 [4.8306]
train done
Epoch 256/1000 : Loss:0.2013, Valid loss: 0.2665, lr:0.000336 [0.7335] 1712.4695529937744
1 [0.2216]
2 [0.4431]
3 [0.6127]
4 [0.7602]
5 [0.9606]
6 [1.1532]
7 [1.2359]
8 [1.3428]
9 [1.475]
10 [1.6376]
11 [1.8055]
12 [1.9256]
13 [2.146]
14 [2.3076]
15 [2.5198]
16 [2.7403]
17 [2.9259]
18 [3.1857]
19 [3.5595]
20 [3.7088]
21 [3.9591]
22 [4.0845]
23 [4.3506]
24 [4.5249]
train done
Epoch 257/1000 : Loss:0.1885, Valid loss: 0.2902, lr:0.000336 [0.7098] 1692.6621189117432
1 [0.2323]
2 [0.3275]
3 [0.5561]
4 [0.764]
5 [0.8705]
6 [1.0505]
7 [1.2195]
8 [1.7189]
9 [1.8817]
10 [2.1042]
11 [2.2845]
12 [2.4079]
13 [2.4855]
14 [2.6654]
15 [2.7627]
16 [2.9126]
17 [3.081]
18 [3.3343]
19 [3.5621]
20 [4.138]
21 [4.2529]
22 [4.3811]
23 [4.5259]
24 [4.7757]
train done
Epoch 258/1000 : Loss:0.1990, Valid loss: 0.2867, lr:0.000336 [0.7133] 1710.1299781799316
1 [0.1786]
2 [0.3575]
3 [0.4369]
4 [0.4369]
5 [0.7283]
6 [0.9448]
7 [1.2174]
8 [1.4319]
9 [1.6002]
10 [1.8481]
11 [1.9662]
12 [2.2564]
13 [2.4353]
14 [2.5557]
15 [2.6682]
16 [2.9054]
17 [3.3072]
18 [3.4259]
19 [3.6084]
20 [3.7103]
21 [3.9331]
22 [4.1755]
23 [4.3612]
24 [4.8573]
train done
Epoch 259/1000 : Loss:0.2024, Valid loss: 0.2630, lr:0.000336 [0.737] 1719.5636529922485
1 [0.1576]
2 [0.2526]
3 [0.4343]
4 [0.5541]
5 [0.7796]
6 [1.1494]
7 [1.5931]
8 [1.7818]
9 [1.9452]
10 [2.1693]
11 [2.245]
12 [2.3427]
13 [2.441]
14 [2.5854]
15 [2.8017]
16 [3.1125]
17 [3.2958]
18 [3.446]
19 [3.63]
20 [3.8033]
21 [4.0512]
22 [4.3708]
23 [4.5843]
24 [4.8949]
train done
Epoch 260/1000 : Loss:0.2040, Valid loss: 0.2895, lr:0.000336 [0.7105] 1722.7108149528503
Model 260 saved.
1 [0.1628]
2 [0.3272]
3 [0.4706]
4 [0.6908]
5 [1.0937]
6 [1.2688]
7 [1.5334]
8 [1.6951]
9 [2.0473]
10 [2.2106]
11 [2.5576]
12 [2.723]
13 [2.9548]
14 [3.2304]
15 [3.3598]
16 [3.5958]
17 [3.6888]
18 [3.9658]
19 [4.1499]
20 [4.2352]
21 [4.3661]
22 [4.5096]
23 [4.6443]
24 [4.9779]
train done
Epoch 261/1000 : Loss:0.2074, Valid loss: 0.2877, lr:0.000336 [0.7123] 1709.6559219360352
1 [0.127]
2 [0.28]
3 [0.4969]
4 [0.6635]
5 [0.8155]
6 [1.0501]
7 [1.1862]
8 [1.3684]
9 [1.7783]
10 [2.0194]
11 [2.1696]
12 [2.3665]
13 [2.5269]
14 [2.6218]
15 [2.7888]
16 [3.167]
17 [3.488]
18 [3.6879]
19 [3.9449]
20 [4.0525]
21 [4.2878]
22 [4.4892]
23 [4.6774]
24 [5.0668]
train done
Epoch 262/1000 : Loss:0.2111, Valid loss: 0.2705, lr:0.000336 [0.7295] 1712.5958461761475
1 [0.2463]
2 [0.3978]
3 [0.8585]
4 [1.0081]
5 [1.184]
6 [1.432]
7 [1.6742]
8 [1.8206]
9 [1.9852]
10 [2.2584]
11 [2.4452]
12 [2.5367]
13 [2.6842]
14 [2.8761]
15 [3.095]
16 [3.4091]
17 [3.5068]
18 [3.66]
19 [3.7933]
20 [3.8637]
21 [4.0367]
22 [4.1841]
23 [4.3663]
24 [4.5682]
train done
Epoch 263/1000 : Loss:0.1903, Valid loss: 0.2865, lr:0.000336 [0.7135] 1707.1874549388885
1 [0.0993]
2 [0.302]
3 [0.5883]
4 [0.7218]
5 [1.1177]
6 [1.2522]
7 [1.3276]
8 [1.5638]
9 [1.6838]
10 [1.9707]
11 [2.1525]
12 [2.4109]
13 [2.7929]
14 [3.0314]
15 [3.1368]
16 [3.2336]
17 [3.3752]
18 [3.5999]
19 [3.9429]
20 [4.0679]
21 [4.4956]
22 [4.6721]
23 [4.814]
24 [5.0317]
train done
Epoch 264/1000 : Loss:0.2097, Valid loss: 0.2904, lr:0.000336 [0.7096] 1728.1240360736847
1 [0.3209]
2 [0.527]
3 [0.527]
4 [0.7318]
5 [0.9075]
6 [1.0391]
7 [1.3784]
8 [1.6072]
9 [1.72]
10 [2.0934]
11 [2.1781]
12 [2.4034]
13 [2.7253]
14 [2.8295]
15 [3.0712]
16 [3.2143]
17 [3.3492]
18 [3.5483]
19 [3.7572]
20 [3.9143]
21 [4.0839]
22 [4.439]
23 [4.64]
24 [4.9245]
train done
Epoch 265/1000 : Loss:0.2052, Valid loss: 0.2727, lr:0.000336 [0.7273] 1699.3718180656433
1 [0.0873]
2 [0.2508]
3 [0.4757]
4 [0.6812]
5 [1.2034]
6 [1.3845]
7 [1.6]
8 [1.8671]
9 [2.0045]
10 [2.1634]
11 [2.314]
12 [2.4574]
13 [2.57]
14 [2.853]
15 [2.9826]
16 [3.1237]
17 [3.3951]
18 [3.5545]
19 [3.9119]
20 [4.1988]
21 [4.4645]
22 [4.6237]
23 [4.8011]
24 [4.9867]
train done
Epoch 266/1000 : Loss:0.2078, Valid loss: 0.2748, lr:0.000336 [0.7252] 1714.0999476909637
1 [0.4708]
2 [0.6451]
3 [0.7914]
4 [0.9711]
5 [1.196]
6 [1.3783]
7 [1.4956]
8 [1.71]
9 [1.8619]
10 [2.0644]
11 [2.2391]
12 [2.4343]
13 [2.5885]
14 [2.7655]
15 [2.8567]
16 [3.0219]
17 [3.2306]
18 [3.3911]
19 [3.805]
20 [4.134]
21 [4.2866]
22 [4.4555]
23 [4.7171]
24 [4.9278]
train done
Epoch 267/1000 : Loss:0.2053, Valid loss: 0.2802, lr:0.000336 [0.7198] 1685.1264939308167
1 [0.2042]
2 [0.3077]
3 [0.4491]
4 [0.5944]
5 [0.8885]
6 [1.0315]
7 [1.3664]
8 [1.5385]
9 [1.628]
10 [1.96]
11 [2.1004]
12 [2.3025]
13 [2.4622]
14 [2.7405]
15 [2.9335]
16 [3.0851]
17 [3.304]
18 [3.4591]
19 [3.6981]
20 [3.8924]
21 [4.1661]
22 [4.343]
23 [4.4502]
24 [4.5764]
train done
Epoch 268/1000 : Loss:0.1907, Valid loss: 0.2771, lr:0.000336 [0.7229] 1700.8863971233368
1 [0.2144]
2 [0.2968]
3 [0.522]
4 [0.8115]
5 [0.9255]
6 [1.1009]
7 [1.2169]
8 [1.4399]
9 [1.832]
10 [2.0919]
11 [2.2647]
12 [2.4941]
13 [2.7413]
14 [2.9157]
15 [3.0917]
16 [3.2538]
17 [3.4611]
18 [3.6327]
19 [3.8096]
20 [3.9312]
21 [4.0228]
22 [4.1469]
23 [4.3249]
24 [4.4076]
train done
Epoch 269/1000 : Loss:0.1836, Valid loss: 0.3013, lr:0.000336 [0.6987] 1695.0497736930847
1 [0.2562]
2 [0.4923]
3 [0.9919]
4 [1.1712]
5 [1.4135]
6 [1.5714]
7 [2.0635]
8 [2.2899]
9 [2.5319]
10 [2.7019]
11 [2.8491]
12 [3.0596]
13 [3.1479]
14 [3.341]
15 [3.4969]
16 [3.6771]
17 [3.859]
18 [4.1333]
19 [4.359]
20 [4.6639]
21 [4.9532]
22 [5.0904]
23 [5.2273]
24 [5.4402]
train done
Epoch 270/1000 : Loss:0.2267, Valid loss: 0.2980, lr:0.000336 [0.702] 1896.2037601470947
Model 270 saved.
1 [0.2607]
2 [0.3747]
3 [0.5464]
4 [1.1551]
5 [1.3685]
6 [1.5294]
7 [1.7122]
8 [1.9856]
9 [2.1344]
10 [2.2651]
11 [2.5029]
12 [2.7154]
13 [3.0679]
14 [3.2169]
15 [3.4932]
16 [3.6861]
17 [3.9097]
18 [4.0526]
19 [4.2092]
20 [4.3659]
21 [4.5238]
22 [4.6738]
23 [4.8276]
24 [5.2232]
train done
Epoch 271/1000 : Loss:0.2176, Valid loss: 0.2877, lr:0.000336 [0.7123] 2267.346224784851
1 [0.1283]
2 [0.2919]
3 [0.5745]
4 [0.8711]
5 [1.3456]
6 [1.7503]
7 [1.8475]
8 [2.0549]
9 [2.3126]
10 [2.455]
11 [2.7097]
12 [2.8567]
13 [2.9801]
14 [3.207]
15 [3.4424]
16 [3.5983]
17 [3.7193]
18 [3.9766]
19 [4.2555]
20 [4.442]
21 [4.5438]
22 [4.6845]
23 [4.834]
24 [5.1158]
train done
Epoch 272/1000 : Loss:0.2132, Valid loss: 0.3350, lr:0.000336 [0.665] 2103.4635078907013
1 [0.3106]
2 [0.4643]
3 [0.5408]
4 [0.7489]
5 [0.8755]
6 [1.1719]
7 [1.2798]
8 [1.4704]
9 [1.6926]
10 [1.8813]
11 [2.2017]
12 [2.3602]
13 [2.6257]
14 [2.7546]
15 [2.8391]
16 [2.9663]
17 [3.0695]
18 [3.2843]
19 [3.6002]
20 [3.8072]
21 [4.0129]
22 [4.1448]
23 [4.2678]
24 [4.404]
train done
Epoch 273/1000 : Loss:0.1835, Valid loss: 0.2982, lr:0.000336 [0.7018] 2160.909554004669
1 [0.4183]
2 [0.5969]
3 [0.6902]
4 [0.8497]
5 [1.0793]
6 [1.3815]
7 [1.5755]
8 [1.6824]
9 [1.7647]
10 [1.8812]
11 [2.018]
12 [2.2282]
13 [2.3991]
14 [2.5786]
15 [2.74]
16 [2.8775]
17 [3.045]
18 [3.1828]
19 [3.3029]
20 [3.6008]
21 [3.7516]
22 [3.9699]
23 [4.1097]
24 [4.4594]
train done
Epoch 274/1000 : Loss:0.1858, Valid loss: 0.3130, lr:0.000336 [0.687] 2335.6368288993835
1 [0.2226]
2 [0.4569]
3 [0.4569]
4 [0.691]
5 [0.8259]
6 [1.1043]
7 [1.1877]
8 [1.2906]
9 [1.4589]
10 [1.7673]
11 [1.9906]
12 [2.189]
13 [2.6852]
14 [2.8441]
15 [3.0595]
16 [3.2057]
17 [3.3954]
18 [3.6548]
19 [3.7343]
20 [3.9547]
21 [4.1129]
22 [4.2689]
23 [4.4321]
24 [4.5718]
train done
Epoch 275/1000 : Loss:0.1905, Valid loss: 0.3020, lr:0.000336 [0.698] 2152.577651977539
1 [0.2149]
2 [0.3745]
3 [0.6965]
4 [1.0294]
5 [1.1528]
6 [1.3122]
7 [1.5707]
8 [1.6761]
9 [1.9727]
10 [2.1435]
11 [2.3318]
12 [2.5721]
13 [2.7822]
14 [3.0143]
15 [3.2294]
16 [3.3756]
17 [3.6316]
18 [3.7458]
19 [3.8271]
20 [4.0547]
21 [4.2127]
22 [4.3606]
23 [4.4614]
24 [4.55]
train done
Epoch 276/1000 : Loss:0.1896, Valid loss: 0.2837, lr:0.000336 [0.7163] 2270.508509874344
1 [0.2742]
2 [0.3564]
3 [0.4588]
4 [0.5963]
5 [0.7324]
6 [1.0728]
7 [1.2997]
8 [1.4829]
9 [1.623]
10 [1.8427]
11 [2.0228]
12 [2.1269]
13 [2.3261]
14 [2.5254]
15 [2.7575]
16 [2.8766]
17 [3.0236]
18 [3.5545]
19 [3.7122]
20 [3.9595]
21 [4.179]
22 [4.3163]
23 [4.6028]
24 [4.7199]
train done
Epoch 277/1000 : Loss:0.1967, Valid loss: 0.2826, lr:0.000336 [0.7174] 2402.504993915558
1 [1.4901e-06]
2 [0.1966]
3 [0.5021]
4 [0.6086]
5 [0.8244]
6 [0.9815]
7 [1.1233]
8 [1.3731]
9 [1.6056]
10 [1.7348]
11 [1.9866]
12 [2.1852]
13 [2.3235]
14 [2.7801]
15 [3.0818]
16 [3.2607]
17 [3.3989]
18 [3.6728]
19 [3.8096]
20 [3.9766]
21 [4.1799]
22 [4.2979]
23 [4.5698]
24 [4.7037]
train done
Epoch 278/1000 : Loss:0.1960, Valid loss: 0.2783, lr:0.000336 [0.7217] 2085.917619943619
1 [0.3548]
2 [0.4616]
3 [0.5906]
4 [0.7527]
5 [0.932]
6 [1.0736]
7 [1.2715]
8 [1.3534]
9 [1.5552]
10 [1.6775]
11 [1.8748]
12 [2.104]
13 [2.3614]
14 [2.7535]
15 [2.9975]
16 [3.1722]
17 [3.3679]
18 [3.5865]
19 [3.8238]
20 [4.2053]
21 [4.3324]
22 [4.7009]
23 [4.9286]
24 [5.305]
train done
Epoch 279/1000 : Loss:0.2210, Valid loss: 0.2939, lr:0.000336 [0.7061] 1994.0702528953552
1 [0.5103]
2 [0.6798]
3 [0.8796]
4 [1.0692]
5 [1.2071]
6 [1.4267]
7 [1.6353]
8 [1.9025]
9 [2.0872]
10 [2.5159]
11 [2.7963]
12 [3.1408]
13 [3.3267]
14 [3.4395]
15 [3.5931]
16 [3.7738]
17 [3.9805]
18 [4.1504]
19 [4.3474]
20 [4.5439]
21 [4.7122]
22 [4.8564]
23 [5.1415]
24 [5.2545]
train done
Epoch 280/1000 : Loss:0.2189, Valid loss: 0.2955, lr:0.000336 [0.7045] 1770.124263048172
Model 280 saved.
1 [0.1338]
2 [0.2622]
3 [0.617]
4 [0.9496]
5 [1.1068]
6 [1.2244]
7 [1.4017]
8 [1.5485]
9 [1.6296]
10 [1.8148]
11 [2.0808]
12 [2.1523]
13 [2.3728]
14 [2.9065]
15 [3.1056]
16 [3.2769]
17 [3.5119]
18 [3.7549]
19 [4.0333]
20 [4.1788]
21 [4.4973]
22 [4.6165]
23 [5.0011]
24 [5.1106]
train done
Epoch 281/1000 : Loss:0.2129, Valid loss: 0.2833, lr:0.000336 [0.7167] 1733.0326311588287
1 [0.1477]
2 [0.3996]
3 [0.6908]
4 [0.9132]
5 [1.0714]
6 [1.3297]
7 [1.5652]
8 [1.6864]
9 [1.8928]
10 [2.0708]
11 [2.2137]
12 [2.3767]
13 [2.5632]
14 [2.6511]
15 [2.9307]
16 [3.0556]
17 [3.2505]
18 [3.5126]
19 [3.6092]
20 [3.7842]
21 [3.8909]
22 [4.0492]
23 [4.2312]
24 [4.4765]
train done
Epoch 282/1000 : Loss:0.1865, Valid loss: 0.2797, lr:0.000336 [0.7203] 1724.559473991394
1 [0.2615]
2 [0.3889]
3 [0.5347]
4 [0.7601]
5 [0.8774]
6 [1.1316]
7 [1.3471]
8 [1.4757]
9 [1.6457]
10 [1.8048]
11 [2.202]
12 [2.322]
13 [2.6707]
14 [2.8831]
15 [3.1157]
16 [3.299]
17 [3.4473]
18 [3.8672]
19 [4.0064]
20 [4.1675]
21 [4.3317]
22 [4.4688]
23 [4.5766]
24 [4.8153]
train done
Epoch 283/1000 : Loss:0.2006, Valid loss: 0.3010, lr:0.000336 [0.699] 1745.163758277893
1 [0.2517]
2 [0.4022]
3 [0.7827]
4 [0.9565]
5 [1.2454]
6 [1.4908]
7 [1.739]
8 [1.8503]
9 [2.1574]
10 [2.3387]
11 [2.6194]
12 [2.789]
13 [2.9411]
14 [3.0566]
15 [3.2748]
16 [3.3969]
17 [3.4868]
18 [3.6903]
19 [3.881]
20 [4.1229]
21 [4.2356]
22 [4.5001]
23 [4.6706]
24 [4.8321]
train done
Epoch 284/1000 : Loss:0.2013, Valid loss: 0.2676, lr:0.000336 [0.7324] 1726.733206987381
1 [0.1174]
2 [0.1864]
3 [0.3788]
4 [0.5691]
5 [0.6853]
6 [0.9585]
7 [1.0449]
8 [1.3195]
9 [1.4809]
10 [1.6647]
11 [1.796]
12 [1.8737]
13 [2.0488]
14 [2.4293]
15 [2.5978]
16 [2.8129]
17 [3.1446]
18 [3.2466]
19 [3.4315]
20 [3.56]
21 [3.8449]
22 [4.053]
23 [4.2717]
24 [4.6277]
train done
Epoch 285/1000 : Loss:0.1928, Valid loss: 0.2851, lr:0.000336 [0.7149] 1749.9705803394318
1 [0.1713]
2 [0.3764]
3 [0.5423]
4 [0.6642]
5 [0.8754]
6 [1.0486]
7 [1.123]
8 [1.3014]
9 [1.571]
10 [1.7291]
11 [1.9773]
12 [2.0782]
13 [2.2133]
14 [2.4066]
15 [2.5098]
16 [2.7333]
17 [2.8377]
18 [2.982]
19 [3.1036]
20 [3.294]
21 [3.5655]
22 [3.8742]
23 [4.0417]
24 [4.2868]
train done
Epoch 286/1000 : Loss:0.1786, Valid loss: 0.2971, lr:0.000336 [0.7029] 1748.9762558937073
1 [0.2009]
2 [0.4929]
3 [0.7066]
4 [0.8149]
5 [1.1107]
6 [1.3155]
7 [1.6785]
8 [1.8445]
9 [2.0175]
10 [2.1319]
11 [2.2737]
12 [2.4226]
13 [2.6599]
14 [2.8557]
15 [3.1556]
16 [3.307]
17 [3.5618]
18 [3.6596]
19 [3.8214]
20 [4.182]
21 [4.2723]
22 [4.3692]
23 [4.5824]
24 [4.744]
train done
Epoch 287/1000 : Loss:0.1977, Valid loss: 0.2760, lr:0.000336 [0.724] 1736.9694910049438
1 [0.0997]
2 [0.2598]
3 [0.5415]
4 [0.7507]
5 [0.8554]
6 [1.1384]
7 [1.4665]
8 [1.6156]
9 [1.8146]
10 [2.2555]
11 [2.4607]
12 [2.5874]
13 [2.8349]
14 [2.9565]
15 [3.1559]
16 [3.4196]
17 [3.5982]
18 [3.7524]
19 [3.9309]
20 [4.012]
21 [4.1164]
22 [4.2802]
23 [4.7039]
24 [4.9202]
train done
Epoch 288/1000 : Loss:0.2050, Valid loss: 0.3126, lr:0.000336 [0.6874] 1791.7289309501648
1 [0.1682]
2 [0.4025]
3 [0.5929]
4 [0.9013]
5 [1.066]
6 [1.163]
7 [1.3628]
8 [1.5025]
9 [1.8509]
10 [1.9677]
11 [2.0768]
12 [2.2777]
13 [2.4278]
14 [2.6282]
15 [2.7817]
16 [2.9154]
17 [3.071]
18 [3.3148]
19 [3.4272]
20 [3.5822]
21 [4.0459]
22 [4.2595]
23 [4.3732]
24 [4.6267]
train done
Epoch 289/1000 : Loss:0.1928, Valid loss: 0.2822, lr:0.000336 [0.7178] 2300.1885323524475
1 [0.3306]
2 [0.5661]
3 [0.7181]
4 [0.8081]
5 [1.0857]
6 [1.3223]
7 [1.6276]
8 [1.7878]
9 [2.0039]
10 [2.3394]
11 [2.543]
12 [2.6632]
13 [3.0547]
14 [3.1807]
15 [3.5392]
16 [3.6959]
17 [3.8899]
18 [4.0298]
19 [4.1532]
20 [4.4633]
21 [4.5857]
22 [4.7649]
23 [4.9057]
24 [5.0793]
train done
Epoch 290/1000 : Loss:0.2116, Valid loss: 0.3075, lr:0.000336 [0.6925] 2165.315131187439
Model 290 saved.
1 [0.0902]
2 [0.2561]
3 [0.4678]
4 [0.715]
5 [0.8554]
6 [1.2515]
7 [1.6744]
8 [1.8826]
9 [2.3483]
10 [2.4665]
11 [2.6518]
12 [2.9079]
13 [3.0136]
14 [3.2171]
15 [3.3192]
16 [3.4349]
17 [3.6708]
18 [3.8666]
19 [4.0651]
20 [4.2003]
21 [4.3712]
22 [4.5597]
23 [4.7421]
24 [4.9103]
train done
Epoch 291/1000 : Loss:0.2046, Valid loss: 0.2869, lr:0.000336 [0.7131] 1933.56178689003
1 [0.162]
2 [0.3246]
3 [0.4548]
4 [0.6188]
5 [0.8532]
6 [0.9867]
7 [1.1702]
8 [1.3528]
9 [1.4383]
10 [1.5098]
11 [1.6567]
12 [2.0276]
13 [2.2727]
14 [2.5095]
15 [2.6198]
16 [2.7316]
17 [2.9529]
18 [3.1936]
19 [3.3686]
20 [3.4433]
21 [3.7399]
22 [3.8294]
23 [4.0014]
24 [4.1754]
train done
Epoch 292/1000 : Loss:0.1740, Valid loss: 0.2738, lr:0.000336 [0.7262] 1924.9961080551147
1 [0.2323]
2 [0.4026]
3 [0.5204]
4 [0.8865]
5 [1.2507]
6 [1.4441]
7 [1.6081]
8 [1.7383]
9 [1.8242]
10 [2.0595]
11 [2.2177]
12 [2.3937]
13 [2.5769]
14 [2.7551]
15 [2.9812]
16 [3.1326]
17 [3.2105]
18 [3.3824]
19 [3.4735]
20 [3.5707]
21 [3.8089]
22 [3.9674]
23 [4.1527]
24 [4.492]
train done
Epoch 293/1000 : Loss:0.1872, Valid loss: 0.2836, lr:0.000336 [0.7164] 1907.3075079917908
1 [0.1819]
2 [0.4022]
3 [0.7307]
4 [0.9051]
5 [1.0405]
6 [1.3748]
7 [1.5703]
8 [1.7776]
9 [1.9218]
10 [2.0601]
11 [2.2484]
12 [2.3434]
13 [2.4788]
14 [2.79]
15 [2.9396]
16 [3.3291]
17 [3.4288]
18 [3.5889]
19 [3.729]
20 [3.9013]
21 [4.0208]
22 [4.1432]
23 [4.4366]
24 [4.5701]
train done
Epoch 294/1000 : Loss:0.1904, Valid loss: 0.3169, lr:0.000336 [0.6831] 1742.8249118328094
1 [0.2059]
2 [0.4091]
3 [0.6378]
4 [0.7374]
5 [1.0625]
6 [1.3551]
7 [1.6255]
8 [1.7763]
9 [2.1162]
10 [2.2795]
11 [2.3888]
12 [2.5726]
13 [2.9194]
14 [3.0168]
15 [3.1257]
16 [3.3162]
17 [3.4059]
18 [3.631]
19 [3.8446]
20 [4.0455]
21 [4.1894]
22 [4.3605]
23 [4.5251]
24 [4.6734]
train done
Epoch 295/1000 : Loss:0.1947, Valid loss: 0.3149, lr:0.000336 [0.6851] 1754.3897619247437
1 [0.1978]
2 [0.3012]
3 [0.4568]
4 [0.635]
5 [0.7542]
6 [1.0128]
7 [1.2424]
8 [1.3368]
9 [1.5498]
10 [1.708]
11 [1.8737]
12 [1.9897]
13 [2.0998]
14 [2.1704]
15 [2.3462]
16 [2.4829]
17 [2.6412]
18 [3.0475]
19 [3.1409]
20 [3.3411]
21 [3.5462]
22 [3.812]
23 [3.9243]
24 [4.0889]
train done
Epoch 296/1000 : Loss:0.1704, Valid loss: 0.2894, lr:0.000336 [0.7106] 1725.2830929756165
1 [0.1396]
2 [0.2829]
3 [0.5785]
4 [0.7904]
5 [1.0052]
6 [1.2232]
7 [1.3527]
8 [1.5194]
9 [1.7766]
10 [1.964]
11 [2.0511]
12 [2.1283]
13 [2.3039]
14 [2.5266]
15 [2.7313]
16 [2.8127]
17 [2.9981]
18 [3.26]
19 [3.4193]
20 [3.7008]
21 [3.8909]
22 [4.0201]
23 [4.1582]
24 [4.2585]
train done
Epoch 297/1000 : Loss:0.1774, Valid loss: 0.3007, lr:0.000336 [0.6993] 1728.2473480701447
1 [0.2022]
2 [0.3409]
3 [0.5753]
4 [0.7254]
5 [1.0036]
6 [1.16]
7 [1.3092]
8 [1.6387]
9 [1.7979]
10 [1.9773]
11 [2.2224]
12 [2.3352]
13 [2.4981]
14 [2.6992]
15 [2.8224]
16 [2.9159]
17 [3.1547]
18 [3.3189]
19 [3.4789]
20 [3.5942]
21 [3.7821]
22 [3.9089]
23 [4.3465]
24 [4.5889]
train done
Epoch 298/1000 : Loss:0.1912, Valid loss: 0.2961, lr:0.000336 [0.7039] 1757.4148519039154
1 [0.1552]
2 [0.3063]
3 [0.4178]
4 [0.5619]
5 [0.6879]
6 [0.8658]
7 [1.2836]
8 [1.4375]
9 [1.6317]
10 [1.7618]
11 [1.9314]
12 [2.146]
13 [2.3006]
14 [2.4031]
15 [2.7185]
16 [2.8909]
17 [3.0633]
18 [3.2661]
19 [3.4824]
20 [3.8307]
21 [3.9273]
22 [4.301]
23 [4.5846]
24 [4.6932]
train done
Epoch 299/1000 : Loss:0.1956, Valid loss: 0.2936, lr:0.000336 [0.7064] 1737.7159171104431
1 [0.1423]
2 [0.416]
3 [0.6828]
4 [0.8539]
5 [1.1615]
6 [1.2398]
7 [1.4156]
8 [1.5952]
9 [1.6748]
10 [1.8045]
11 [1.9765]
12 [2.1179]
13 [2.2507]
14 [2.4254]
15 [2.5693]
16 [2.724]
17 [2.9333]
18 [3.0839]
19 [3.2096]
20 [3.4636]
21 [3.6102]
22 [3.7957]
23 [4.1789]
24 [4.2928]
train done
Epoch 300/1000 : Loss:0.1789, Valid loss: 0.2770, lr:0.000336 [0.723] 1797.8070039749146
Model 300 saved.
1 [0.131]
2 [0.3045]
3 [0.3926]
4 [0.5142]
5 [0.6064]
6 [0.7525]
7 [0.8557]
8 [0.9793]
9 [1.2434]
10 [1.4424]
11 [1.604]
12 [1.8184]
13 [1.945]
14 [2.1293]
15 [2.2756]
16 [2.3889]
17 [2.5066]
18 [2.6951]
19 [2.7823]
20 [3.1135]
21 [3.3441]
22 [3.4877]
23 [3.759]
24 [3.9794]
train done
Epoch 301/1000 : Loss:0.1658, Valid loss: 0.2907, lr:0.000235 [0.7093] 1729.0375740528107
1 [0.2152]
2 [0.5137]
3 [0.6496]
4 [0.7384]
5 [0.9152]
6 [1.1046]
7 [1.4084]
8 [1.6106]
9 [1.7028]
10 [1.8819]
11 [2.127]
12 [2.2656]
13 [2.4455]
14 [2.8279]
15 [2.9614]
16 [3.0941]
17 [3.2997]
18 [3.4356]
19 [3.5729]
20 [3.6783]
21 [3.7492]
22 [4.0435]
23 [4.1461]
24 [4.3094]
train done
Epoch 302/1000 : Loss:0.1796, Valid loss: 0.2983, lr:0.000235 [0.7017] 1768.6967828273773
1 [0.1138]
2 [0.2804]
3 [0.5307]
4 [0.6594]
5 [0.8503]
6 [1.0085]
7 [1.1091]
8 [1.2345]
9 [1.4988]
10 [1.6154]
11 [1.8418]
12 [2.0388]
13 [2.1922]
14 [2.298]
15 [2.5171]
16 [2.6018]
17 [2.7419]
18 [3.0621]
19 [3.1891]
20 [3.578]
21 [3.8311]
22 [4.0612]
23 [4.2357]
24 [4.544]
train done
Epoch 303/1000 : Loss:0.1893, Valid loss: 0.2886, lr:0.000235 [0.7114] 1754.1212031841278
1 [0.106]
2 [0.3913]
3 [0.5621]
4 [0.7058]
5 [0.8434]
6 [1.0094]
7 [1.2224]
8 [1.5727]
9 [1.7518]
10 [2.0338]
11 [2.2103]
12 [2.3333]
13 [2.6468]
14 [2.7849]
15 [2.8715]
16 [2.9666]
17 [3.1865]
18 [3.4283]
19 [3.5519]
20 [3.7028]
21 [3.8629]
22 [4.0266]
23 [4.1048]
24 [4.2879]
train done
Epoch 304/1000 : Loss:0.1787, Valid loss: 0.2745, lr:0.000235 [0.7255] 1738.9142236709595
1 [0.1058]
2 [0.2347]
3 [0.4557]
4 [0.5833]
5 [0.8339]
6 [0.9582]
7 [1.0946]
8 [1.3618]
9 [1.4781]
10 [1.6157]
11 [1.7515]
12 [1.849]
13 [2.1656]
14 [2.5291]
15 [2.651]
16 [2.8629]
17 [3.1117]
18 [3.3312]
19 [3.5075]
20 [3.671]
21 [3.8251]
22 [3.947]
23 [4.094]
24 [4.2098]
train done
Epoch 305/1000 : Loss:0.1754, Valid loss: 0.2771, lr:0.000235 [0.7229] 1747.5620408058167
1 [0.2005]
2 [0.3645]
3 [0.6626]
4 [0.846]
5 [1.1207]
6 [1.194]
7 [1.3478]
8 [1.6652]
9 [1.7641]
10 [1.8663]
11 [2.0344]
12 [2.1877]
13 [2.1877]
14 [2.3364]
15 [2.6629]
16 [2.7597]
17 [2.8963]
18 [3.1442]
19 [3.2976]
20 [3.4167]
21 [3.5771]
22 [3.7156]
23 [3.9473]
24 [4.0638]
train done
Epoch 306/1000 : Loss:0.1693, Valid loss: 0.2821, lr:0.000235 [0.7179] 1739.8477818965912
1 [0.1894]
2 [0.3151]
3 [0.4806]
4 [0.5867]
5 [0.8401]
6 [1.2862]
7 [1.489]
8 [1.6641]
9 [1.8236]
10 [2.0298]
11 [2.1168]
12 [2.2954]
13 [2.4856]
14 [2.6898]
15 [2.8021]
16 [2.9289]
17 [3.0222]
18 [3.2459]
19 [3.5485]
20 [3.6961]
21 [3.8832]
22 [4.0725]
23 [4.2094]
24 [4.3109]
train done
Epoch 307/1000 : Loss:0.1796, Valid loss: 0.2798, lr:0.000235 [0.7202] 1728.8952960968018
1 [0.1499]
2 [0.2597]
3 [0.8376]
4 [0.9541]
5 [1.153]
6 [1.2625]
7 [1.4881]
8 [1.8713]
9 [2.0404]
10 [2.2321]
11 [2.4451]
12 [2.6135]
13 [2.7801]
14 [2.8845]
15 [3.1199]
16 [3.3565]
17 [3.5754]
18 [3.7669]
19 [4.1273]
20 [4.2513]
21 [4.46]
22 [4.6291]
23 [4.732]
24 [4.8924]
train done
Epoch 308/1000 : Loss:0.2039, Valid loss: 0.2883, lr:0.000235 [0.7117] 1718.0093648433685
1 [0.1522]
2 [0.2789]
3 [0.5323]
4 [0.6965]
5 [1.1942]
6 [1.3684]
7 [1.5274]
8 [1.7651]
9 [1.9413]
10 [2.1647]
11 [2.3995]
12 [2.4848]
13 [2.5963]
14 [2.677]
15 [2.9613]
16 [3.0388]
17 [3.1563]
18 [3.3475]
19 [3.9432]
20 [4.191]
21 [4.3401]
22 [4.4211]
23 [4.5882]
24 [4.7506]
train done
Epoch 309/1000 : Loss:0.1979, Valid loss: 0.2624, lr:0.000235 [0.7376] 1735.0869572162628
1 [0.2602]
2 [0.4559]
3 [0.7621]
4 [1.1039]
5 [1.4071]
6 [1.4855]
7 [1.7155]
8 [1.8114]
9 [1.9169]
10 [2.2379]
11 [2.3924]
12 [2.6523]
13 [2.9709]
14 [3.1211]
15 [3.2637]
16 [3.3747]
17 [3.5321]
18 [3.8183]
19 [4.0159]
20 [4.1584]
21 [4.2326]
22 [4.4519]
23 [4.63]
24 [4.7486]
train done
Epoch 310/1000 : Loss:0.1979, Valid loss: 0.2616, lr:0.000235 [0.7384] 1714.3396458625793
Model 310 saved.
1 [0.2316]
2 [0.3855]
3 [0.6394]
4 [0.7415]
5 [0.9614]
6 [1.1252]
7 [1.3337]
8 [1.4824]
9 [1.6587]
10 [2.1142]
11 [2.4431]
12 [2.5744]
13 [2.79]
14 [2.9605]
15 [3.2232]
16 [3.5104]
17 [3.8134]
18 [3.9464]
19 [4.441]
20 [4.5973]
21 [4.7248]
22 [4.9082]
23 [5.0195]
24 [5.2685]
train done
Epoch 311/1000 : Loss:0.2195, Valid loss: 0.2679, lr:0.000235 [0.7321] 1721.7112407684326
1 [0.3257]
2 [0.4653]
3 [0.5851]
4 [0.793]
5 [0.9568]
6 [1.1355]
7 [1.2442]
8 [1.4325]
9 [1.6557]
10 [1.7444]
11 [2.1893]
12 [2.3999]
13 [2.5312]
14 [2.7574]
15 [3.0377]
16 [3.2149]
17 [3.4117]
18 [3.521]
19 [3.861]
20 [4.0033]
21 [4.0752]
22 [4.2454]
23 [4.5953]
24 [4.6644]
train done
Epoch 312/1000 : Loss:0.1943, Valid loss: 0.2676, lr:0.000235 [0.7324] 1729.503445148468
1 [0.2115]
2 [0.4455]
3 [0.7347]
4 [0.8318]
5 [1.0588]
6 [1.3818]
7 [1.5459]
8 [1.7126]
9 [1.9647]
10 [2.1335]
11 [2.3815]
12 [2.5518]
13 [2.7689]
14 [2.993]
15 [3.1242]
16 [3.2968]
17 [3.4351]
18 [3.6059]
19 [3.6881]
20 [4.0725]
21 [4.218]
22 [4.3691]
23 [4.5171]
24 [4.7268]
train done
Epoch 313/1000 : Loss:0.1969, Valid loss: 0.2586, lr:0.000235 [0.7414] 2204.6009089946747
1 [0.1636]
2 [0.3655]
3 [0.5088]
4 [0.5895]
5 [0.7813]
6 [1.0001]
7 [1.1387]
8 [1.4615]
9 [1.6433]
10 [2.1246]
11 [2.4812]
12 [2.8001]
13 [2.9722]
14 [3.1941]
15 [3.3703]
16 [3.5552]
17 [3.6946]
18 [3.7856]
19 [3.9371]
20 [4.1687]
21 [4.3596]
22 [4.6006]
23 [4.8163]
24 [4.9276]
train done
Epoch 314/1000 : Loss:0.2053, Valid loss: 0.2888, lr:0.000235 [0.7112] 1784.0354850292206
1 [0.2391]
2 [0.3519]
3 [0.46]
4 [0.7133]
5 [0.8809]
6 [1.0932]
7 [1.3029]
8 [1.4063]
9 [1.6282]
10 [1.8476]
11 [2.1511]
12 [2.5631]
13 [2.6546]
14 [2.8704]
15 [3.0642]
16 [3.1717]
17 [3.3242]
18 [3.4426]
19 [3.6075]
20 [3.7838]
21 [3.9148]
22 [4.3204]
23 [4.6466]
24 [4.768]
train done
Epoch 315/1000 : Loss:0.1987, Valid loss: 0.2860, lr:0.000235 [0.714] 1827.0726072788239
1 [0.1533]
2 [0.4574]
3 [0.6059]
4 [0.7943]
5 [0.9652]
6 [1.0353]
7 [1.1873]
8 [1.4708]
9 [1.6782]
10 [1.8338]
11 [1.9633]
12 [2.1199]
13 [2.3712]
14 [2.5969]
15 [2.6949]
16 [2.7728]
17 [3.0096]
18 [3.2486]
19 [3.4116]
20 [3.5662]
21 [3.791]
22 [3.9165]
23 [4.0601]
24 [4.2202]
train done
Epoch 316/1000 : Loss:0.1758, Valid loss: 0.2697, lr:0.000235 [0.7303] 2144.9254100322723
1 [0.1401]
2 [0.4166]
3 [0.5774]
4 [0.7599]
5 [0.9587]
6 [1.1227]
7 [1.2863]
8 [1.421]
9 [1.5995]
10 [1.7176]
11 [1.8301]
12 [2.0151]
13 [2.1736]
14 [2.2635]
15 [2.3798]
16 [2.5759]
17 [2.7955]
18 [3.2633]
19 [3.4354]
20 [3.8681]
21 [4.069]
22 [4.1921]
23 [4.5223]
24 [4.6019]
train done
Epoch 317/1000 : Loss:0.1917, Valid loss: 0.2569, lr:0.000235 [0.7431] 1885.2654960155487
1 [0.2034]
2 [0.4221]
3 [0.5493]
4 [0.8178]
5 [0.9011]
6 [1.0701]
7 [1.2867]
8 [1.6766]
9 [2.0095]
10 [2.1685]
11 [2.3047]
12 [2.4425]
13 [2.809]
14 [2.9187]
15 [3.063]
16 [3.2229]
17 [3.3336]
18 [3.4615]
19 [3.5551]
20 [3.6897]
21 [3.8981]
22 [4.0279]
23 [4.173]
24 [4.2721]
train done
Epoch 318/1000 : Loss:0.1780, Valid loss: 0.2926, lr:0.000235 [0.7074] 1748.3677501678467
1 [0.1421]
2 [0.2686]
3 [0.4925]
4 [0.638]
5 [0.7442]
6 [1.0259]
7 [1.2951]
8 [1.4174]
9 [1.5347]
10 [1.6941]
11 [2.079]
12 [2.2386]
13 [2.3355]
14 [2.5144]
15 [2.7591]
16 [2.9373]
17 [3.035]
18 [3.1626]
19 [3.3742]
20 [3.5562]
21 [3.8505]
22 [4.0018]
23 [4.157]
24 [4.3158]
train done
Epoch 319/1000 : Loss:0.1798, Valid loss: 0.2770, lr:0.000235 [0.723] 1744.9488999843597
1 [0.1704]
2 [0.3968]
3 [0.5513]
4 [0.7562]
5 [0.9899]
6 [1.1306]
7 [1.2332]
8 [1.5064]
9 [1.6243]
10 [1.8009]
11 [1.8971]
12 [1.9793]
13 [2.0768]
14 [2.1803]
15 [2.6664]
16 [2.7791]
17 [2.8647]
18 [3.118]
19 [3.4694]
20 [3.8224]
21 [3.9919]
22 [4.2532]
23 [4.6419]
24 [4.8335]
train done
Epoch 320/1000 : Loss:0.2014, Valid loss: 0.2766, lr:0.000235 [0.7234] 1726.9596390724182
Model 320 saved.
1 [0.1121]
2 [0.4235]
3 [0.7157]
4 [0.8394]
5 [1.1234]
6 [1.305]
7 [1.5567]
8 [1.888]
9 [2.0554]
10 [2.1612]
11 [2.244]
12 [2.3983]
13 [2.5024]
14 [2.7084]
15 [2.8845]
16 [3.2602]
17 [3.5145]
18 [3.7976]
19 [3.998]
20 [4.2035]
21 [4.3968]
22 [4.7343]
23 [4.94]
24 [5.0488]
train done
Epoch 321/1000 : Loss:0.2104, Valid loss: 0.2991, lr:0.000235 [0.7009] 1742.8279330730438
1 [0.4591]
2 [0.8387]
3 [1.0638]
4 [1.1546]
5 [1.3084]
6 [1.3981]
7 [1.579]
8 [1.7068]
9 [1.7981]
10 [2.107]
11 [2.317]
12 [2.6402]
13 [2.8691]
14 [3.112]
15 [3.283]
16 [3.4596]
17 [3.6777]
18 [3.8431]
19 [4.0834]
20 [4.1739]
21 [4.3288]
22 [4.329]
23 [4.4762]
24 [4.6926]
train done
Epoch 322/1000 : Loss:0.1955, Valid loss: 0.2667, lr:0.000235 [0.7333] 1748.6105239391327
1 [0.1908]
2 [0.3237]
3 [0.6471]
4 [0.8686]
5 [0.9818]
6 [1.1441]
7 [1.2733]
8 [1.459]
9 [1.5451]
10 [1.6347]
11 [1.7116]
12 [2.1743]
13 [2.321]
14 [2.4759]
15 [2.7243]
16 [2.9058]
17 [3.2011]
18 [3.6447]
19 [4.1405]
20 [4.4517]
21 [4.6832]
22 [4.8496]
23 [4.9625]
24 [5.3492]
train done
Epoch 323/1000 : Loss:0.2229, Valid loss: 0.2814, lr:0.000235 [0.7186] 1725.7630488872528
1 [0.147]
2 [0.3275]
3 [0.4718]
4 [0.6316]
5 [0.7647]
6 [1.0389]
7 [1.1474]
8 [1.2597]
9 [1.727]
10 [1.8956]
11 [2.3398]
12 [2.6316]
13 [2.7702]
14 [2.9928]
15 [3.122]
16 [3.3024]
17 [3.5266]
18 [3.8952]
19 [4.2417]
20 [4.419]
21 [4.5316]
22 [4.6673]
23 [4.8388]
24 [5.0187]
train done
Epoch 324/1000 : Loss:0.2091, Valid loss: 0.2726, lr:0.000235 [0.7274] 1953.2576639652252
1 [0.2144]
2 [0.3536]
3 [0.5184]
4 [0.6304]
5 [0.7902]
6 [0.9114]
7 [1.2019]
8 [1.3413]
9 [1.487]
10 [1.7208]
11 [1.9049]
12 [2.064]
13 [2.2284]
14 [2.4937]
15 [2.7333]
16 [2.8569]
17 [2.959]
18 [3.1695]
19 [3.3769]
20 [3.5258]
21 [3.6604]
22 [3.7876]
23 [3.953]
24 [4.1485]
train done
Epoch 325/1000 : Loss:0.1729, Valid loss: 0.2849, lr:0.000235 [0.7151] 2078.496967792511
1 [0.0832]
2 [0.0832]
3 [0.2819]
4 [0.3623]
5 [0.4567]
6 [0.6105]
7 [0.7373]
8 [0.8745]
9 [1.0802]
10 [1.3413]
11 [1.5814]
12 [1.7194]
13 [1.89]
14 [2.0794]
15 [2.4362]
16 [2.727]
17 [2.8355]
18 [3.4227]
19 [3.7413]
20 [3.9938]
21 [4.1754]
22 [4.3118]
23 [4.4163]
24 [4.5552]
train done
Epoch 326/1000 : Loss:0.1898, Valid loss: 0.2801, lr:0.000235 [0.7199] 2161.1910400390625
1 [0.0891]
2 [0.3801]
3 [0.548]
4 [0.6574]
5 [0.7739]
6 [0.8706]
7 [1.0471]
8 [1.5831]
9 [1.7942]
10 [1.9561]
11 [2.1181]
12 [2.1956]
13 [2.3723]
14 [2.6381]
15 [2.7805]
16 [3.071]
17 [3.2118]
18 [3.5557]
19 [3.7435]
20 [4.0174]
21 [4.207]
22 [4.4052]
23 [4.7119]
24 [4.9576]
train done
Epoch 327/1000 : Loss:0.2066, Valid loss: 0.2825, lr:0.000235 [0.7175] 2176.3698608875275
1 [0.2626]
2 [0.4039]
3 [0.7215]
4 [1.0262]
5 [1.1667]
6 [1.2512]
7 [1.4829]
8 [1.6689]
9 [1.8161]
10 [1.9762]
11 [2.1034]
12 [2.2822]
13 [2.7558]
14 [3.0403]
15 [3.2351]
16 [3.4085]
17 [3.5759]
18 [3.6964]
19 [3.9242]
20 [4.0853]
21 [4.2326]
22 [4.3612]
23 [4.4454]
24 [4.5797]
train done
Epoch 328/1000 : Loss:0.1908, Valid loss: 0.2802, lr:0.000235 [0.7198] 1906.2504298686981
1 [0.1914]
2 [0.3513]
3 [0.5573]
4 [0.6689]
5 [0.886]
6 [1.1277]
7 [1.313]
8 [1.5651]
9 [2.0431]
10 [2.2698]
11 [2.711]
12 [2.9245]
13 [3.1425]
14 [3.2745]
15 [3.4504]
16 [3.7173]
17 [3.8402]
18 [3.9317]
19 [4.0202]
20 [4.1662]
21 [4.3435]
22 [4.5506]
23 [4.6417]
24 [4.7345]
train done
Epoch 329/1000 : Loss:0.1973, Valid loss: 0.2910, lr:0.000235 [0.709] 2243.7119097709656
1 [0.1201]
2 [0.2466]
3 [0.3749]
4 [0.6952]
5 [0.8252]
6 [1.1974]
7 [1.4256]
8 [1.526]
9 [1.719]
10 [1.8337]
11 [2.0762]
12 [2.2435]
13 [2.5454]
14 [2.7073]
15 [2.7868]
16 [2.9085]
17 [3.0817]
18 [3.3681]
19 [3.5052]
20 [3.6394]
21 [3.7325]
22 [3.868]
23 [4.1507]
24 [4.2879]
train done
Epoch 330/1000 : Loss:0.1787, Valid loss: 0.2841, lr:0.000235 [0.7159] 1718.882323026657
Model 330 saved.
1 [0.2464]
2 [0.3874]
3 [0.5676]
4 [0.748]
5 [0.8855]
6 [0.9648]
7 [1.2317]
8 [1.373]
9 [1.5254]
10 [1.6739]
11 [2.1246]
12 [2.261]
13 [2.394]
14 [2.5306]
15 [2.6719]
16 [2.8075]
17 [2.985]
18 [3.1919]
19 [3.415]
20 [3.6292]
21 [3.7384]
22 [3.8358]
23 [4.1915]
24 [4.4556]
train done
Epoch 331/1000 : Loss:0.1857, Valid loss: 0.2834, lr:0.000235 [0.7166] 1722.8577132225037
1 [0.193]
2 [0.3901]
3 [0.4822]
4 [0.5756]
5 [0.7986]
6 [1.0274]
7 [1.2877]
8 [1.4551]
9 [1.6152]
10 [1.7081]
11 [1.9351]
12 [2.0982]
13 [2.2234]
14 [2.37]
15 [2.5058]
16 [2.6157]
17 [2.8986]
18 [3.0324]
19 [3.1846]
20 [3.3705]
21 [3.4591]
22 [3.7108]
23 [3.9246]
24 [4.0111]
train done
Epoch 332/1000 : Loss:0.1671, Valid loss: 0.2691, lr:0.000235 [0.7309] 2120.706062078476
1 [0.1796]
2 [0.2851]
3 [0.4141]
4 [0.5414]
5 [0.8251]
6 [0.9604]
7 [1.1193]
8 [1.3918]
9 [1.5339]
10 [1.7673]
11 [1.853]
12 [2.0096]
13 [2.337]
14 [2.4708]
15 [2.548]
16 [2.732]
17 [3.0108]
18 [3.2378]
19 [3.4354]
20 [3.6026]
21 [3.7282]
22 [3.8793]
23 [4.0911]
24 [4.2403]
train done
Epoch 333/1000 : Loss:0.1767, Valid loss: 0.2725, lr:0.000235 [0.7275] 2161.9200942516327
1 [0.1982]
2 [0.3442]
3 [0.4854]
4 [0.6465]
5 [0.7493]
6 [0.8543]
7 [1.0637]
8 [1.2377]
9 [1.3846]
10 [1.5692]
11 [2.0521]
12 [2.3107]
13 [2.4283]
14 [2.6003]
15 [2.7393]
16 [2.9815]
17 [3.1794]
18 [3.4744]
19 [3.5861]
20 [3.6946]
21 [3.8577]
22 [4.0205]
23 [4.2704]
24 [4.4927]
train done
Epoch 334/1000 : Loss:0.1872, Valid loss: 0.2857, lr:0.000235 [0.7143] 2221.953220129013
1 [0.2181]
2 [0.4393]
3 [0.7446]
4 [0.958]
5 [1.094]
6 [1.1762]
7 [1.2854]
8 [1.3727]
9 [1.5733]
10 [1.7402]
11 [1.865]
12 [1.9705]
13 [2.1186]
14 [2.3046]
15 [2.4366]
16 [2.5613]
17 [2.6829]
18 [2.8479]
19 [3.0383]
20 [3.2694]
21 [3.567]
22 [3.7556]
23 [3.9723]
24 [4.068]
train done
Epoch 335/1000 : Loss:0.1695, Valid loss: 0.2772, lr:0.000235 [0.7228] 2262.878564119339
1 [0.1593]
2 [0.4213]
3 [0.5632]
4 [0.8242]
5 [0.9875]
6 [1.1414]
7 [1.1414]
8 [1.2225]
9 [1.3079]
10 [1.3936]
11 [1.5057]
12 [1.6653]
13 [1.871]
14 [2.0289]
15 [2.1693]
16 [2.3848]
17 [2.5052]
18 [2.6157]
19 [2.9671]
20 [3.2066]
21 [3.3362]
22 [3.4534]
23 [3.6051]
24 [3.8166]
train done
Epoch 336/1000 : Loss:0.1590, Valid loss: 0.2686, lr:0.000235 [0.7314] 2684.2491450309753
1 [0.1032]
2 [0.3172]
3 [0.4733]
4 [0.6444]
5 [0.8454]
6 [0.9864]
7 [1.2425]
8 [1.3791]
9 [1.5436]
10 [1.8429]
11 [2.0704]
12 [2.315]
13 [2.455]
14 [2.6471]
15 [2.7271]
16 [2.9353]
17 [3.0235]
18 [3.2327]
19 [3.3525]
20 [3.4684]
21 [3.6834]
22 [3.81]
23 [3.9648]
24 [4.1167]
train done
Epoch 337/1000 : Loss:0.1715, Valid loss: 0.2685, lr:0.000235 [0.7315] 2656.674498796463
1 [0.2482]
2 [0.4414]
3 [0.6034]
4 [0.9405]
5 [1.1974]
6 [1.2876]
7 [1.4301]
8 [1.6102]
9 [1.8223]
10 [1.921]
11 [2.0719]
12 [2.5132]
13 [2.785]
14 [2.8801]
15 [3.1304]
16 [3.2488]
17 [3.4223]
18 [3.5564]
19 [3.693]
20 [3.7882]
21 [3.9068]
22 [4.1629]
23 [4.2925]
24 [4.4422]
train done
Epoch 338/1000 : Loss:0.1851, Valid loss: 0.2675, lr:0.000235 [0.7325] 2528.9420800209045
1 [0.1966]
2 [0.3849]
3 [0.4542]
4 [0.6003]
5 [0.8147]
6 [0.9773]
7 [1.1454]
8 [1.4296]
9 [1.6249]
10 [1.7411]
11 [1.9985]
12 [2.356]
13 [2.5758]
14 [2.7339]
15 [2.839]
16 [3.0193]
17 [3.2558]
18 [3.3391]
19 [3.501]
20 [3.6486]
21 [3.7893]
22 [3.9331]
23 [4.0622]
24 [4.2908]
train done
Epoch 339/1000 : Loss:0.1788, Valid loss: 0.2664, lr:0.000235 [0.7336] 2047.8313479423523
1 [0.2603]
2 [0.5199]
3 [0.7127]
4 [0.8765]
5 [1.0704]
6 [1.2698]
7 [1.427]
8 [1.5579]
9 [1.8473]
10 [1.95]
11 [2.1771]
12 [2.3601]
13 [2.4839]
14 [2.6239]
15 [2.7899]
16 [2.9098]
17 [3.0995]
18 [3.414]
19 [3.9713]
20 [4.3742]
21 [4.4931]
22 [4.6063]
23 [4.765]
24 [4.86]
train done
Epoch 340/1000 : Loss:0.2025, Valid loss: 0.2754, lr:0.000235 [0.7246] 1754.4566609859467
Model 340 saved.
1 [0.1115]
2 [0.2447]
3 [0.4097]
4 [0.5154]
5 [0.6161]
6 [1.0578]
7 [1.5374]
8 [2.0611]
9 [2.2822]
10 [2.4068]
11 [2.5706]
12 [2.9782]
13 [3.0911]
14 [3.2985]
15 [3.4558]
16 [3.5487]
17 [3.7042]
18 [3.7971]
19 [3.9435]
20 [4.2108]
21 [4.3887]
22 [4.5019]
23 [4.6051]
24 [4.747]
train done
Epoch 341/1000 : Loss:0.1978, Valid loss: 0.2842, lr:0.000235 [0.7158] 1743.2924571037292
1 [0.1788]
2 [0.4215]
3 [0.6857]
4 [0.7859]
5 [0.9444]
6 [1.1847]
7 [1.3795]
8 [1.5137]
9 [1.602]
10 [1.7216]
11 [1.8035]
12 [1.9258]
13 [2.0164]
14 [2.3038]
15 [2.4891]
16 [2.7964]
17 [2.9292]
18 [3.0384]
19 [3.1805]
20 [3.2615]
21 [3.4143]
22 [3.5047]
23 [3.685]
24 [3.8431]
train done
Epoch 342/1000 : Loss:0.1601, Valid loss: 0.2906, lr:0.000235 [0.7094] 1748.668536901474
1 [0.3147]
2 [0.4942]
3 [0.5899]
4 [0.8663]
5 [1.0082]
6 [1.2907]
7 [1.5198]
8 [1.6141]
9 [1.7234]
10 [1.8786]
11 [2.062]
12 [2.2137]
13 [2.4701]
14 [2.658]
15 [2.9489]
16 [3.103]
17 [3.1902]
18 [3.3446]
19 [3.4694]
20 [3.5545]
21 [3.8344]
22 [4.0637]
23 [4.1453]
24 [4.3362]
train done
Epoch 343/1000 : Loss:0.1807, Valid loss: 0.2818, lr:0.000235 [0.7182] 1721.9220061302185
1 [0.4158]
2 [0.5297]
3 [0.7558]
4 [1.0136]
5 [1.1235]
6 [1.3125]
7 [1.42]
8 [1.5331]
9 [1.6055]
10 [1.8139]
11 [1.9538]
12 [2.0968]
13 [2.3659]
14 [2.5104]
15 [2.6638]
16 [2.8873]
17 [3.0108]
18 [3.2668]
19 [3.4432]
20 [3.8361]
21 [3.9831]
22 [4.1495]
23 [4.3072]
24 [4.4331]
train done
Epoch 344/1000 : Loss:0.1847, Valid loss: 0.2673, lr:0.000235 [0.7327] 1742.9903478622437
1 [0.0856]
2 [0.3073]
3 [0.513]
4 [0.7315]
5 [0.9361]
6 [1.032]
7 [1.1505]
8 [1.246]
9 [1.3691]
10 [1.5523]
11 [1.6848]
12 [1.7648]
13 [1.9346]
14 [2.2038]
15 [2.3552]
16 [2.4785]
17 [2.82]
18 [2.9617]
19 [3.1269]
20 [3.2486]
21 [3.4535]
22 [3.5537]
23 [3.8572]
24 [4.0312]
train done
Epoch 345/1000 : Loss:0.1680, Valid loss: 0.2758, lr:0.000235 [0.7242] 1744.7032108306885
1 [0.0776]
2 [0.2174]
3 [0.3566]
4 [0.6556]
5 [0.7382]
6 [0.9363]
7 [1.1497]
8 [1.3879]
9 [1.6001]
10 [1.7193]
11 [1.8774]
12 [2.2471]
13 [2.4157]
14 [2.5941]
15 [2.7204]
16 [2.8797]
17 [2.9682]
18 [3.0788]
19 [3.2108]
20 [3.5154]
21 [3.6353]
22 [3.9816]
23 [4.1938]
24 [4.3122]
train done
Epoch 346/1000 : Loss:0.1797, Valid loss: 0.2830, lr:0.000235 [0.717] 1716.8082659244537
1 [0.1964]
2 [0.2931]
3 [0.7049]
4 [0.8148]
5 [0.986]
6 [1.2724]
7 [1.3502]
8 [1.5089]
9 [1.6639]
10 [1.7712]
11 [2.0305]
12 [2.1619]
13 [2.361]
14 [2.5489]
15 [2.7434]
16 [2.9315]
17 [3.0175]
18 [3.3395]
19 [3.4975]
20 [3.6565]
21 [3.815]
22 [4.0199]
23 [4.1143]
24 [4.267]
train done
Epoch 347/1000 : Loss:0.1778, Valid loss: 0.2741, lr:0.000235 [0.7259] 1728.7777650356293
1 [0.1571]
2 [0.2828]
3 [0.5304]
4 [0.6162]
5 [0.8276]
6 [1.0451]
7 [1.2397]
8 [1.5899]
9 [1.7487]
10 [1.8397]
11 [1.9611]
12 [2.1619]
13 [2.2866]
14 [2.5871]
15 [2.6722]
16 [2.8324]
17 [3.0655]
18 [3.2703]
19 [3.5235]
20 [3.6172]
21 [3.7927]
22 [3.9035]
23 [4.0361]
24 [4.1881]
train done
Epoch 348/1000 : Loss:0.1745, Valid loss: 0.2782, lr:0.000235 [0.7218] 1737.3096098899841
1 [0.1284]
2 [0.3022]
3 [0.4232]
4 [0.5796]
5 [0.7056]
6 [0.8664]
7 [1.0619]
8 [1.3948]
9 [1.5784]
10 [1.6681]
11 [1.9898]
12 [2.1419]
13 [2.5118]
14 [2.5878]
15 [2.8302]
16 [2.9779]
17 [3.1715]
18 [3.396]
19 [3.5926]
20 [3.7794]
21 [3.8611]
22 [4.0261]
23 [4.3203]
24 [4.5893]
train done
Epoch 349/1000 : Loss:0.1912, Valid loss: 0.2924, lr:0.000235 [0.7076] 1734.422644853592
1 [0.1387]
2 [0.3315]
3 [0.6351]
4 [0.9035]
5 [1.0882]
6 [1.2652]
7 [1.4272]
8 [1.6649]
9 [1.7739]
10 [1.8842]
11 [1.9981]
12 [2.2076]
13 [2.4385]
14 [2.5407]
15 [2.6732]
16 [2.7633]
17 [2.8933]
18 [3.0136]
19 [3.2182]
20 [3.4127]
21 [3.5739]
22 [3.76]
23 [3.8787]
24 [3.9997]
train done
Epoch 350/1000 : Loss:0.1667, Valid loss: 0.2715, lr:0.000235 [0.7285] 1747.7814621925354
Model 350 saved.
1 [0.1787]
2 [0.2761]
3 [0.4307]
4 [0.6887]
5 [0.829]
6 [1.025]
7 [1.1627]
8 [1.5054]
9 [1.7173]
10 [1.8893]
11 [2.0619]
12 [2.1724]
13 [2.5591]
14 [2.695]
15 [2.7868]
16 [2.9128]
17 [3.1113]
18 [3.2545]
19 [3.4335]
20 [3.7929]
21 [3.9215]
22 [4.0276]
23 [4.1208]
24 [4.3666]
train done
Epoch 351/1000 : Loss:0.1819, Valid loss: 0.2655, lr:0.000165 [0.7345] 1771.9870800971985
1 [0.1421]
2 [0.2533]
3 [0.3884]
4 [0.5578]
5 [0.682]
6 [1.0077]
7 [1.2069]
8 [1.3327]
9 [1.4422]
10 [1.6196]
11 [1.7422]
12 [1.9695]
13 [2.0479]
14 [2.1386]
15 [2.2725]
16 [2.6113]
17 [2.7919]
18 [3.0351]
19 [3.18]
20 [3.4041]
21 [3.5669]
22 [3.685]
23 [3.7603]
24 [3.944]
train done
Epoch 352/1000 : Loss:0.1643, Valid loss: 0.2826, lr:0.000165 [0.7174] 1742.5138761997223
1 [0.119]
2 [0.2893]
3 [0.3891]
4 [0.5394]
5 [0.7448]
6 [1.0793]
7 [1.1787]
8 [1.3417]
9 [1.5212]
10 [2.0477]
11 [2.2155]
12 [2.3265]
13 [2.4172]
14 [2.6012]
15 [2.7537]
16 [2.8318]
17 [2.9641]
18 [3.0788]
19 [3.2546]
20 [3.4707]
21 [3.7047]
22 [3.833]
23 [3.9614]
24 [4.1674]
train done
Epoch 353/1000 : Loss:0.1736, Valid loss: 0.2816, lr:0.000165 [0.7184] 1723.3747310638428
1 [0.1421]
2 [0.2818]
3 [0.4591]
4 [0.6023]
5 [0.9014]
6 [0.987]
7 [1.0974]
8 [1.3531]
9 [1.5356]
10 [1.7358]
11 [1.8903]
12 [2.1297]
13 [2.1987]
14 [2.5518]
15 [2.7537]
16 [2.9552]
17 [3.079]
18 [3.256]
19 [3.4247]
20 [3.4248]
21 [3.5597]
22 [3.91]
23 [4.2152]
24 [4.2878]
train done
Epoch 354/1000 : Loss:0.1787, Valid loss: 0.2641, lr:0.000165 [0.7359] 1710.75652384758
1 [0.0916]
2 [0.5509]
3 [0.676]
4 [0.7843]
5 [0.9495]
6 [1.222]
7 [1.3819]
8 [1.6426]
9 [1.7852]
10 [1.9457]
11 [2.0933]
12 [2.1785]
13 [2.2658]
14 [2.5885]
15 [2.7457]
16 [2.8717]
17 [3.0232]
18 [3.2411]
19 [3.3113]
20 [3.4857]
21 [3.5908]
22 [3.8872]
23 [4.2036]
24 [4.3787]
train done
Epoch 355/1000 : Loss:0.1824, Valid loss: 0.2705, lr:0.000165 [0.7295] 1731.4106488227844
1 [0.1276]
2 [0.268]
3 [0.6143]
4 [0.8621]
5 [0.9972]
6 [1.3513]
7 [1.5404]
8 [1.7499]
9 [1.9046]
10 [2.071]
11 [2.2533]
12 [2.4261]
13 [2.7044]
14 [2.7912]
15 [2.9087]
16 [2.9087]
17 [2.9848]
18 [3.186]
19 [3.3246]
20 [3.4632]
21 [3.6001]
22 [3.7391]
23 [3.8521]
24 [4.0272]
train done
Epoch 356/1000 : Loss:0.1678, Valid loss: 0.2697, lr:0.000165 [0.7303] 1738.7853569984436
1 [0.1369]
2 [0.296]
3 [0.5085]
4 [0.6663]
5 [0.7821]
6 [0.9451]
7 [1.0713]
8 [1.2607]
9 [1.5291]
10 [1.594]
11 [1.8196]
12 [2.0491]
13 [2.1769]
14 [2.315]
15 [2.4293]
16 [2.532]
17 [2.6642]
18 [2.9433]
19 [3.0542]
20 [3.2569]
21 [3.3556]
22 [3.55]
23 [3.7883]
24 [3.9345]
train done
Epoch 357/1000 : Loss:0.1639, Valid loss: 0.2666, lr:0.000165 [0.7334] 1747.0889580249786
1 [0.1194]
2 [0.3341]
3 [0.48]
4 [0.7941]
5 [0.8916]
6 [1.101]
7 [1.1867]
8 [1.3738]
9 [1.5368]
10 [1.6413]
11 [1.7864]
12 [1.8747]
13 [2.0407]
14 [2.3248]
15 [2.487]
16 [2.5912]
17 [2.7483]
18 [2.8098]
19 [2.9581]
20 [3.2178]
21 [3.4587]
22 [3.5648]
23 [3.6931]
24 [3.8867]
train done
Epoch 358/1000 : Loss:0.1619, Valid loss: 0.2798, lr:0.000165 [0.7202] 1735.1256301403046
1 [0.2374]
2 [0.3595]
3 [0.5072]
4 [0.5823]
5 [0.8864]
6 [0.9863]
7 [1.2245]
8 [1.3805]
9 [1.5223]
10 [1.6041]
11 [1.7595]
12 [1.8777]
13 [2.0735]
14 [2.3328]
15 [2.4543]
16 [2.5868]
17 [2.7058]
18 [2.874]
19 [3.1141]
20 [3.3474]
21 [3.4378]
22 [3.5864]
23 [3.713]
24 [3.7835]
train done
Epoch 359/1000 : Loss:0.1576, Valid loss: 0.2691, lr:0.000165 [0.7309] 1758.666790008545
1 [0.12]
2 [0.3646]
3 [0.5322]
4 [0.6439]
5 [0.8312]
6 [1.1256]
7 [1.3439]
8 [1.4794]
9 [1.5951]
10 [1.667]
11 [1.8419]
12 [1.9866]
13 [2.078]
14 [2.1963]
15 [2.3387]
16 [2.5239]
17 [2.7288]
18 [2.8172]
19 [2.9694]
20 [3.1313]
21 [3.2682]
22 [3.4656]
23 [3.5592]
24 [3.9604]
train done
Epoch 360/1000 : Loss:0.1650, Valid loss: 0.2794, lr:0.000165 [0.7206] 1735.378300189972
Model 360 saved.
1 [0.2064]
2 [0.3281]
3 [0.4906]
4 [0.6959]
5 [0.8072]
6 [1.0108]
7 [1.1745]
8 [1.3368]
9 [1.525]
10 [1.6707]
11 [1.8014]
12 [1.9995]
13 [2.1311]
14 [2.333]
15 [2.4748]
16 [2.7177]
17 [2.8883]
18 [3.1913]
19 [3.3171]
20 [3.3992]
21 [3.5173]
22 [3.6235]
23 [3.8197]
24 [3.9881]
train done
Epoch 361/1000 : Loss:0.1662, Valid loss: 0.2727, lr:0.000165 [0.7273] 1751.4866287708282
1 [0.1407]
2 [0.4139]
3 [0.8403]
4 [0.9752]
5 [1.2292]
6 [1.6965]
7 [2.0311]
8 [2.1722]
9 [2.3054]
10 [2.4496]
11 [2.6037]
12 [2.8931]
13 [3.0022]
14 [3.1163]
15 [3.5518]
16 [3.7849]
17 [3.8638]
18 [4.1048]
19 [4.2503]
20 [4.4095]
21 [4.5034]
22 [4.6431]
23 [4.7795]
24 [4.8968]
train done
Epoch 362/1000 : Loss:0.2040, Valid loss: 0.2690, lr:0.000165 [0.731] 2233.6866438388824
1 [0.2296]
2 [0.3957]
3 [0.545]
4 [0.8163]
5 [1.0506]
6 [1.1603]
7 [1.2461]
8 [1.4974]
9 [1.6761]
10 [1.8014]
11 [1.941]
12 [2.0747]
13 [2.1912]
14 [2.477]
15 [2.6253]
16 [2.7958]
17 [2.9362]
18 [3.3449]
19 [3.4586]
20 [3.5993]
21 [3.6808]
22 [3.8465]
23 [4.0449]
24 [4.1435]
train done
Epoch 363/1000 : Loss:0.1726, Valid loss: 0.2607, lr:0.000165 [0.7393] 2096.9718952178955
1 [0.742]
2 [0.8482]
3 [1.098]
4 [1.3241]
5 [1.4039]
6 [1.5183]
7 [1.6798]
8 [1.7837]
9 [1.9955]
10 [2.1961]
11 [2.3402]
12 [2.4758]
13 [2.6244]
14 [2.8511]
15 [3.0602]
16 [3.2534]
17 [3.6273]
18 [3.7708]
19 [3.867]
20 [3.9736]
21 [4.1877]
22 [4.382]
23 [4.4879]
24 [4.713]
train done
Epoch 364/1000 : Loss:0.1964, Valid loss: 0.2781, lr:0.000165 [0.7219] 1984.6503632068634
1 [0.2376]
2 [0.4742]
3 [0.5712]
4 [0.6444]
5 [0.937]
6 [1.0547]
7 [1.1779]
8 [1.3746]
9 [1.5948]
10 [1.8294]
11 [1.9913]
12 [2.2293]
13 [2.4494]
14 [2.5221]
15 [2.8206]
16 [2.9716]
17 [3.0819]
18 [3.2638]
19 [3.6691]
20 [3.8048]
21 [4.1009]
22 [4.2852]
23 [4.4977]
24 [4.5828]
train done
Epoch 365/1000 : Loss:0.1910, Valid loss: 0.2650, lr:0.000165 [0.735] 1778.4795780181885
1 [0.1409]
2 [0.2789]
3 [0.411]
4 [0.4908]
5 [0.8392]
6 [1.023]
7 [1.1617]
8 [1.3845]
9 [1.4793]
10 [1.7036]
11 [1.8766]
12 [2.0899]
13 [2.2324]
14 [2.3855]
15 [2.6128]
16 [2.7562]
17 [2.9105]
18 [3.0159]
19 [3.2198]
20 [3.408]
21 [3.5277]
22 [3.6355]
23 [3.7314]
24 [4.011]
train done
Epoch 366/1000 : Loss:0.1671, Valid loss: 0.2725, lr:0.000165 [0.7275] 1780.0757162570953
1 [0.1557]
2 [0.3548]
3 [0.4478]
4 [0.6016]
5 [0.7569]
6 [0.9008]
7 [1.0074]
8 [1.2161]
9 [1.3151]
10 [1.4565]
11 [1.7896]
12 [2.0537]
13 [2.2534]
14 [2.331]
15 [2.459]
16 [2.5319]
17 [2.6897]
18 [2.8711]
19 [2.9979]
20 [3.2313]
21 [3.4314]
22 [3.5672]
23 [3.7165]
24 [3.8805]
train done
Epoch 367/1000 : Loss:0.1617, Valid loss: 0.2739, lr:0.000165 [0.7261] 1765.5627620220184
1 [0.1405]
2 [0.2407]
3 [0.3718]
4 [0.6157]
5 [0.7035]
6 [0.8603]
7 [0.9442]
8 [1.1183]
9 [1.3971]
10 [1.6364]
11 [1.7907]
12 [1.9309]
13 [2.1347]
14 [2.4588]
15 [2.6712]
16 [2.8689]
17 [3.0241]
18 [3.2066]
19 [3.4108]
20 [3.5444]
21 [3.6264]
22 [3.7549]
23 [3.8331]
24 [3.9796]
train done
Epoch 368/1000 : Loss:0.1658, Valid loss: 0.2745, lr:0.000165 [0.7255] 1754.4959149360657
1 [0.215]
2 [0.3777]
3 [0.5049]
4 [0.6068]
5 [0.8985]
6 [0.987]
7 [1.1625]
8 [1.4988]
9 [1.6658]
10 [1.7875]
11 [2.0422]
12 [2.3209]
13 [2.5246]
14 [2.6034]
15 [3.0351]
16 [3.2039]
17 [3.3228]
18 [3.476]
19 [3.6371]
20 [3.7104]
21 [3.8732]
22 [4.0317]
23 [4.1568]
24 [4.3084]
train done
Epoch 369/1000 : Loss:0.1795, Valid loss: 0.2842, lr:0.000165 [0.7158] 1759.6300008296967
1 [0.1312]
2 [0.3097]
3 [0.4395]
4 [0.5596]
5 [0.7007]
6 [0.8154]
7 [0.9001]
8 [1.0791]
9 [1.4565]
10 [1.5608]
11 [1.7207]
12 [1.8133]
13 [2.2867]
14 [2.4435]
15 [2.6563]
16 [2.8344]
17 [3.1561]
18 [3.2762]
19 [3.4455]
20 [3.7436]
21 [3.9013]
22 [4.0927]
23 [4.2206]
24 [4.4514]
train done
Epoch 370/1000 : Loss:0.1855, Valid loss: 0.2777, lr:0.000165 [0.7223] 1773.2238993644714
Model 370 saved.
1 [0.1785]
2 [0.4404]
3 [0.6375]
4 [0.7633]
5 [1.011]
6 [1.1012]
7 [1.2485]
8 [1.3936]
9 [1.5203]
10 [1.685]
11 [1.9394]
12 [2.0025]
13 [2.3702]
14 [2.5157]
15 [2.6103]
16 [2.8899]
17 [3.0036]
18 [3.1262]
19 [3.2636]
20 [3.5886]
21 [3.679]
22 [3.8055]
23 [3.9609]
24 [4.239]
train done
Epoch 371/1000 : Loss:0.1766, Valid loss: 0.2761, lr:0.000165 [0.7239] 2108.073750972748
1 [0.1645]
2 [0.249]
3 [0.6691]
4 [0.75]
5 [0.8847]
6 [1.0804]
7 [1.2289]
8 [1.3328]
9 [1.4057]
10 [1.6087]
11 [1.7983]
12 [1.9712]
13 [2.0544]
14 [2.2269]
15 [2.4198]
16 [2.5248]
17 [2.6918]
18 [2.8403]
19 [2.9675]
20 [3.1427]
21 [3.2923]
22 [3.4056]
23 [3.7201]
24 [3.8317]
train done
Epoch 372/1000 : Loss:0.1597, Valid loss: 0.2635, lr:0.000165 [0.7365] 2066.6526782512665
1 [0.1385]
2 [0.3044]
3 [0.5333]
4 [0.6912]
5 [0.9015]
6 [1.0434]
7 [1.2516]
8 [1.3266]
9 [1.5344]
10 [1.71]
11 [1.9158]
12 [2.1838]
13 [2.3947]
14 [2.5285]
15 [2.6033]
16 [2.7599]
17 [2.9276]
18 [3.1448]
19 [3.2856]
20 [3.5584]
21 [3.672]
22 [3.7723]
23 [3.8838]
24 [3.9958]
train done
Epoch 373/1000 : Loss:0.1665, Valid loss: 0.2921, lr:0.000165 [0.7079] 1778.107409954071
1 [0.2396]
2 [0.3149]
3 [0.4404]
4 [0.7829]
5 [0.8678]
6 [1.0187]
7 [1.1097]
8 [1.2484]
9 [1.351]
10 [1.5189]
11 [1.7329]
12 [1.8122]
13 [1.9744]
14 [2.0521]
15 [2.2128]
16 [2.3703]
17 [2.4759]
18 [2.7104]
19 [2.9662]
20 [3.1266]
21 [3.3332]
22 [3.5181]
23 [3.7361]
24 [3.8204]
train done
Epoch 374/1000 : Loss:0.1592, Valid loss: 0.2893, lr:0.000165 [0.7107] 1725.2866399288177
1 [0.1143]
2 [0.2152]
3 [0.3609]
4 [0.5398]
5 [0.703]
6 [0.9439]
7 [1.0283]
8 [1.244]
9 [1.3506]
10 [1.5025]
11 [1.7552]
12 [2.017]
13 [2.1081]
14 [2.3996]
15 [2.6372]
16 [2.7735]
17 [2.9342]
18 [3.2131]
19 [3.2939]
20 [3.6223]
21 [3.7052]
22 [3.8965]
23 [3.9883]
24 [4.4072]
train done
Epoch 375/1000 : Loss:0.1836, Valid loss: 0.2569, lr:0.000165 [0.7431] 2164.791566848755
1 [0.1004]
2 [0.2381]
3 [0.4845]
4 [0.5781]
5 [0.7684]
6 [0.9266]
7 [1.0734]
8 [1.2072]
9 [1.3115]
10 [1.5686]
11 [1.7167]
12 [1.9172]
13 [2.0997]
14 [2.2457]
15 [2.3975]
16 [2.6049]
17 [2.6857]
18 [2.7728]
19 [2.9872]
20 [3.3129]
21 [3.4297]
22 [3.5893]
23 [3.6874]
24 [3.8222]
train done
Epoch 376/1000 : Loss:0.1593, Valid loss: 0.2623, lr:0.000165 [0.7377] 2321.4870121479034
1 [0.0887]
2 [0.3265]
3 [0.4679]
4 [0.6131]
5 [0.6767]
6 [0.7754]
7 [0.8739]
8 [1.0595]
9 [1.3397]
10 [1.4085]
11 [1.5752]
12 [1.6958]
13 [1.8079]
14 [1.95]
15 [2.135]
16 [2.2236]
17 [2.3878]
18 [2.5312]
19 [2.7407]
20 [3.0681]
21 [3.2307]
22 [3.4613]
23 [3.6014]
24 [3.7009]
train done
Epoch 377/1000 : Loss:0.1542, Valid loss: 0.2690, lr:0.000165 [0.731] 2372.1398808956146
1 [0.1031]
2 [0.2068]
3 [0.3853]
4 [0.5388]
5 [0.6441]
6 [0.7679]
7 [0.8906]
8 [0.9585]
9 [1.0689]
10 [1.1988]
11 [1.4041]
12 [1.5404]
13 [1.781]
14 [1.8936]
15 [2.0712]
16 [2.3482]
17 [2.459]
18 [2.5536]
19 [2.7503]
20 [2.8599]
21 [3.1234]
22 [3.39]
23 [3.6278]
24 [3.7827]
train done
Epoch 378/1000 : Loss:0.1576, Valid loss: 0.2714, lr:0.000165 [0.7286] 2302.102035045624
1 [0.2323]
2 [0.3843]
3 [0.7673]
4 [0.9136]
5 [1.1199]
6 [1.1991]
7 [1.6276]
8 [1.7498]
9 [1.9211]
10 [2.1405]
11 [2.2279]
12 [2.3386]
13 [2.489]
14 [2.6041]
15 [2.7957]
16 [2.9113]
17 [3.071]
18 [3.2339]
19 [3.4135]
20 [3.6943]
21 [3.7791]
22 [3.9187]
23 [3.9991]
24 [4.1151]
train done
Epoch 379/1000 : Loss:0.1715, Valid loss: 0.2974, lr:0.000165 [0.7026] 2361.403864145279
1 [0.1814]
2 [0.2632]
3 [0.3927]
4 [0.5375]
5 [0.6428]
6 [0.7417]
7 [1.0023]
8 [1.1536]
9 [1.2838]
10 [1.392]
11 [1.4709]
12 [1.6375]
13 [1.963]
14 [2.1065]
15 [2.2457]
16 [2.519]
17 [2.6903]
18 [2.7849]
19 [2.9114]
20 [3.1093]
21 [3.3351]
22 [3.6976]
23 [3.8755]
24 [3.9646]
train done
Epoch 380/1000 : Loss:0.1652, Valid loss: 0.2961, lr:0.000165 [0.7039] 2386.5498909950256
Model 380 saved.
1 [0.0954]
2 [0.2481]
3 [0.4241]
4 [0.5318]
5 [0.6619]
6 [0.8423]
7 [1.1363]
8 [1.281]
9 [1.4075]
10 [1.5643]
11 [1.7032]
12 [1.8021]
13 [1.9944]
14 [2.636]
15 [2.7612]
16 [2.8616]
17 [3.0798]
18 [3.2758]
19 [3.4347]
20 [3.5717]
21 [3.7902]
22 [3.8883]
23 [4.1093]
24 [4.3163]
train done
Epoch 381/1000 : Loss:0.1798, Valid loss: 0.2624, lr:0.000165 [0.7376] 2432.761617898941
1 [0.1732]
2 [0.3602]
3 [0.4556]
4 [0.6628]
5 [0.85]
6 [0.9464]
7 [1.0642]
8 [1.2071]
9 [1.3593]
10 [1.4485]
11 [1.5427]
12 [1.7036]
13 [1.8391]
14 [1.9545]
15 [2.2133]
16 [2.4444]
17 [2.575]
18 [2.8122]
19 [2.9415]
20 [3.1727]
21 [3.2948]
22 [3.4281]
23 [3.5629]
24 [3.7201]
train done
Epoch 382/1000 : Loss:0.1550, Valid loss: 0.2757, lr:0.000165 [0.7243] 2350.6626391410828
1 [0.106]
2 [0.2409]
3 [0.3819]
4 [0.5852]
5 [0.9145]
6 [1.0298]
7 [1.1807]
8 [1.363]
9 [1.6804]
10 [1.8108]
11 [2.1967]
12 [2.5284]
13 [2.6237]
14 [2.7049]
15 [2.8075]
16 [2.9273]
17 [3.0283]
18 [3.256]
19 [3.3714]
20 [3.7574]
21 [3.9599]
22 [4.0859]
23 [4.208]
24 [4.3209]
train done
Epoch 383/1000 : Loss:0.1800, Valid loss: 0.2748, lr:0.000165 [0.7252] 2185.340584039688
1 [0.0936]
2 [0.239]
3 [0.5003]
4 [0.6008]
5 [0.7974]
6 [1.1278]
7 [1.2779]
8 [1.4315]
9 [1.5617]
10 [1.7199]
11 [1.7855]
12 [1.8788]
13 [2.106]
14 [2.2263]
15 [2.305]
16 [2.4269]
17 [2.6883]
18 [2.8217]
19 [2.903]
20 [3.1233]
21 [3.3083]
22 [3.4366]
23 [3.647]
24 [3.7278]
train done
Epoch 384/1000 : Loss:0.1553, Valid loss: 0.2782, lr:0.000165 [0.7218] 2136.721261024475
1 [0.3322]
2 [0.4203]
3 [0.6238]
4 [0.9821]
5 [1.0636]
6 [1.1714]
7 [1.3865]
8 [1.6898]
9 [1.7559]
10 [1.8768]
11 [2.004]
12 [2.3158]
13 [2.4548]
14 [2.5559]
15 [2.7274]
16 [2.7996]
17 [2.9319]
18 [3.1006]
19 [3.4109]
20 [3.5504]
21 [3.7377]
22 [3.9349]
23 [4.0482]
24 [4.2198]
train done
Epoch 385/1000 : Loss:0.1758, Valid loss: 0.2738, lr:0.000165 [0.7262] 2383.669686794281
1 [0.1879]
2 [0.333]
3 [0.4277]
4 [0.5545]
5 [0.6882]
6 [0.8049]
7 [1.0056]
8 [1.2187]
9 [1.3564]
10 [1.483]
11 [1.7039]
12 [2.003]
13 [2.1302]
14 [2.3954]
15 [2.5537]
16 [2.8117]
17 [3.0284]
18 [3.2394]
19 [3.4321]
20 [3.5546]
21 [3.6511]
22 [3.7292]
23 [3.8745]
24 [4.0275]
train done
Epoch 386/1000 : Loss:0.1678, Valid loss: 0.2541, lr:0.000165 [0.7459] 2373.962616920471
1 [0.2834]
2 [0.4844]
3 [0.6731]
4 [0.8457]
5 [0.9604]
6 [1.0874]
7 [1.2204]
8 [1.4692]
9 [1.6763]
10 [1.8916]
11 [2.0174]
12 [2.1769]
13 [2.3289]
14 [2.472]
15 [2.6265]
16 [2.9557]
17 [3.1375]
18 [3.3356]
19 [3.505]
20 [3.5908]
21 [3.679]
22 [3.805]
23 [3.9004]
24 [4.0369]
train done
Epoch 387/1000 : Loss:0.1682, Valid loss: 0.2767, lr:0.000165 [0.7233] 2304.5199978351593
1 [0.1471]
2 [0.2575]
3 [0.4745]
4 [0.5986]
5 [0.703]
6 [0.8948]
7 [1.084]
8 [1.3143]
9 [1.4087]
10 [1.5965]
11 [1.8637]
12 [1.9587]
13 [2.1912]
14 [2.2876]
15 [2.3559]
16 [2.6383]
17 [2.9612]
18 [3.1074]
19 [3.2432]
20 [3.325]
21 [3.4637]
22 [3.5969]
23 [3.6725]
24 [3.9232]
train done
Epoch 388/1000 : Loss:0.1635, Valid loss: 0.2706, lr:0.000165 [0.7294] 2249.6374258995056
1 [0.1592]
2 [0.3096]
3 [0.4185]
4 [0.4891]
5 [0.5977]
6 [0.7203]
7 [0.8771]
8 [1.0278]
9 [1.2239]
10 [1.6479]
11 [1.8911]
12 [2.0864]
13 [2.2595]
14 [2.3336]
15 [2.4643]
16 [2.6335]
17 [2.7464]
18 [2.819]
19 [3.0124]
20 [3.1539]
21 [3.3]
22 [3.4673]
23 [3.6005]
24 [3.8113]
train done
Epoch 389/1000 : Loss:0.1588, Valid loss: 0.2607, lr:0.000165 [0.7393] 2075.179486989975
1 [0.2887]
2 [0.462]
3 [0.5316]
4 [0.7209]
5 [0.8249]
6 [1.0964]
7 [1.219]
8 [1.3664]
9 [1.5559]
10 [1.7461]
11 [1.9073]
12 [2.1781]
13 [2.3741]
14 [2.5251]
15 [2.6603]
16 [2.7842]
17 [2.9243]
18 [3.0538]
19 [3.211]
20 [3.3205]
21 [3.4037]
22 [3.5602]
23 [3.6773]
24 [3.7962]
train done
Epoch 390/1000 : Loss:0.1582, Valid loss: 0.2684, lr:0.000165 [0.7316] 2007.1676511764526
Model 390 saved.
1 [0.1502]
2 [0.296]
3 [0.4306]
4 [0.6553]
5 [0.7155]
6 [0.83]
7 [1.0734]
8 [1.2317]
9 [1.3685]
10 [1.5747]
11 [1.7736]
12 [1.8808]
13 [1.9969]
14 [2.138]
15 [2.3]
16 [2.4784]
17 [2.6137]
18 [2.7298]
19 [2.9442]
20 [3.0448]
21 [3.1785]
22 [3.3876]
23 [3.4964]
24 [3.6855]
train done
Epoch 391/1000 : Loss:0.1536, Valid loss: 0.2845, lr:0.000165 [0.7155] 1795.4519081115723
1 [0.1555]
2 [0.5513]
3 [0.7019]
4 [0.8976]
5 [0.9836]
6 [1.0561]
7 [1.2005]
8 [1.3312]
9 [1.5082]
10 [1.649]
11 [1.7835]
12 [1.8761]
13 [2.1021]
14 [2.1796]
15 [2.2903]
16 [2.497]
17 [2.6664]
18 [2.8548]
19 [3.0314]
20 [3.1475]
21 [3.2642]
22 [3.5691]
23 [3.7628]
24 [3.8759]
train done
Epoch 392/1000 : Loss:0.1615, Valid loss: 0.2701, lr:0.000165 [0.7299] 1781.5096671581268
1 [0.1321]
2 [0.2059]
3 [0.2975]
4 [0.4404]
5 [0.5307]
6 [0.6611]
7 [0.7967]
8 [1.0785]
9 [1.2393]
10 [1.3635]
11 [1.4887]
12 [1.6785]
13 [1.7744]
14 [1.9759]
15 [2.1698]
16 [2.4063]
17 [2.5274]
18 [2.7081]
19 [2.8625]
20 [3.0852]
21 [3.1784]
22 [3.5576]
23 [3.7259]
24 [3.9185]
train done
Epoch 393/1000 : Loss:0.1633, Valid loss: 0.2847, lr:0.000165 [0.7153] 1773.4437129497528
1 [0.0877]
2 [0.2386]
3 [0.423]
4 [0.5508]
5 [0.734]
6 [0.8609]
7 [1.1221]
8 [1.2178]
9 [1.3693]
10 [1.6246]
11 [1.836]
12 [1.9645]
13 [2.1629]
14 [2.5595]
15 [2.7269]
16 [2.8352]
17 [2.9622]
18 [3.1015]
19 [3.2376]
20 [3.373]
21 [3.6056]
22 [3.7667]
23 [3.8723]
24 [4.1022]
train done
Epoch 394/1000 : Loss:0.1709, Valid loss: 0.2776, lr:0.000165 [0.7224] 1894.5130350589752
1 [0.6603]
2 [0.8484]
3 [1.0127]
4 [1.1049]
5 [1.3641]
6 [1.6385]
7 [1.863]
8 [2.012]
9 [2.1197]
10 [2.2292]
11 [2.4308]
12 [2.5872]
13 [2.715]
14 [2.8128]
15 [3.0038]
16 [3.1636]
17 [3.3126]
18 [3.4769]
19 [3.6132]
20 [3.6971]
21 [3.8468]
22 [3.9887]
23 [4.251]
24 [4.4509]
train done
Epoch 395/1000 : Loss:0.1855, Valid loss: 0.2777, lr:0.000165 [0.7223] 1801.691633939743
1 [0.2203]
2 [0.4372]
3 [0.5905]
4 [0.7527]
5 [1.0532]
6 [1.2009]
7 [1.3261]
8 [1.6586]
9 [1.8332]
10 [1.9163]
11 [1.9861]
12 [2.0898]
13 [2.1739]
14 [2.2692]
15 [2.4262]
16 [2.5801]
17 [2.7813]
18 [2.9144]
19 [3.3436]
20 [3.41]
21 [3.5853]
22 [3.8248]
23 [4.0668]
24 [4.1564]
train done
Epoch 396/1000 : Loss:0.1732, Valid loss: 0.2669, lr:0.000165 [0.7331] 1801.225081205368
1 [0.131]
2 [0.1952]
3 [0.363]
4 [0.4878]
5 [0.6743]
6 [0.94]
7 [1.0509]
8 [1.1664]
9 [1.2725]
10 [1.4832]
11 [1.6215]
12 [1.6932]
13 [1.8059]
14 [1.9397]
15 [2.1088]
16 [2.3059]
17 [2.5581]
18 [2.7234]
19 [2.845]
20 [3.1261]
21 [3.2737]
22 [3.4043]
23 [3.5956]
24 [3.681]
train done
Epoch 397/1000 : Loss:0.1534, Valid loss: 0.2718, lr:0.000165 [0.7282] 1790.7885489463806
1 [0.0862]
2 [0.1827]
3 [0.399]
4 [0.5598]
5 [0.8214]
6 [1.1122]
7 [1.2144]
8 [1.3862]
9 [1.455]
10 [1.6282]
11 [1.7434]
12 [2.109]
13 [2.2537]
14 [2.3605]
15 [2.5719]
16 [2.7081]
17 [2.9077]
18 [3.0514]
19 [3.1288]
20 [3.2372]
21 [3.3693]
22 [3.4926]
23 [3.623]
24 [3.8338]
train done
Epoch 398/1000 : Loss:0.1597, Valid loss: 0.2756, lr:0.000165 [0.7244] 1831.0298130512238
1 [0.222]
2 [0.3762]
3 [0.6192]
4 [0.7817]
5 [0.8918]
6 [1.0493]
7 [1.1264]
8 [1.2757]
9 [1.3891]
10 [1.5354]
11 [1.8574]
12 [1.931]
13 [2.0065]
14 [2.1327]
15 [2.2071]
16 [2.3469]
17 [2.4629]
18 [2.7076]
19 [2.8718]
20 [3.1477]
21 [3.28]
22 [3.5878]
23 [3.8014]
24 [4.0574]
train done
Epoch 399/1000 : Loss:0.1691, Valid loss: 0.2741, lr:0.000165 [0.7259] 1766.6308379173279
1 [0.3402]
2 [0.4959]
3 [0.6276]
4 [0.7922]
5 [0.9322]
6 [1.0921]
7 [1.2813]
8 [1.5111]
9 [1.7077]
10 [1.8868]
11 [2.004]
12 [2.0884]
13 [2.1588]
14 [2.2977]
15 [2.4991]
16 [2.5933]
17 [2.6942]
18 [2.8815]
19 [3.3129]
20 [3.4615]
21 [3.6043]
22 [3.904]
23 [4.055]
24 [4.2453]
train done
Epoch 400/1000 : Loss:0.1769, Valid loss: 0.2829, lr:0.000165 [0.7171] 1781.6789078712463
Model 400 saved.
1 [0.169]
2 [0.2669]
3 [0.4767]
4 [0.6407]
5 [0.783]
6 [0.96]
7 [1.1526]
8 [1.3281]
9 [1.4493]
10 [1.5512]
11 [1.7324]
12 [1.9594]
13 [2.2146]
14 [2.6296]
15 [2.8141]
16 [2.9477]
17 [3.031]
18 [3.1817]
19 [3.3178]
20 [3.4697]
21 [3.7874]
22 [3.8787]
23 [3.9833]
24 [4.1203]
train done
Epoch 401/1000 : Loss:0.1717, Valid loss: 0.2736, lr:0.000115 [0.7264] 1767.4327719211578
1 [0.1342]
2 [0.2435]
3 [0.3444]
4 [0.5326]
5 [0.6641]
6 [0.8491]
7 [1.0091]
8 [1.0846]
9 [1.3359]
10 [1.4429]
11 [1.5964]
12 [1.7127]
13 [1.8307]
14 [1.9664]
15 [2.2399]
16 [2.338]
17 [2.4211]
18 [2.5721]
19 [2.651]
20 [2.913]
21 [3.1614]
22 [3.3336]
23 [3.7028]
24 [3.7783]
train done
Epoch 402/1000 : Loss:0.1574, Valid loss: 0.2717, lr:0.000115 [0.7283] 1812.7105658054352
1 [0.0996]
2 [0.2874]
3 [0.4132]
4 [0.7725]
5 [0.8389]
6 [0.9689]
7 [1.1355]
8 [1.3829]
9 [1.5589]
10 [1.7458]
11 [1.8724]
12 [1.9999]
13 [2.1711]
14 [2.277]
15 [2.4695]
16 [2.5785]
17 [2.8256]
18 [3.0663]
19 [3.1763]
20 [3.3387]
21 [3.486]
22 [3.7334]
23 [4.0492]
24 [4.1596]
train done
Epoch 403/1000 : Loss:0.1733, Valid loss: 0.2760, lr:0.000115 [0.724] 1785.4865260124207
1 [0.285]
2 [0.4921]
3 [0.6045]
4 [0.7246]
5 [0.8216]
6 [0.8971]
7 [1.1468]
8 [1.3618]
9 [1.5427]
10 [1.7113]
11 [1.8398]
12 [1.9707]
13 [2.0737]
14 [2.1551]
15 [2.5037]
16 [2.6656]
17 [2.7615]
18 [2.9253]
19 [3.1256]
20 [3.2585]
21 [3.353]
22 [3.4527]
23 [3.7249]
24 [3.8982]
train done
Epoch 404/1000 : Loss:0.1624, Valid loss: 0.2802, lr:0.000115 [0.7198] 1801.0428838729858
1 [0.0957]
2 [0.3383]
3 [0.3383]
4 [0.5525]
5 [0.6247]
6 [0.7872]
7 [1.059]
8 [1.3803]
9 [1.5349]
10 [1.6498]
11 [1.8694]
12 [2.1896]
13 [2.2883]
14 [2.4815]
15 [2.6585]
16 [2.8138]
17 [2.9335]
18 [3.1126]
19 [3.2719]
20 [3.3707]
21 [3.5352]
22 [3.614]
23 [3.8586]
24 [4.0238]
train done
Epoch 405/1000 : Loss:0.1677, Valid loss: 0.2679, lr:0.000115 [0.7321] 1807.4278810024261
1 [0.1706]
2 [0.3654]
3 [0.6244]
4 [0.7214]
5 [0.9431]
6 [1.2529]
7 [1.3831]
8 [1.472]
9 [1.5396]
10 [1.6077]
11 [1.8089]
12 [1.9309]
13 [2.0671]
14 [2.2218]
15 [2.3105]
16 [2.4503]
17 [2.6452]
18 [2.7911]
19 [2.859]
20 [2.9591]
21 [3.1332]
22 [3.2905]
23 [3.5221]
24 [3.7878]
train done
Epoch 406/1000 : Loss:0.1578, Valid loss: 0.2782, lr:0.000115 [0.7218] 1813.3303377628326
1 [0.1129]
2 [0.2498]
3 [0.5231]
4 [0.7282]
5 [1.0488]
6 [1.1837]
7 [1.251]
8 [1.4251]
9 [1.66]
10 [1.7489]
11 [1.8445]
12 [1.9913]
13 [2.1744]
14 [2.2716]
15 [2.4181]
16 [2.5372]
17 [2.6358]
18 [2.7955]
19 [2.9251]
20 [3.0212]
21 [3.0973]
22 [3.3354]
23 [3.4517]
24 [3.5842]
train done
Epoch 407/1000 : Loss:0.1493, Valid loss: 0.2740, lr:0.000115 [0.726] 1802.645362854004
1 [0.0869]
2 [0.1676]
3 [0.3118]
4 [0.4744]
5 [0.7445]
6 [0.8089]
7 [0.9585]
8 [1.1076]
9 [1.2617]
10 [1.3741]
11 [1.4839]
12 [1.6891]
13 [1.7869]
14 [1.9806]
15 [2.1641]
16 [2.3581]
17 [2.52]
18 [2.88]
19 [3.0278]
20 [3.2068]
21 [3.2795]
22 [3.354]
23 [3.4615]
24 [3.7568]
train done
Epoch 408/1000 : Loss:0.1565, Valid loss: 0.2706, lr:0.000115 [0.7294] 1818.5392379760742
1 [0.2176]
2 [0.4186]
3 [0.6478]
4 [0.7685]
5 [0.8588]
6 [1.1222]
7 [1.3947]
8 [1.5039]
9 [1.6709]
10 [1.8621]
11 [1.9829]
12 [2.1629]
13 [2.2969]
14 [2.3796]
15 [2.53]
16 [2.6949]
17 [2.8782]
18 [3.0013]
19 [3.0867]
20 [3.1618]
21 [3.2616]
22 [3.4543]
23 [3.5945]
24 [3.9813]
train done
Epoch 409/1000 : Loss:0.1659, Valid loss: 0.2641, lr:0.000115 [0.7359] 1993.1581401824951
1 [0.1255]
2 [0.4283]
3 [0.709]
4 [0.8557]
5 [1.001]
6 [1.2477]
7 [1.5019]
8 [1.6753]
9 [1.9401]
10 [2.1012]
11 [2.1667]
12 [2.269]
13 [2.4102]
14 [2.4866]
15 [2.639]
16 [2.7738]
17 [3.0611]
18 [3.3013]
19 [3.3962]
20 [3.5266]
21 [3.6351]
22 [3.733]
23 [3.8617]
24 [3.9911]
train done
Epoch 410/1000 : Loss:0.1663, Valid loss: 0.2727, lr:0.000115 [0.7273] 2368.515275001526
Model 410 saved.
1 [0.097]
2 [0.2484]
3 [0.367]
4 [0.6564]
5 [0.7806]
6 [0.8823]
7 [0.9882]
8 [1.1743]
9 [1.2679]
10 [1.34]
11 [1.6671]
12 [1.7596]
13 [1.9501]
14 [2.1044]
15 [2.217]
16 [2.3661]
17 [2.5367]
18 [2.7009]
19 [2.9151]
20 [3.0562]
21 [3.1791]
22 [3.4141]
23 [3.5246]
24 [3.7703]
train done
Epoch 411/1000 : Loss:0.1571, Valid loss: 0.2639, lr:0.000115 [0.7361] 2313.092225790024
1 [0.1217]
2 [0.3627]
3 [0.5121]
4 [0.6436]
5 [0.7598]
6 [0.8784]
7 [0.9898]
8 [1.1384]
9 [1.2871]
10 [1.4557]
11 [1.7471]
12 [1.9256]
13 [2.3218]
14 [2.4161]
15 [2.5237]
16 [2.6244]
17 [2.7211]
18 [2.893]
19 [3.0189]
20 [3.1626]
21 [3.3263]
22 [3.5217]
23 [3.7227]
24 [3.8802]
train done
Epoch 412/1000 : Loss:0.1617, Valid loss: 0.2692, lr:0.000115 [0.7308] 2217.9567580223083
1 [0.1218]
2 [0.3487]
3 [0.5906]
4 [0.89]
5 [0.9642]
6 [1.0786]
7 [1.207]
8 [1.4852]
9 [1.703]
10 [1.7868]
11 [1.9117]
12 [2.0573]
13 [2.2694]
14 [2.3795]
15 [2.5247]
16 [2.5949]
17 [2.7283]
18 [2.794]
19 [2.9421]
20 [3.0529]
21 [3.3631]
22 [3.4947]
23 [3.6975]
24 [3.9092]
train done
Epoch 413/1000 : Loss:0.1629, Valid loss: 0.2763, lr:0.000115 [0.7237] 2128.2225120067596
1 [0.254]
2 [0.3528]
3 [0.5167]
4 [0.7992]
5 [0.9315]
6 [1.0989]
7 [1.2144]
8 [1.3952]
9 [1.4998]
10 [1.5794]
11 [1.6499]
12 [1.7642]
13 [2.069]
14 [2.3654]
15 [2.5786]
16 [2.6466]
17 [2.7751]
18 [3.0129]
19 [3.2514]
20 [3.3149]
21 [3.4696]
22 [3.6661]
23 [3.7764]
24 [4.0355]
train done
Epoch 414/1000 : Loss:0.1681, Valid loss: 0.2822, lr:0.000115 [0.7178] 2158.663542032242
1 [0.1946]
2 [0.3028]
3 [0.4758]
4 [0.6122]
5 [0.8328]
6 [1.0043]
7 [1.2462]
8 [1.4116]
9 [1.6059]
10 [1.7601]
11 [1.9147]
12 [2.0771]
13 [2.1845]
14 [2.4556]
15 [2.5457]
16 [2.649]
17 [2.8504]
18 [3.0167]
19 [3.2664]
20 [3.4179]
21 [3.5261]
22 [3.5974]
23 [3.7908]
24 [3.8935]
train done
Epoch 415/1000 : Loss:0.1622, Valid loss: 0.2608, lr:0.000115 [0.7392] 1783.9386780261993
1 [0.1951]
2 [0.3121]
3 [0.445]
4 [0.5111]
5 [0.6463]
6 [0.7155]
7 [0.8077]
8 [1.008]
9 [1.1754]
10 [1.2981]
11 [1.5086]
12 [1.6179]
13 [1.8345]
14 [1.9341]
15 [2.0783]
16 [2.205]
17 [2.3421]
18 [2.4698]
19 [2.5543]
20 [2.6491]
21 [3.0557]
22 [3.287]
23 [3.4967]
24 [3.6311]
train done
Epoch 416/1000 : Loss:0.1513, Valid loss: 0.2631, lr:0.000115 [0.7369] 1704.544498205185
1 [0.1043]
2 [0.2008]
3 [0.3014]
4 [0.3926]
5 [0.4926]
6 [0.5793]
7 [0.958]
8 [1.1063]
9 [1.3477]
10 [1.5233]
11 [1.6394]
12 [1.7721]
13 [1.8612]
14 [1.9955]
15 [2.1829]
16 [2.284]
17 [2.5553]
18 [2.7213]
19 [2.8792]
20 [3.0725]
21 [3.2471]
22 [3.4279]
23 [3.6042]
24 [3.9215]
train done
Epoch 417/1000 : Loss:0.1634, Valid loss: 0.2685, lr:0.000115 [0.7315] 1721.528776884079
1 [0.1372]
2 [0.2625]
3 [0.4646]
4 [0.6623]
5 [0.8114]
6 [0.897]
7 [1.179]
8 [1.3001]
9 [1.4194]
10 [1.5606]
11 [1.6261]
12 [1.7707]
13 [1.9041]
14 [2.0447]
15 [2.3056]
16 [2.4551]
17 [2.5371]
18 [2.6941]
19 [2.8591]
20 [3.104]
21 [3.3661]
22 [3.4507]
23 [3.537]
24 [3.7314]
train done
Epoch 418/1000 : Loss:0.1555, Valid loss: 0.2698, lr:0.000115 [0.7302] 1716.3860869407654
1 [0.1056]
2 [0.2079]
3 [0.3845]
4 [0.5611]
5 [0.6993]
6 [0.8947]
7 [1.0733]
8 [1.1589]
9 [1.3087]
10 [1.4161]
11 [1.4889]
12 [1.6893]
13 [1.8374]
14 [1.933]
15 [2.1081]
16 [2.235]
17 [2.4331]
18 [2.5753]
19 [2.6655]
20 [2.9125]
21 [3.0214]
22 [3.1593]
23 [3.3629]
24 [3.6399]
train done
Epoch 419/1000 : Loss:0.1517, Valid loss: 0.2796, lr:0.000115 [0.7204] 1704.5558819770813
1 [0.2375]
2 [0.4214]
3 [0.515]
4 [0.6675]
5 [0.8031]
6 [0.9049]
7 [0.9899]
8 [1.1113]
9 [1.3528]
10 [1.525]
11 [1.8381]
12 [2.0735]
13 [2.1755]
14 [2.3118]
15 [2.3949]
16 [2.8662]
17 [2.9744]
18 [3.1387]
19 [3.2165]
20 [3.3801]
21 [3.5027]
22 [3.6839]
23 [3.7719]
24 [3.9245]
train done
Epoch 420/1000 : Loss:0.1635, Valid loss: 0.2704, lr:0.000115 [0.7296] 1742.400446176529
Model 420 saved.
1 [0.075]
2 [0.176]
3 [0.3043]
4 [0.39]
5 [0.5499]
6 [0.7201]
7 [0.8423]
8 [1.0622]
9 [1.3381]
10 [1.4231]
11 [1.5339]
12 [1.7385]
13 [1.8602]
14 [2.0416]
15 [2.1708]
16 [2.3103]
17 [2.6207]
18 [2.812]
19 [2.8905]
20 [3.1649]
21 [3.2889]
22 [3.4811]
23 [3.6413]
24 [3.8597]
train done
Epoch 421/1000 : Loss:0.1608, Valid loss: 0.2662, lr:0.000115 [0.7338] 1752.8161149024963
1 [0.0621]
2 [0.1333]
3 [0.2591]
4 [0.3587]
5 [0.6141]
6 [0.7457]
7 [0.867]
8 [1.0781]
9 [1.29]
10 [1.5981]
11 [1.7811]
12 [1.9074]
13 [2.1682]
14 [2.2711]
15 [2.3817]
16 [2.6057]
17 [2.7454]
18 [2.9641]
19 [3.2181]
20 [3.3274]
21 [3.4281]
22 [3.4981]
23 [3.6715]
24 [3.8448]
train done
Epoch 422/1000 : Loss:0.1602, Valid loss: 0.2641, lr:0.000115 [0.7359] 1747.6194832324982
1 [0.1799]
2 [0.2418]
3 [0.4494]
4 [0.6561]
5 [0.7832]
6 [0.8839]
7 [0.99]
8 [1.0956]
9 [1.0956]
10 [1.1882]
11 [1.3367]
12 [1.4742]
13 [1.6236]
14 [1.7467]
15 [2.042]
16 [2.2139]
17 [2.4147]
18 [2.7488]
19 [2.8342]
20 [2.9767]
21 [3.2397]
22 [3.3432]
23 [3.4722]
24 [3.5654]
train done
Epoch 423/1000 : Loss:0.1486, Valid loss: 0.2628, lr:0.000115 [0.7372] 1823.8384189605713
1 [0.1467]
2 [0.3263]
3 [0.4212]
4 [0.6161]
5 [0.776]
6 [0.8469]
7 [0.9291]
8 [1.1512]
9 [1.2486]
10 [1.3562]
11 [1.4716]
12 [1.5514]
13 [1.6942]
14 [1.8478]
15 [1.9773]
16 [2.2264]
17 [2.3537]
18 [2.5921]
19 [2.9117]
20 [3.0244]
21 [3.2628]
22 [3.4352]
23 [3.5948]
24 [3.7185]
train done
Epoch 424/1000 : Loss:0.1549, Valid loss: 0.2672, lr:0.000115 [0.7328] 2007.1103518009186
1 [0.1382]
2 [0.2416]
3 [0.4087]
4 [0.5885]
5 [0.7855]
6 [0.92]
7 [1.1581]
8 [1.3296]
9 [1.3977]
10 [1.5245]
11 [1.6268]
12 [1.8532]
13 [2.0148]
14 [2.2829]
15 [2.3633]
16 [2.5942]
17 [2.6893]
18 [2.7755]
19 [2.8784]
20 [2.9609]
21 [3.0472]
22 [3.2118]
23 [3.4379]
24 [3.6829]
train done
Epoch 425/1000 : Loss:0.1535, Valid loss: 0.2709, lr:0.000115 [0.7291] 1995.4413828849792
1 [0.0707]
2 [0.1555]
3 [0.3273]
4 [0.4675]
5 [0.6314]
6 [0.7236]
7 [0.8578]
8 [0.991]
9 [1.0926]
10 [1.257]
11 [1.4021]
12 [1.5671]
13 [1.7386]
14 [1.8316]
15 [1.9558]
16 [2.0738]
17 [2.2625]
18 [2.4924]
19 [2.6913]
20 [2.8167]
21 [2.975]
22 [3.1073]
23 [3.2631]
24 [3.3359]
train done
Epoch 426/1000 : Loss:0.1390, Valid loss: 0.2638, lr:0.000115 [0.7362] 2093.3296291828156
1 [0.0881]
2 [0.2322]
3 [0.33]
4 [0.8095]
5 [0.9237]
6 [1.1007]
7 [1.2405]
8 [1.4361]
9 [1.6384]
10 [1.7813]
11 [1.8527]
12 [1.9922]
13 [2.3023]
14 [2.4289]
15 [2.6419]
16 [2.7664]
17 [3.1036]
18 [3.2352]
19 [3.318]
20 [3.4513]
21 [3.6545]
22 [3.8709]
23 [3.9857]
24 [4.1297]
train done
Epoch 427/1000 : Loss:0.1721, Valid loss: 0.2769, lr:0.000115 [0.7231] 2080.736491918564
1 [0.0853]
2 [0.2601]
3 [0.5185]
4 [0.8042]
5 [0.9392]
6 [1.0617]
7 [1.1927]
8 [1.2831]
9 [1.4349]
10 [1.5767]
11 [1.8315]
12 [2.0483]
13 [2.2449]
14 [2.4528]
15 [2.6601]
16 [2.8455]
17 [2.9553]
18 [3.0467]
19 [3.2165]
20 [3.3518]
21 [3.5569]
22 [3.6657]
23 [3.7986]
24 [3.9279]
train done
Epoch 428/1000 : Loss:0.1637, Valid loss: 0.2717, lr:0.000115 [0.7283] 2156.9164519309998
1 [0.0977]
2 [0.2748]
3 [0.4957]
4 [0.6258]
5 [0.7788]
6 [0.863]
7 [0.863]
8 [1.1142]
9 [1.201]
10 [1.3378]
11 [1.4368]
12 [1.5603]
13 [1.659]
14 [1.8569]
15 [1.9553]
16 [2.1144]
17 [2.2537]
18 [2.4171]
19 [2.5879]
20 [2.7126]
21 [2.8883]
22 [2.9889]
23 [3.2606]
24 [3.4019]
train done
Epoch 429/1000 : Loss:0.1417, Valid loss: 0.2734, lr:0.000115 [0.7266] 1973.7243828773499
1 [0.1712]
2 [0.3144]
3 [0.4756]
4 [0.5822]
5 [0.6892]
6 [0.8376]
7 [1.0455]
8 [1.1333]
9 [1.287]
10 [1.4901]
11 [1.5889]
12 [1.7099]
13 [1.8908]
14 [2.032]
15 [2.1657]
16 [2.2908]
17 [2.4654]
18 [2.5966]
19 [2.7031]
20 [2.8543]
21 [2.9372]
22 [3.3156]
23 [3.4026]
24 [3.6152]
train done
Epoch 430/1000 : Loss:0.1506, Valid loss: 0.2658, lr:0.000115 [0.7342] 1731.173327922821
Model 430 saved.
1 [0.1379]
2 [0.3051]
3 [0.4418]
4 [0.5653]
5 [0.824]
6 [0.9288]
7 [1.2224]
8 [1.304]
9 [1.3965]
10 [1.5272]
11 [1.7023]
12 [2.0179]
13 [2.2726]
14 [2.3684]
15 [2.5762]
16 [2.7329]
17 [2.826]
18 [2.919]
19 [3.1471]
20 [3.2854]
21 [3.3607]
22 [3.5929]
23 [3.7611]
24 [3.8651]
train done
Epoch 431/1000 : Loss:0.1610, Valid loss: 0.2676, lr:0.000115 [0.7324] 1705.965273141861
1 [0.0761]
2 [0.2326]
3 [0.4256]
4 [0.5313]
5 [0.6716]
6 [0.8833]
7 [1.0384]
8 [1.3684]
9 [1.6745]
10 [1.7569]
11 [1.8517]
12 [2.0902]
13 [2.3288]
14 [2.4483]
15 [2.5384]
16 [2.7536]
17 [3.0261]
18 [3.1039]
19 [3.4997]
20 [3.705]
21 [3.7899]
22 [3.8688]
23 [4.013]
24 [4.1232]
train done
Epoch 432/1000 : Loss:0.1718, Valid loss: 0.2699, lr:0.000115 [0.7301] 1694.7634108066559
1 [0.1777]
2 [0.311]
3 [0.5985]
4 [0.6982]
5 [0.8138]
6 [0.9004]
7 [1.0953]
8 [1.1769]
9 [1.4818]
10 [1.6673]
11 [1.7947]
12 [1.9001]
13 [2.0437]
14 [2.2048]
15 [2.3143]
16 [2.3933]
17 [2.6005]
18 [2.7121]
19 [2.7884]
20 [3.0186]
21 [3.0937]
22 [3.3816]
23 [3.6464]
24 [3.826]
train done
Epoch 433/1000 : Loss:0.1594, Valid loss: 0.2700, lr:0.000115 [0.73] 1700.2034533023834
1 [0.145]
2 [0.2468]
3 [0.4016]
4 [0.6541]
5 [0.7324]
6 [0.8169]
7 [1.01]
8 [1.2289]
9 [1.5397]
10 [1.667]
11 [2.0391]
12 [2.1763]
13 [2.307]
14 [2.4742]
15 [2.5681]
16 [2.7447]
17 [2.9935]
18 [3.0963]
19 [3.1831]
20 [3.2884]
21 [3.3684]
22 [3.5209]
23 [3.6613]
24 [3.7707]
train done
Epoch 434/1000 : Loss:0.1571, Valid loss: 0.2764, lr:0.000115 [0.7236] 1690.639975309372
1 [0.1229]
2 [0.2475]
3 [0.3514]
4 [0.6741]
5 [0.7814]
6 [0.8565]
7 [0.962]
8 [1.0505]
9 [1.2742]
10 [1.6002]
11 [1.6704]
12 [1.7385]
13 [1.8919]
14 [2.0088]
15 [2.1249]
16 [2.4807]
17 [2.685]
18 [2.8289]
19 [2.967]
20 [3.2216]
21 [3.4803]
22 [3.5967]
23 [3.8155]
24 [4.0336]
train done
Epoch 435/1000 : Loss:0.1681, Valid loss: 0.2789, lr:0.000115 [0.7211] 1693.161294221878
1 [0.1631]
2 [0.3579]
3 [0.4771]
4 [0.6394]
5 [0.7343]
6 [0.9276]
7 [1.0096]
8 [1.1133]
9 [1.2646]
10 [1.5326]
11 [1.795]
12 [1.8835]
13 [1.9829]
14 [2.2628]
15 [2.421]
16 [2.5583]
17 [2.7282]
18 [2.8068]
19 [2.9029]
20 [3.035]
21 [3.2483]
22 [3.3396]
23 [3.4918]
24 [3.5889]
train done
Epoch 436/1000 : Loss:0.1495, Valid loss: 0.2677, lr:0.000115 [0.7323] 1704.3974997997284
1 [0.1632]
2 [0.2417]
3 [0.3418]
4 [0.6042]
5 [0.7106]
6 [0.8474]
7 [1.0333]
8 [1.1572]
9 [1.2734]
10 [1.4164]
11 [1.6361]
12 [1.854]
13 [1.9909]
14 [2.1748]
15 [2.3115]
16 [2.448]
17 [2.5881]
18 [2.7333]
19 [2.8212]
20 [2.9243]
21 [3.1302]
22 [3.3913]
23 [3.4757]
24 [3.6512]
train done
Epoch 437/1000 : Loss:0.1521, Valid loss: 0.2734, lr:0.000115 [0.7266] 1696.7434151172638
1 [0.107]
2 [0.3566]
3 [0.5914]
4 [0.726]
5 [0.9321]
6 [1.073]
7 [1.1481]
8 [1.282]
9 [1.4465]
10 [1.5543]
11 [1.7126]
12 [1.8105]
13 [1.909]
14 [2.1882]
15 [2.3745]
16 [2.5477]
17 [2.6983]
18 [2.7833]
19 [3.0097]
20 [3.1046]
21 [3.3142]
22 [3.5897]
23 [3.6652]
24 [3.8124]
train done
Epoch 438/1000 : Loss:0.1589, Valid loss: 0.2662, lr:0.000115 [0.7338] 1699.786476135254
1 [0.2388]
2 [0.3679]
3 [0.6732]
4 [0.9046]
5 [1.0365]
6 [1.1627]
7 [1.242]
8 [1.375]
9 [1.5063]
10 [1.6152]
11 [1.7505]
12 [1.9372]
13 [2.0901]
14 [2.161]
15 [2.2537]
16 [2.3292]
17 [2.4692]
18 [2.5655]
19 [2.8931]
20 [2.9932]
21 [3.1057]
22 [3.3489]
23 [3.5424]
24 [3.6916]
train done
Epoch 439/1000 : Loss:0.1538, Valid loss: 0.2697, lr:0.000115 [0.7303] 1721.1056315898895
1 [0.1181]
2 [0.1861]
3 [0.2989]
4 [0.423]
5 [0.5014]
6 [0.708]
7 [0.8936]
8 [1.0272]
9 [1.0918]
10 [1.2103]
11 [1.3844]
12 [1.5622]
13 [1.7885]
14 [1.916]
15 [1.9913]
16 [2.18]
17 [2.2693]
18 [2.5838]
19 [2.6679]
20 [2.8168]
21 [2.9753]
22 [3.1333]
23 [3.3717]
24 [3.481]
train done
Epoch 440/1000 : Loss:0.1450, Valid loss: 0.2700, lr:0.000115 [0.73] 1725.7795407772064
Model 440 saved.
1 [0.1048]
2 [0.1789]
3 [0.3028]
4 [0.4304]
5 [0.5896]
6 [0.8332]
7 [1.074]
8 [1.1531]
9 [1.2816]
10 [1.4241]
11 [1.5389]
12 [1.7292]
13 [1.8301]
14 [2.0434]
15 [2.2576]
16 [2.4717]
17 [2.6483]
18 [2.7494]
19 [2.862]
20 [3.0005]
21 [3.0829]
22 [3.2554]
23 [3.3709]
24 [3.444]
train done
Epoch 441/1000 : Loss:0.1435, Valid loss: 0.2633, lr:0.000115 [0.7367] 1769.9336578845978
1 [0.1213]
2 [0.2822]
3 [0.3892]
4 [0.5657]
5 [0.6722]
6 [0.7421]
7 [0.8779]
8 [1.1944]
9 [1.3636]
10 [1.4819]
11 [1.7227]
12 [1.8366]
13 [1.9883]
14 [2.0848]
15 [2.1759]
16 [2.2714]
17 [2.509]
18 [2.6618]
19 [3.0241]
20 [3.2049]
21 [3.3875]
22 [3.6585]
23 [3.7913]
24 [3.9909]
train done
Epoch 442/1000 : Loss:0.1663, Valid loss: 0.2697, lr:0.000115 [0.7303] 1728.650004863739
1 [0.086]
2 [0.4066]
3 [0.5702]
4 [0.7205]
5 [0.8863]
6 [0.9859]
7 [1.1176]
8 [1.2952]
9 [1.3928]
10 [1.6365]
11 [1.7879]
12 [1.9646]
13 [2.2414]
14 [2.4852]
15 [2.5787]
16 [2.6691]
17 [2.8671]
18 [3.0818]
19 [3.2796]
20 [3.459]
21 [3.6213]
22 [3.7356]
23 [3.8811]
24 [3.971]
train done
Epoch 443/1000 : Loss:0.1655, Valid loss: 0.2800, lr:0.000115 [0.72] 1722.108351945877
1 [0.1497]
2 [0.343]
3 [0.5091]
4 [0.5953]
5 [0.7613]
6 [0.9218]
7 [1.0784]
8 [1.2423]
9 [1.34]
10 [1.4386]
11 [1.5405]
12 [1.7549]
13 [1.9023]
14 [1.9905]
15 [2.1236]
16 [2.2364]
17 [2.4182]
18 [2.6094]
19 [3.0371]
20 [3.1505]
21 [3.3507]
22 [3.4684]
23 [3.6384]
24 [3.9253]
train done
Epoch 444/1000 : Loss:0.1636, Valid loss: 0.2721, lr:0.000115 [0.7279] 1707.9820790290833
1 [0.0773]
2 [0.3333]
3 [0.4262]
4 [0.5207]
5 [0.6231]
6 [0.8415]
7 [0.9736]
8 [1.1845]
9 [1.3165]
10 [1.3908]
11 [1.5675]
12 [1.7161]
13 [1.9981]
14 [2.1578]
15 [2.3449]
16 [2.4908]
17 [2.6191]
18 [2.8728]
19 [2.9889]
20 [3.0746]
21 [3.1897]
22 [3.3521]
23 [3.4383]
24 [3.6111]
train done
Epoch 445/1000 : Loss:0.1505, Valid loss: 0.2701, lr:0.000115 [0.7299] 1706.6191699504852
1 [0.1459]
2 [0.3743]
3 [0.5164]
4 [0.8028]
5 [0.9218]
6 [1.0118]
7 [1.1327]
8 [1.3109]
9 [1.3875]
10 [1.7057]
11 [1.7811]
12 [1.8866]
13 [1.9656]
14 [2.0888]
15 [2.3539]
16 [2.4412]
17 [2.5444]
18 [2.712]
19 [2.8089]
20 [3.0389]
21 [3.1847]
22 [3.3814]
23 [3.6144]
24 [3.7431]
train done
Epoch 446/1000 : Loss:0.1560, Valid loss: 0.2745, lr:0.000115 [0.7255] 1701.4889941215515
******EXIT******: No improvement for 60 epochs!
