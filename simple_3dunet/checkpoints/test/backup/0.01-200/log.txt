Building a new model...
24 8 9 ['19.nii', '11.nii', '30.nii', '25.nii', '9.nii', '3.nii', '4.nii', '13.nii', '18.nii', '32.nii', '39.nii', '14.nii', '6.nii', '1.nii', '2.nii', '.DS_Store', '36.nii', '5.nii', '34.nii', '7.nii', '17.nii', '20.nii', '10.nii', '24.nii'] ['0.nii', '28.nii', '38.nii', '15.nii', '8.nii', '12.nii', '35.nii', '27.nii'] ['21.nii', '16.nii', '31.nii', '29.nii', '22.nii', '37.nii', '23.nii', '33.nii', '26.nii']
Starting training:
            Epochs:300
            Batch size:1
            Learning rate:0.001
            Training size:24
            Validation size:8
            
Building a new model...
6 2 2 ['7.nii', '4.nii', '0.nii', '2.nii', '6.nii', '9.nii'] ['3.nii', '1.nii'] ['5.nii', '8.nii']
Starting training:
            Epochs:300
            Batch size:1
            Learning rate:0.01
            Training size:6
            Validation size:2
            
1
2
3
4
5
6
train done
Epoch 1/300 : Loss:0.9982, Valid loss: 0.9979, lr:0.010000 [0.0021] 402.6077423095703
1
2
3
4
5
6
train done
Epoch 2/300 : Loss:0.9974, Valid loss: 0.9969, lr:0.010000 [0.0031] 402.9293031692505
1
2
3
4
5
6
train done
Epoch 3/300 : Loss:0.9967, Valid loss: 0.9954, lr:0.010000 [0.0046] 406.5734028816223
1
2
3
4
5
6
train done
Epoch 4/300 : Loss:0.9963, Valid loss: 0.9948, lr:0.010000 [0.0052] 398.113333940506
1
2
3
4
5
6
train done
Epoch 5/300 : Loss:0.9958, Valid loss: 0.9955, lr:0.010000 [0.0045] 387.39390683174133
1
2
3
4
5
6
train done
Epoch 6/300 : Loss:0.9950, Valid loss: 0.9938, lr:0.010000 [0.0062] 380.3852698802948
1
2
3
4
5
6
train done
Epoch 7/300 : Loss:0.9931, Valid loss: 0.9877, lr:0.010000 [0.0123] 379.55501914024353
1
2
3
4
5
6
train done
Epoch 8/300 : Loss:0.9914, Valid loss: 0.9906, lr:0.010000 [0.0094] 376.09808325767517
1
2
3
4
5
6
train done
Epoch 9/300 : Loss:0.9828, Valid loss: 0.9857, lr:0.010000 [0.0143] 372.97251987457275
1
2
3
4
5
6
train done
Epoch 10/300 : Loss:0.9597, Valid loss: 0.9800, lr:0.010000 [0.02] 373.72550988197327
Model 10 saved.
1
2
3
4
5
6
train done
Epoch 11/300 : Loss:0.9510, Valid loss: 0.9242, lr:0.010000 [0.0758] 375.1872351169586
1
2
3
4
5
6
train done
Epoch 12/300 : Loss:0.9284, Valid loss: 0.9116, lr:0.010000 [0.0884] 375.5150270462036
1
2
3
4
5
6
train done
Epoch 13/300 : Loss:0.9130, Valid loss: 0.9470, lr:0.010000 [0.053] 375.8440361022949
1
2
3
4
5
6
train done
Epoch 14/300 : Loss:0.8993, Valid loss: 0.9153, lr:0.010000 [0.0847] 375.4146020412445
1
2
3
4
5
6
train done
Epoch 15/300 : Loss:0.8646, Valid loss: 0.9140, lr:0.010000 [0.086] 373.6791398525238
1
2
3
4
5
6
train done
Epoch 16/300 : Loss:0.9054, Valid loss: 0.9442, lr:0.010000 [0.0558] 374.3803539276123
1
2
3
4
5
6
train done
Epoch 17/300 : Loss:0.8596, Valid loss: 0.9424, lr:0.010000 [0.0576] 376.9193298816681
1
2
3
4
5
6
train done
Epoch 18/300 : Loss:0.9798, Valid loss: 1.0000, lr:0.010000 [1.4114e-08] 375.74470686912537
1
2
3
4
5
6
train done
Epoch 19/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.3687e-08] 375.59764313697815
1
2
3
4
5
6
train done
Epoch 20/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.2416e-08] 375.5561318397522
Model 20 saved.
1
2
3
4
5
6
train done
Epoch 21/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.2668e-08] 374.68657398223877
1
2
3
4
5
6
train done
Epoch 22/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.2754e-08] 375.230073928833
1
2
3
4
5
6
train done
Epoch 23/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.3554e-08] 376.71408891677856
1
2
3
4
5
6
train done
Epoch 24/300 : Loss:0.9999, Valid loss: 1.0000, lr:0.010000 [1.4305e-08] 375.1273670196533
1
2
3
4
5
6
train done
Epoch 25/300 : Loss:0.9999, Valid loss: 1.0000, lr:0.010000 [1.4127e-08] 375.2390170097351
1
2
3
4
5
6
train done
Epoch 26/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.4077e-08] 375.3194930553436
1
2
3
4
5
6
train done
Epoch 27/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.3352e-08] 375.14071393013
1
2
3
4
5
6
train done
Epoch 28/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.3133e-08] 374.4406547546387
1
2
3
4
5
6
train done
Epoch 29/300 : Loss:1.0000, Valid loss: 1.0000, lr:0.010000 [1.2871e-08] 377.31110095977783
1
2
3
4
5
6
train done
Epoch 30/300 : Loss:0.9999, Valid loss: 1.0000, lr:0.010000 [1.283e-08] 376.37581396102905
Model 30 saved.
1
2
3
4
5
6
train done
Epoch 31/300 : Loss:0.9997, Valid loss: 1.0000, lr:0.007000 [1.3283e-08] 375.63243317604065
1
2
3
4
5
6
train done
Epoch 32/300 : Loss:0.9991, Valid loss: 1.0000, lr:0.007000 [1.2761e-08] 376.36303210258484
1
2
3
4
5
6
train done
Epoch 33/300 : Loss:0.9894, Valid loss: 0.9996, lr:0.007000 [0.0004] 375.48492407798767
1
2
3
4
5
6
train done
Epoch 34/300 : Loss:0.9290, Valid loss: 0.9295, lr:0.007000 [0.0705] 376.1866261959076
1
2
3
4
5
6
train done
Epoch 35/300 : Loss:0.8668, Valid loss: 0.9488, lr:0.007000 [0.0512] 375.3942310810089
1
2
3
4
5
6
train done
Epoch 36/300 : Loss:0.8224, Valid loss: 0.9124, lr:0.007000 [0.0876] 376.88280415534973
1
2
3
4
5
6
train done
Epoch 37/300 : Loss:0.8661, Valid loss: 0.8607, lr:0.007000 [0.1393] 378.00452494621277
1
2
3
4
5
6
train done
Epoch 38/300 : Loss:0.7743, Valid loss: 0.7812, lr:0.007000 [0.2188] 376.2430930137634
1
2
3
4
5
6
train done
Epoch 39/300 : Loss:0.6814, Valid loss: 0.8363, lr:0.007000 [0.1637] 376.6645860671997
1
2
3
4
5
6
train done
Epoch 40/300 : Loss:0.6785, Valid loss: 0.8275, lr:0.007000 [0.1725] 376.72358989715576
Model 40 saved.
1
2
3
4
5
6
train done
Epoch 41/300 : Loss:0.7059, Valid loss: 0.7935, lr:0.007000 [0.2065] 377.602175951004
1
2
3
4
5
6
train done
Epoch 42/300 : Loss:0.5898, Valid loss: 0.7506, lr:0.007000 [0.2494] 375.84944581985474
1
2
3
4
5
6
train done
Epoch 43/300 : Loss:0.5834, Valid loss: 0.8342, lr:0.007000 [0.1658] 377.0738570690155
1
2
3
4
5
6
train done
Epoch 44/300 : Loss:0.5297, Valid loss: 0.8109, lr:0.007000 [0.1891] 376.72177290916443
1
2
3
4
5
6
train done
Epoch 45/300 : Loss:0.5847, Valid loss: 0.7226, lr:0.007000 [0.2774] 377.0018491744995
1
2
3
4
5
6
train done
Epoch 46/300 : Loss:0.5788, Valid loss: 0.7497, lr:0.007000 [0.2503] 375.6299960613251
1
2
3
4
5
6
train done
Epoch 47/300 : Loss:0.5906, Valid loss: 0.7650, lr:0.007000 [0.235] 374.63215589523315
1
2
3
4
5
6
train done
Epoch 48/300 : Loss:0.5361, Valid loss: 0.7476, lr:0.007000 [0.2524] 376.1597490310669
1
2
3
4
5
6
train done
Epoch 49/300 : Loss:0.5046, Valid loss: 0.6984, lr:0.007000 [0.3016] 375.21701979637146
1
2
3
4
5
6
train done
Epoch 50/300 : Loss:0.5276, Valid loss: 0.7172, lr:0.007000 [0.2828] 375.4620180130005
Model 50 saved.
1
2
3
4
5
6
train done
Epoch 51/300 : Loss:0.5227, Valid loss: 0.7490, lr:0.007000 [0.251] 374.74420714378357
1
2
3
4
5
6
train done
Epoch 52/300 : Loss:0.4944, Valid loss: 0.7550, lr:0.007000 [0.245] 374.5745358467102
1
2
3
4
5
6
train done
Epoch 53/300 : Loss:0.5302, Valid loss: 0.7055, lr:0.007000 [0.2945] 374.98494005203247
1
2
3
4
5
6
train done
Epoch 54/300 : Loss:0.4855, Valid loss: 0.6995, lr:0.007000 [0.3005] 375.264817237854
1
2
3
4
5
6
train done
Epoch 55/300 : Loss:0.5317, Valid loss: 0.6871, lr:0.007000 [0.3129] 376.04532623291016
1
2
3
4
5
6
train done
Epoch 56/300 : Loss:0.4619, Valid loss: 0.7249, lr:0.007000 [0.2751] 375.5837330818176
1
2
3
4
5
6
train done
Epoch 57/300 : Loss:0.5487, Valid loss: 0.7176, lr:0.007000 [0.2824] 376.67550683021545
1
2
3
4
5
6
train done
Epoch 58/300 : Loss:0.5275, Valid loss: 0.6768, lr:0.007000 [0.3232] 376.2330138683319
1
2
3
4
5
6
train done
Epoch 59/300 : Loss:0.4794, Valid loss: 0.7161, lr:0.007000 [0.2839] 375.95639085769653
1
2
3
4
5
6
train done
Epoch 60/300 : Loss:0.4794, Valid loss: 0.7227, lr:0.007000 [0.2773] 377.74311685562134
Model 60 saved.
1
2
3
4
5
6
train done
Epoch 61/300 : Loss:0.4882, Valid loss: 0.7140, lr:0.004900 [0.286] 375.7835841178894
1
2
3
4
5
6
train done
Epoch 62/300 : Loss:0.4283, Valid loss: 0.7060, lr:0.004900 [0.294] 375.9632592201233
1
2
3
4
5
6
train done
Epoch 63/300 : Loss:0.4417, Valid loss: 0.6979, lr:0.004900 [0.3021] 377.87652707099915
1
2
3
4
5
6
train done
Epoch 64/300 : Loss:0.3918, Valid loss: 0.7148, lr:0.004900 [0.2852] 375.7374048233032
1
2
3
4
5
6
train done
Epoch 65/300 : Loss:0.3697, Valid loss: 0.7063, lr:0.004900 [0.2937] 376.8832540512085
1
2
3
4
5
6
train done
Epoch 66/300 : Loss:0.4021, Valid loss: 0.7126, lr:0.004900 [0.2874] 377.3504340648651
1
2
3
4
5
6
train done
Epoch 67/300 : Loss:0.3957, Valid loss: 0.6994, lr:0.004900 [0.3006] 377.27408599853516
1
2
3
4
5
6
train done
Epoch 68/300 : Loss:0.3649, Valid loss: 0.6960, lr:0.004900 [0.304] 377.1654369831085
1
2
3
4
5
6
train done
Epoch 69/300 : Loss:0.3571, Valid loss: 0.6890, lr:0.004900 [0.311] 377.4747738838196
1
2
3
4
5
6
train done
Epoch 70/300 : Loss:0.3794, Valid loss: 0.7062, lr:0.004900 [0.2938] 377.7362790107727
Model 70 saved.
1
2
3
4
5
6
train done
Epoch 71/300 : Loss:0.3664, Valid loss: 0.6961, lr:0.004900 [0.3039] 376.9413847923279
1
2
3
4
5
6
train done
Epoch 72/300 : Loss:0.3056, Valid loss: 0.7237, lr:0.004900 [0.2763] 375.92033100128174
1
2
3
4
5
6
train done
Epoch 73/300 : Loss:0.2518, Valid loss: 0.7325, lr:0.004900 [0.2675] 380.97622418403625
1
2
3
4
5
6
train done
Epoch 74/300 : Loss:0.3239, Valid loss: 0.7214, lr:0.004900 [0.2786] 376.97004079818726
1
2
3
4
5
6
train done
Epoch 75/300 : Loss:0.3493, Valid loss: 0.6857, lr:0.004900 [0.3143] 374.6461601257324
1
2
3
4
5
6
train done
Epoch 76/300 : Loss:0.3977, Valid loss: 0.7544, lr:0.004900 [0.2456] 375.899062871933
1
2
3
4
5
6
train done
Epoch 77/300 : Loss:0.4869, Valid loss: 0.6974, lr:0.004900 [0.3026] 374.2202408313751
1
2
3
4
5
6
train done
Epoch 78/300 : Loss:0.4341, Valid loss: 0.7053, lr:0.004900 [0.2947] 373.6184220314026
1
2
3
4
5
6
train done
Epoch 79/300 : Loss:0.4025, Valid loss: 0.6701, lr:0.004900 [0.3299] 373.5781331062317
1
2
3
4
5
6
train done
Epoch 80/300 : Loss:0.3591, Valid loss: 0.7413, lr:0.004900 [0.2587] 373.1027841567993
Model 80 saved.
1
2
3
4
5
6
train done
Epoch 81/300 : Loss:0.5141, Valid loss: 0.6810, lr:0.004900 [0.319] 402.51759481430054
1
2
3
4
5
6
train done
Epoch 82/300 : Loss:0.3883, Valid loss: 0.6877, lr:0.004900 [0.3123] 389.306293964386
1
2
3
4
5
6
train done
Epoch 83/300 : Loss:0.3609, Valid loss: 0.6777, lr:0.004900 [0.3223] 390.70330905914307
1
2
3
4
5
6
train done
Epoch 84/300 : Loss:0.4447, Valid loss: 0.6775, lr:0.004900 [0.3225] 404.28468203544617
1
2
3
4
5
6
train done
Epoch 85/300 : Loss:0.3982, Valid loss: 0.6965, lr:0.004900 [0.3035] 418.55007219314575
1
2
3
4
5
6
train done
Epoch 86/300 : Loss:0.3582, Valid loss: 0.7154, lr:0.004900 [0.2846] 418.84198904037476
1
2
3
4
5
6
train done
Epoch 87/300 : Loss:0.4397, Valid loss: 0.6653, lr:0.004900 [0.3347] 402.2205550670624
1
2
3
4
5
6
train done
Epoch 88/300 : Loss:0.3592, Valid loss: 0.6533, lr:0.004900 [0.3467] 394.2053120136261
1
2
3
4
5
6
train done
Epoch 89/300 : Loss:0.3169, Valid loss: 0.6814, lr:0.004900 [0.3186] 413.2782838344574
1
2
3
4
5
6
train done
Epoch 90/300 : Loss:0.4357, Valid loss: 0.7167, lr:0.004900 [0.2833] 417.3235399723053
Model 90 saved.
1
2
3
4
5
6
train done
Epoch 91/300 : Loss:0.4027, Valid loss: 0.6892, lr:0.003430 [0.3108] 414.7396287918091
1
2
3
4
5
6
train done
Epoch 92/300 : Loss:0.3632, Valid loss: 0.7057, lr:0.003430 [0.2943] 417.27189207077026
1
2
3
4
5
6
train done
Epoch 93/300 : Loss:0.3694, Valid loss: 0.6846, lr:0.003430 [0.3154] 414.40172600746155
1
2
3
4
5
6
train done
Epoch 94/300 : Loss:0.3068, Valid loss: 0.6760, lr:0.003430 [0.324] 415.5874638557434
1
2
3
4
5
6
train done
Epoch 95/300 : Loss:0.3162, Valid loss: 0.6898, lr:0.003430 [0.3102] 414.09653306007385
1
2
3
4
5
6
train done
Epoch 96/300 : Loss:0.3170, Valid loss: 0.6962, lr:0.003430 [0.3038] 414.66275215148926
1
2
3
4
5
6
train done
Epoch 97/300 : Loss:0.2912, Valid loss: 0.6815, lr:0.003430 [0.3185] 415.4307441711426
1
2
3
4
5
6
train done
Epoch 98/300 : Loss:0.2760, Valid loss: 0.6526, lr:0.003430 [0.3474] 415.9643859863281
1
2
3
4
5
6
train done
Epoch 99/300 : Loss:0.3488, Valid loss: 0.6529, lr:0.003430 [0.3471] 416.06537795066833
1
2
3
4
5
6
train done
Epoch 100/300 : Loss:0.2653, Valid loss: 0.6682, lr:0.003430 [0.3318] 424.7215600013733
Model 100 saved.
1
2
3
4
5
6
train done
Epoch 101/300 : Loss:0.2302, Valid loss: 0.6810, lr:0.003430 [0.319] 416.7821171283722
1
2
3
4
5
6
train done
Epoch 102/300 : Loss:0.2580, Valid loss: 0.6557, lr:0.003430 [0.3443] 414.5743350982666
1
2
3
4
5
6
train done
Epoch 103/300 : Loss:0.3021, Valid loss: 0.6684, lr:0.003430 [0.3316] 408.57221388816833
1
2
3
4
5
6
train done
Epoch 104/300 : Loss:0.3235, Valid loss: 0.6593, lr:0.003430 [0.3407] 417.7499098777771
1
2
3
4
5
6
train done
Epoch 105/300 : Loss:0.2395, Valid loss: 0.6845, lr:0.003430 [0.3155] 394.9512982368469
1
2
3
4
5
6
train done
Epoch 106/300 : Loss:0.2902, Valid loss: 0.6673, lr:0.003430 [0.3327] 394.2033200263977
1
2
3
4
5
6
train done
Epoch 107/300 : Loss:0.2310, Valid loss: 0.7115, lr:0.003430 [0.2885] 394.9927308559418
1
2
3
4
5
6
train done
Epoch 108/300 : Loss:0.3398, Valid loss: 0.6781, lr:0.003430 [0.3219] 400.42061710357666
1
2
3
4
5
6
train done
Epoch 109/300 : Loss:0.2688, Valid loss: 0.6598, lr:0.003430 [0.3402] 397.4270808696747
1
2
3
4
5
6
train done
Epoch 110/300 : Loss:0.2516, Valid loss: 0.6792, lr:0.003430 [0.3208] 397.33537888526917
Model 110 saved.
1
2
3
4
5
6
train done
Epoch 111/300 : Loss:0.2969, Valid loss: 0.6531, lr:0.003430 [0.3469] 400.51047706604004
1
2
3
4
5
6
train done
Epoch 112/300 : Loss:0.2680, Valid loss: 0.6406, lr:0.003430 [0.3594] 387.8843080997467
1
2
3
4
5
6
train done
Epoch 113/300 : Loss:0.3023, Valid loss: 0.6434, lr:0.003430 [0.3566] 388.4376177787781
1
2
3
4
5
6
train done
Epoch 114/300 : Loss:0.2879, Valid loss: 0.6946, lr:0.003430 [0.3054] 385.1659269332886
1
2
3
4
5
6
train done
Epoch 115/300 : Loss:0.2409, Valid loss: 0.6583, lr:0.003430 [0.3417] 392.4045569896698
1
2
3
4
5
6
train done
Epoch 116/300 : Loss:0.2242, Valid loss: 0.6497, lr:0.003430 [0.3503] 394.3041648864746
1
2
3
4
5
6
train done
Epoch 117/300 : Loss:0.2423, Valid loss: 0.6766, lr:0.003430 [0.3234] 392.60849690437317
1
2
3
4
5
6
train done
Epoch 118/300 : Loss:0.2459, Valid loss: 0.7134, lr:0.003430 [0.2866] 384.0063831806183
1
2
3
4
5
6
train done
Epoch 119/300 : Loss:0.3053, Valid loss: 0.6704, lr:0.003430 [0.3296] 373.26929926872253
1
2
3
4
5
6
train done
Epoch 120/300 : Loss:0.2549, Valid loss: 0.6908, lr:0.003430 [0.3092] 374.37542605400085
Model 120 saved.
1
2
3
4
5
6
train done
Epoch 121/300 : Loss:0.3559, Valid loss: 0.6647, lr:0.002401 [0.3353] 374.53511095046997
1
2
3
4
5
6
train done
Epoch 122/300 : Loss:0.2307, Valid loss: 0.6644, lr:0.002401 [0.3356] 377.38522505760193
1
2
3
4
5
6
train done
Epoch 123/300 : Loss:0.2516, Valid loss: 0.6945, lr:0.002401 [0.3055] 372.6597809791565
1
2
3
4
5
6
train done
Epoch 124/300 : Loss:0.2303, Valid loss: 0.6785, lr:0.002401 [0.3215] 371.5381360054016
1
2
3
4
5
6
train done
Epoch 125/300 : Loss:0.1845, Valid loss: 0.6754, lr:0.002401 [0.3246] 371.8903863430023
1
2
3
4
5
6
train done
Epoch 126/300 : Loss:0.2535, Valid loss: 0.6672, lr:0.002401 [0.3328] 373.14069509506226
1
2
3
4
5
6
train done
Epoch 127/300 : Loss:0.2094, Valid loss: 0.6681, lr:0.002401 [0.3319] 372.16787004470825
1
2
3
4
5
6
train done
Epoch 128/300 : Loss:0.2158, Valid loss: 0.6620, lr:0.002401 [0.338] 374.20209789276123
1
2
3
4
5
6
train done
Epoch 129/300 : Loss:0.2100, Valid loss: 0.6722, lr:0.002401 [0.3278] 375.2652599811554
1
2
3
4
5
6
train done
Epoch 130/300 : Loss:0.2261, Valid loss: 0.6949, lr:0.002401 [0.3051] 374.84299302101135
Model 130 saved.
1
2
3
4
5
6
train done
Epoch 131/300 : Loss:0.2271, Valid loss: 0.6371, lr:0.002401 [0.3629] 373.61639189720154
1
2
3
4
5
6
train done
Epoch 132/300 : Loss:0.2046, Valid loss: 0.6137, lr:0.002401 [0.3863] 373.96919417381287
1
2
3
4
5
6
train done
Epoch 133/300 : Loss:0.1991, Valid loss: 0.6554, lr:0.002401 [0.3446] 374.2831518650055
1
2
3
4
5
6
train done
Epoch 134/300 : Loss:0.1740, Valid loss: 0.6547, lr:0.002401 [0.3453] 375.37558698654175
1
2
3
4
5
6
train done
Epoch 135/300 : Loss:0.2006, Valid loss: 0.6627, lr:0.002401 [0.3373] 376.68408393859863
1
2
3
4
5
6
train done
Epoch 136/300 : Loss:0.2210, Valid loss: 0.6598, lr:0.002401 [0.3402] 375.78387475013733
1
2
3
4
5
6
train done
Epoch 137/300 : Loss:0.2250, Valid loss: 0.6504, lr:0.002401 [0.3496] 373.24919080734253
1
2
3
4
5
6
train done
Epoch 138/300 : Loss:0.2592, Valid loss: 0.6298, lr:0.002401 [0.3702] 374.875563621521
1
2
3
4
5
6
train done
Epoch 139/300 : Loss:0.2232, Valid loss: 0.6461, lr:0.002401 [0.3539] 375.5246071815491
1
2
3
4
5
6
train done
Epoch 140/300 : Loss:0.2153, Valid loss: 0.6299, lr:0.002401 [0.3701] 374.59210991859436
Model 140 saved.
1
2
3
4
5
6
train done
Epoch 141/300 : Loss:0.2004, Valid loss: 0.6015, lr:0.002401 [0.3985] 375.2719099521637
1
2
3
4
5
6
train done
Epoch 142/300 : Loss:0.1793, Valid loss: 0.6251, lr:0.002401 [0.3749] 376.78862619400024
1
2
3
4
5
6
train done
Epoch 143/300 : Loss:0.1640, Valid loss: 0.6567, lr:0.002401 [0.3433] 376.73090505599976
1
2
3
4
5
6
train done
Epoch 144/300 : Loss:0.2347, Valid loss: 0.6823, lr:0.002401 [0.3177] 376.31397771835327
1
2
3
4
5
6
train done
Epoch 145/300 : Loss:0.2600, Valid loss: 0.6246, lr:0.002401 [0.3754] 375.11939692497253
1
2
3
4
5
6
train done
Epoch 146/300 : Loss:0.2269, Valid loss: 0.5891, lr:0.002401 [0.4109] 375.27017092704773
1
2
3
4
5
6
train done
Epoch 147/300 : Loss:0.2242, Valid loss: 0.6165, lr:0.002401 [0.3835] 376.69783878326416
1
2
3
4
5
6
train done
Epoch 148/300 : Loss:0.2215, Valid loss: 0.6465, lr:0.002401 [0.3535] 377.19613790512085
1
2
3
4
5
6
train done
Epoch 149/300 : Loss:0.2010, Valid loss: 0.6241, lr:0.002401 [0.3759] 375.08325386047363
1
2
3
4
5
6
train done
Epoch 150/300 : Loss:0.1764, Valid loss: 0.6185, lr:0.002401 [0.3815] 376.216295003891
Model 150 saved.
1
2
3
4
5
6
train done
Epoch 151/300 : Loss:0.2148, Valid loss: 0.5966, lr:0.001681 [0.4034] 375.621701002121
1
2
3
4
5
6
train done
Epoch 152/300 : Loss:0.1892, Valid loss: 0.6154, lr:0.001681 [0.3846] 376.1831753253937
1
2
3
4
5
6
train done
Epoch 153/300 : Loss:0.1841, Valid loss: 0.6306, lr:0.001681 [0.3694] 375.18951177597046
1
2
3
4
5
6
train done
Epoch 154/300 : Loss:0.1842, Valid loss: 0.6549, lr:0.001681 [0.3451] 375.63712882995605
1
2
3
4
5
6
train done
Epoch 155/300 : Loss:0.1662, Valid loss: 0.6510, lr:0.001681 [0.349] 377.67984223365784
1
2
3
4
5
6
train done
Epoch 156/300 : Loss:0.1738, Valid loss: 0.6398, lr:0.001681 [0.3602] 376.9711101055145
1
2
3
4
5
6
train done
Epoch 157/300 : Loss:0.1782, Valid loss: 0.6394, lr:0.001681 [0.3606] 384.1190288066864
1
2
3
4
5
6
train done
Epoch 158/300 : Loss:0.1588, Valid loss: 0.6266, lr:0.001681 [0.3734] 408.627809047699
1
2
3
4
5
6
train done
Epoch 159/300 : Loss:0.1633, Valid loss: 0.6319, lr:0.001681 [0.3681] 420.74256682395935
1
2
3
4
5
6
train done
Epoch 160/300 : Loss:0.1599, Valid loss: 0.6173, lr:0.001681 [0.3827] 415.8989520072937
Model 160 saved.
1
2
3
4
5
6
train done
Epoch 161/300 : Loss:0.1425, Valid loss: 0.6284, lr:0.001681 [0.3716] 416.1173400878906
1
2
3
4
5
6
train done
Epoch 162/300 : Loss:0.1599, Valid loss: 0.6298, lr:0.001681 [0.3702] 419.29092288017273
1
2
3
4
5
6
train done
Epoch 163/300 : Loss:0.1459, Valid loss: 0.6347, lr:0.001681 [0.3653] 390.5540328025818
1
2
3
4
5
6
train done
Epoch 164/300 : Loss:0.1373, Valid loss: 0.6472, lr:0.001681 [0.3528] 392.2367379665375
1
2
3
4
5
6
train done
Epoch 165/300 : Loss:0.1423, Valid loss: 0.6382, lr:0.001681 [0.3618] 395.64931631088257
1
2
3
4
5
6
train done
Epoch 166/300 : Loss:0.1758, Valid loss: 0.6211, lr:0.001681 [0.3789] 394.8915288448334
1
2
3
4
5
6
train done
Epoch 167/300 : Loss:0.1525, Valid loss: 0.6358, lr:0.001681 [0.3642] 393.3389027118683
1
2
3
4
5
6
train done
Epoch 168/300 : Loss:0.1521, Valid loss: 0.6320, lr:0.001681 [0.368] 386.69479298591614
1
2
3
4
5
6
train done
Epoch 169/300 : Loss:0.1474, Valid loss: 0.6550, lr:0.001681 [0.345] 398.8461229801178
1
2
3
4
5
6
train done
Epoch 170/300 : Loss:0.1488, Valid loss: 0.6393, lr:0.001681 [0.3607] 387.71906208992004
Model 170 saved.
1
2
3
4
5
6
train done
Epoch 171/300 : Loss:0.1460, Valid loss: 0.6481, lr:0.001681 [0.3519] 387.48800015449524
1
2
3
4
5
6
train done
Epoch 172/300 : Loss:0.1441, Valid loss: 0.6272, lr:0.001681 [0.3728] 389.14457511901855
1
2
3
4
5
6
train done
Epoch 173/300 : Loss:0.1917, Valid loss: 0.6483, lr:0.001681 [0.3517] 403.4544987678528
1
2
3
4
5
6
train done
Epoch 174/300 : Loss:0.1851, Valid loss: 0.6514, lr:0.001681 [0.3486] 395.79231214523315
1
2
3
4
5
6
train done
Epoch 175/300 : Loss:0.1681, Valid loss: 0.7104, lr:0.001681 [0.2896] 394.4358730316162
1
2
3
4
5
6
train done
Epoch 176/300 : Loss:0.2091, Valid loss: 0.6618, lr:0.001681 [0.3382] 393.02047991752625
1
2
3
4
5
6
train done
Epoch 177/300 : Loss:0.2041, Valid loss: 0.6460, lr:0.001681 [0.354] 396.4990608692169
1
2
3
4
5
6
train done
Epoch 178/300 : Loss:0.1974, Valid loss: 0.6507, lr:0.001681 [0.3493] 398.5017671585083
1
2
3
4
5
6
train done
Epoch 179/300 : Loss:0.2053, Valid loss: 0.6652, lr:0.001681 [0.3348] 387.4671142101288
1
2
3
4
5
6
train done
Epoch 180/300 : Loss:0.1744, Valid loss: 0.6626, lr:0.001681 [0.3374] 379.6758677959442
Model 180 saved.
1
2
3
4
5
6
train done
Epoch 181/300 : Loss:0.1725, Valid loss: 0.6446, lr:0.001176 [0.3554] 385.08577728271484
1
2
3
4
5
6
train done
Epoch 182/300 : Loss:0.2017, Valid loss: 0.6805, lr:0.001176 [0.3195] 374.2291898727417
1
2
3
4
5
6
train done
Epoch 183/300 : Loss:0.1804, Valid loss: 0.6724, lr:0.001176 [0.3276] 369.9672119617462
1
2
3
4
5
6
train done
Epoch 184/300 : Loss:0.1780, Valid loss: 0.6609, lr:0.001176 [0.3391] 379.2345631122589
1
2
3
4
5
6
train done
Epoch 185/300 : Loss:0.1644, Valid loss: 0.6519, lr:0.001176 [0.3481] 373.7805335521698
1
2
3
4
5
6
train done
Epoch 186/300 : Loss:0.1568, Valid loss: 0.6314, lr:0.001176 [0.3686] 371.58490109443665
1
2
3
4
5
6
train done
Epoch 187/300 : Loss:0.1935, Valid loss: 0.6369, lr:0.001176 [0.3631] 374.4372329711914
1
2
3
4
5
6
train done
Epoch 188/300 : Loss:0.1586, Valid loss: 0.6406, lr:0.001176 [0.3594] 373.47918486595154
1
2
3
4
5
6
train done
Epoch 189/300 : Loss:0.1400, Valid loss: 0.6350, lr:0.001176 [0.365] 375.0208189487457
1
2
3
4
5
6
train done
Epoch 190/300 : Loss:0.1321, Valid loss: 0.6360, lr:0.001176 [0.364] 374.04239892959595
Model 190 saved.
1
2
3
4
5
6
train done
Epoch 191/300 : Loss:0.1527, Valid loss: 0.6308, lr:0.001176 [0.3692] 383.0793499946594
1
2
3
4
5
6
train done
Epoch 192/300 : Loss:0.1698, Valid loss: 0.6275, lr:0.001176 [0.3725] 374.4914581775665
1
2
3
4
5
6
train done
Epoch 193/300 : Loss:0.1295, Valid loss: 0.6390, lr:0.001176 [0.361] 375.40273427963257
1
2
3
4
5
6
train done
Epoch 194/300 : Loss:0.1733, Valid loss: 0.6213, lr:0.001176 [0.3787] 373.0099220275879
1
2
3
4
5
6
train done
Epoch 195/300 : Loss:0.1466, Valid loss: 0.6302, lr:0.001176 [0.3698] 372.48018407821655
1
2
3
4
5
6
train done
Epoch 196/300 : Loss:0.1377, Valid loss: 0.6397, lr:0.001176 [0.3603] 371.5886800289154
1
2
3
4
5
6
train done
Epoch 197/300 : Loss:0.1412, Valid loss: 0.6243, lr:0.001176 [0.3757] 384.5849258899689
1
2
3
4
5
6
train done
Epoch 198/300 : Loss:0.1347, Valid loss: 0.6436, lr:0.001176 [0.3564] 393.679151058197
1
2
3
4
5
6
train done
Epoch 199/300 : Loss:0.1412, Valid loss: 0.6236, lr:0.001176 [0.3764] 406.20933079719543
1
2
3
4
5
6
train done
Epoch 200/300 : Loss:0.1568, Valid loss: 0.6279, lr:0.001176 [0.3721] 405.51627492904663
Model 200 saved.
1
2
3
4
5
6
train done
Epoch 201/300 : Loss:0.1521, Valid loss: 0.6242, lr:0.001176 [0.3758] 417.47300004959106
1
2
3
4
5
6
train done
Epoch 202/300 : Loss:0.1592, Valid loss: 0.6334, lr:0.001176 [0.3666] 408.5642261505127
1
2
3
4
5
6
train done
Epoch 203/300 : Loss:0.1548, Valid loss: 0.6418, lr:0.001176 [0.3582] 407.0178098678589
1
2
3
4
5
6
train done
Epoch 204/300 : Loss:0.1365, Valid loss: 0.6397, lr:0.001176 [0.3603] 396.42240476608276
1
2
3
4
5
6
train done
Epoch 205/300 : Loss:0.1507, Valid loss: 0.6491, lr:0.001176 [0.3509] 378.87008810043335
1
2
3
4
5
6
train done
Epoch 206/300 : Loss:0.1456, Valid loss: 0.6431, lr:0.001176 [0.3569] 379.08359122276306
******EXIT******: No improvement for 60 epochs!
